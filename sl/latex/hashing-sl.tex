\chapter{Razpršene tabele}
\chaplabel{hashtables}
\chaplabel{hashing}
\translatedby{Matej Romih, Aleš Lokovšek, ???}{sl}
Razpršene tabele predstavljajo učinkovito metodo za shranjevanje majhnega števila celih števil
#n#, iz velikega obsega $U=\{0,\ldots,2^{#w#}-1\}$.
Izraz \emph{Razpršena tabela}
\index{Razpršena tabela}%
sicer označuje širok spekter podatkovnih struktur. 
rvi del poglavja se osredotoča na dve najbolj pogosti implementaciji: zgoščevanje z veriženjem in linear probing.

Zelo pogosto se uporabljajo za shranjevanje podatkov, katerih
tip niso cela števila.
V tem primeru je celoštevilska \emph{razpršena koda}
\index{razpršena koda}%
povezana z vsako podatkovno enoto in uporabljena v razpršeni tabeli. 
Drugi del predstavi, kako so razpršene kode ustvarjene.

Nekatere uporabljene metode iz tega poglavja potrebujejo naključno izbrana števila v določenem razponu.
V primerih kode, so nekatera ``naključna'' cela števila
enolično določena z uporabo naključnih bitov generiranih iz atmosferskega šuma.

\section{Razpršena tabela z veriženjem}
\seclabel{hashtable}
Podatkovna struktura verižna razpršena tabela za shranjevanje tabele t listov uporablja zgoščevanje z veriženjem. Za hranjenje skupnega števila itemov v vseh seznamih se uporablja celo število n.
(see \figref{chainedhashtable}):
\codeimport{ods/ChainedHashTable.t.n}

\begin{figure}
   \begin{center}
     \includegraphics[width=\ScaleIfNeeded]{figs/chainedhashtable}
   \end{center}
   \caption[A ChainedHashTable]{Primer verižne razpršene tabele z $#n#=14$ in $#t.length#=16$.  V tem primeru je $#hash(x)#=6$}
   \figlabel{chainedhashtable}
\end{figure}

\emph{Razpršena vrednost} podatkovnega objekta #x#, označena z #hash(x)# predstavlja vrednost v razponu $\{0,\ldots,#t.length#-1\}$. Vsi itemi z razpršeno vrednostjo #i#
so shranjeni v seznamu na lokaciji #t[i]#.  Da se izognemo prevelikim 
seznamom, ohranjamo invarianto
\[
    #n# \le #t.length#
\]
tako da je povprečno število elementov shranjenih v posameznem seznamu
$#n#/#t.length# \le 1$.

Pri dodajanju elementa #x#, v razpršeno tabelo, najprej preverimo če je potrebno povečati #t.length#. V kolikor je to potrebno ga povečamo.
Potem razpršimo #x#, da dobimo število #i#, v razponu $\{0,\ldots,#t.length#-1\}$, in pripnemo #x# seznamu #t[i]#:
\codeimport{ods/ChainedHashTable.add(x)}
Povečevanje tabele, v kolikor je le-to potrebno, vključuje podvojitev dolžine tabele #t# in ponovno vstavljanje elementov vanjo. Ta strategija je popolnoma enaka kot pri implementaciji
ArrayStacka in tudi tu velja enako pravilo: Cena rasti je amortizirano po nekaj sekvencah vstavljanja  samo konstantna (see~\lemref{arraystack-amortized} on
page~\pageref{lem:arraystack-amortized}).

Poleg rasti je edino potrebno opravilo ob vstavljanju nove vrednosti #x# v razpršeno verižno tabelo dodajanje #x#-a seznamu #t[hash(x)]#. Za katerokoli od implementacij seznama 
opisanih v poglavjih Chapters~\ref{chap:arrays}
in \ref{chap:linkedlists}, potrebujemo le konstanten čas.

Za odstranitev elementa #x# iz razpršene tabele se sprehodimo čez seznam #t[hash(x)]#, dokler n najdemo elementa #x#, tako da ga lahko odstranimo:
\codeimport{ods/ChainedHashTable.remove(x)}
Časovna zahtevnost je $O(#n#_{#hash(x)#})$), pri čemer  $#n#_{#i#}$ označuje dolžino seznama shranjenega v #t[i]#.

Iskanje elementa #x# v razpršeni tabeli poteka podobno. Izvedemo linearno iskanje nad seznamom #t[hash(x)]#:
\codeimport{ods/ChainedHashTable.find(x)}
Podobno tudi tu potrebujemo čas sorezmeren z dolžino seznama #t[hash(x)]#.

Performanse razpršene tabele so odvisne predvsem od izbire razpršilne funkcije. Dobra zgoščevalna funkcija razporedi elemente sorezmerno med #t.length# seznamov, tako da je pričakovana
velikost seznama #t[hash(x)]# $O(#n#/#t.length)# = O(1)$. Po drugi strani pa slaba zgoščevalna funkcija razprši vse vrednosti(vključno z #x#) na isto lokacijo v tabeli. V tem primeru bo velikost
seznama #t[hash(x)]# #n#. V naslednjem poglavju je opisan primer dobre zgoščevalne funckije. 

\subsection{Multiplicative Hashing}
\seclabel{multihash}

\index{hashing!multiplicative}%
\index{multiplicative hashing}%

Množilno razprševanje je učinkovita metoda tvorbe razprščenih vrednosti osnovana na modularni aritmetiki(opisana v poglavju  \secref{arrayqueue}) in celoštevilskemu deljenju. Uporablja $\ddiv$ operator, 
ki obdrži celoštevilski del kvocienta, ostanek pa zanemari. Praktično za vsako število $a\ge 0$ in $b\ge 1$, $a\ddiv b = \lfloor
a/b\rfloor$. 

Pri množilnem razprševanju uporabljamo tabele velikosti $2^{#d#}$ pri čemer je #d# neko celo število(imenovano \emph{dimension}). Formula za razprševanje celega števila $#x#\in\{0,\ldots,2^{#w#}-1\}$ je
\[
    #hash#(#x#) = ((#z#\cdot#x#) \bmod 2^{#w#}) \ddiv 2^{#w#-#d#} \enspace .
\]

Pri tem je #z# neko naključno izbrano \emph{celo} število v $\{1,\ldots,2^{#w#}-1\}$.
Razprševalna funkcija je lahko realizirana zelo učinkovito, z obzirom na to, da so operacije nad celimi število že v osnovi modulom $2^{#w#}$, kjer je $#w#$ število bitov v celem številu. 
(Glej \figref{multihashing}.) Poleg tega je celoštevilsko deljenje z $2^{#w#-#d#}$ enako izločanju skrajno desnih $#w#-#d#$ bitov v binarni predstavitvi (kar uredimo s premikom $#w#-#d#$).
S tem dosežemo, da ima koda lažjo implementacijo kot sama formula:
\codeimport{ods/ChainedHashTable.hash(x)}

\begin{figure}
  \begin{center}
    \resizebox{.98\textwidth}{!}{
    \setlength{\arrayrulewidth}{1pt}
    \begin{tabular}{|lr@{}r|}\hline
    $2^#w#$ (4294967296)&            #1#&#00000000000000000000000000000000# \\
    #z# (4102541685)&                   &#11110100100001111101000101110101# \\
    #x# (42) &                          &#00000000000000000000000000101010# \\
    $#z#\cdot#x#$ &             #101000#&#00011110010010000101110100110010# \\
    $(#z#\cdot#x#)\bmod 2^{#w#}$ &      &#00011110010010000101110100110010# \\
    $((#z#\cdot#x#)\bmod 2^{#w#})\ddiv 2^{#w#-#d#}$ &&
                      \multicolumn{1}{@{}l|}{#00011110#} \\\hline
    \end{tabular}}
    \setlength{\arrayrulewidth}{.4pt}
  \end{center}
  \caption{Operacija večkratne razprševalne funkcije z $#w#=32$
    in $#d#=8$.}
  \figlabel{multihashing}
\end{figure}

Sledeča lema, katere dokaz sledi kasneje v poglavju, da množilno razprševanje precej uspešno preprečuje kolizije:

\begin{lem}\lemlabel{universal-hashing}
  Naj bosta #x# in #y# vrednosti iz $\{0,\ldots,2^{#w#}-1\}$ kjer
  $#x#\neq #y#$. Potem velja $\Pr\{#hash(x)#=#hash(y)#\} \le 2/2^{#d#}$.
\end{lem}

Z lemo \lemref{universal-hashing}, lahko precej preprosto ocenimo performanso  #remove(x)# in
#find(x)#:

\begin{lem}
  Za kakršnokoli vrednost #x#, je pričakovana dolžina seznama #t[hash(x)]# kvečjemu $#n#_{#x#} + 2$, kjer je $#n#_{#x#}$ število ponovitev #x#-a v razpršeni tableli.
\end{lem}


\begin{proof}
  Naj bo $S$ množica elementov različnih od #x# shranjenih v razpršeni tabeli. Za element $#y#\in S$, definiramo kazalno spremenljivko.

    \[ I_{#y#} = \left\{\begin{array}{ll}
       1 & \mbox{if $#hash(x)#=#hash(y)#$} \\
       0 & \mbox{otherwise}
       \end{array}\right.
    \]
 pri čemer opazimo, da po lemi \lemref{universal-hashing}, $\E[I_{#y#}] \le
  2/2^{#d#}=2/#t.length#$.  Pričakovana dolžina tabele #t[hash(x)]#
  je podaba z
  \begin{eqnarray*}
   \E\left[#t[hash(x)].size()#\right] &=& \E\left[#n#_{#x#} + \sum_{#y#\in S} I_{#y#}\right] \\
    &=& #n#_{#x#} + \sum_{#y#\in S} \E [I_{#y#} ] \\
    &\le& #n#_{#x#} + \sum_{#y#\in S} 2/#t.length# \\
    &\le& #n#_{#x#} + \sum_{#y#\in S} 2/#n# \\
    &\le& #n#_{#x#} + (#n#-#n#_{#x#})2/#n# \\
    &\le& #n#_{#x#} + 2 \enspace ,
  \end{eqnarray*}
\end{proof}

Da dokažemo pravilnost leme \lemref{universal-hashing}, potrebujemo dokaz iz teorije števil. V sledečem dokazu uporabljamo notacijo $(b_r,\ldots,b_0)_2$ za označitev $\sum_{i=0}^r b_i2^i$, kjer je vsak $b_i$ bit, torej 0 ali 1. Z drugimi besedami 
$(b_r,\ldots,b_0)_2$ je celo število, katerega binarna predstavitev je podana z $b_r,\ldots,b_0$. Za označbo neznane vrednosti uporabljamo $\star$.

\begin{lem}\lemlabel{hashing-mapping}
  Naj bo $S$ množica celih lihih števil v območju $\{1,\ldots,2^{#w#}-1\}$; naj bosta $q$
  in $i$ elementa iz množice $S$.  Potem obstaja samo ena vrednost
  $#z#\in S$, da velja $#z#q\bmod 2^{#w#} = i$.
\end{lem}

\begin{proof}
  Ker je število izbir za $#z#$ in $i$ enako je dovolj dokazati, da je
   \emph{vsaj} ena vrednost $#z#\in S$, ki zadošča
   $#z#q\bmod 2^{#w#} = i$.

 Predpostavimo, v namen protislovja, da obstajata dve vrednosti #z# in #z'#, za kateri velja $#z#>#z#'$. Potem
  \[
     #z#q\bmod 2^{#w#} = #z#'q \bmod 2^{#w#} = i
  \]
  Tako da
  \[ 
     (#z#-#z#')q\bmod 2^{#w#} = 0 
  \]
  Vendar to pomeni, da 
  \begin{equation}
    (#z#-#z#')q = k 2^{#w#} \eqlabel{factors} 
  \end{equation}
  za neko število $k$.  Gledano z vidika dvojiških števil, imamo 
  \[
    (#z#-#z#')q = k\cdot(1,\underbrace{0,\ldots,0}_{#w#})_2 \enspace ,
  \]
  tako da je #w# zadnjih bitov dvojiške predstavitve 
  $(#z#-#z#')q$ samih ničel.

  Naprej sledi $k\neq 0$, saj je $q\neq 0$ in $#z#-#z#'\neq 0$.  Ker je $q$
  liho število, nima desnih ničel v dvojiški predtsavitvi:
  \[
    q = (\star,\ldots,\star,1)_2 \enspace .
  \]
  Ker velja $|#z#-#z#'| < 2^{#w#}$, ima $#z#-#z#'$ manj kot #w# desnih ničel
  v svoji dvojiški predstavitvi:
  \[
    #z#-#z#' = (\star,\ldots,\star,1,\underbrace{0,\ldots,0}_{<#w#})_2
      \enspace .
  \]
  Potemtakem ima produkt $(#z#-#z#')q$ manj kot #w# desnih ničel v dvojiški predstavitvi:
  
  \[
   (#z#-#z#')q = (\star,\cdots,\star,1,\underbrace{0,\ldots,0}_{<#w#})_2 
    \enspace .
  \]
  Zato $(#z#-#z#')q$ ne zadošča \myeqref{factors}, kar rpivede do protislovja in s tem končamo dokaz.
\end{proof}

Uporabnost \lemref{hashing-mapping} izhaja iz sledeče
observation: Če je #z# izbran enakomerno naključno iz $S$, potem je #zt#
enakomerno porazdeljen nad $S$.  V sledečem dokazu, si pomagamo
z dvojiško predstavitvijo #z#, katera sestoji iz $#w#-1$
naključnih bitov s pripono 1.

\begin{proof}[Dokaz za \lemref{universal-hashing}]
  Začnemo z ugotovitvijo da je $#hash(x)#=#hash(y)#$ ekvivalenten
  trditvi `` #d# bitov najvišjega reda v $#z# #x#\bmod2^{#w#}$
  in #d# bitov najvišjega reda $#z# #y#\bmod 2^{#w#}$ je enakih.''
  Pri prejšnji trditvi je potrebno poudariti, da je #d# bitov najvišjega reda
  v dvojiški predstavitvi $#z#(#x#-#y#)\bmod 2^{#w#}$
  vseh enakih 1 ali enakih 0.  Torej velja,
  \begin{equation}
      #z#(#x#-#y#)\bmod 2^{#w#} = 
      (\underbrace{0,\ldots,0}_{#d#},\underbrace{\star,\ldots,\star}_{#w#-#d#})_2 
      \eqlabel{all-zeros}
  \end{equation}
  ko velja $#zx#\bmod 2^{#w#} > #zy#\bmod 2^{#w#}$ ali
  \begin{equation}
      #z#(#x#-#y#)\bmod 2^{#w#} = 
      (\underbrace{1,\ldots,1}_{#d#},\underbrace{\star,\ldots,\star}_{#w#-#d#})_2 
       \enspace .
      \eqlabel{all-ones}
  \end{equation}
  ko velja $#zx#\bmod 2^{#w#} < #zy#\bmod 2^{#w#}$.
  Potemtakem, ugotavljamo le verjetnost, da
  $#z#(#x#-#y#)\bmod 2^{#w#}$ izgleda kot \myeqref{all-zeros} or \myeqref{all-ones}.
  
  Naj bo $q$ enolično liho število, za katero velja $(#x#-#y#)\bmod
  2^{#w#}=q2^r$ za neko število $r\ge 0$. Po
  \lemref{hashing-mapping}, ima dvojiška predstavitev $#z#q\bmod
  2^{#w#}$ $#w#-1$ naključnih bitov, zaključenih z 1:
  \[
   #z#q\bmod 2^{#w#}  = (\underbrace{b_{#w#-1},\ldots,b_{1}}_{#w#-1},1)_2
  \]
  Iz tega sledi, da ima dvojiška predstavitev $#z#(#x#-#y#)\bmod 2^{#w#}=#z#q2^r\bmod 2^{#w#}$ 
  $#w#-r-1$ naključnih bitov, zaključenih z 1, zaključenih z $r$ ponovitvami 0:
  \[
  #z#(#x#-#y#)\bmod 2^{#w#}  =
  #z#q2^{r}\bmod 2^{#w#} =
      (\underbrace{b_{#w#-r-1},\ldots,b_{1}}_{#w#-r-1},1,\underbrace{0,0,\ldots,0}_{r})_2
  \]
  S tem zaključimo dokaz. Če je $r > #w#-#d#$, potem #d#
  bitov najvišjega reda $#z#(#x#-#y#)\bmod 2^{#w#}$  vsebuje tako ničle
   kot enice , tako da je verjetnost da $#z#(#x#-#y#)\bmod 2^{#w#}$ izgleda kot
  \myeqref{all-zeros} ali \myeqref{all-ones} nična.  Če je $#r#=#w#-#d#$,
  potem je verjetnost da izgleda kot \myeqref{all-zeros} nična, vendar je
  verjetnost da izgleda kot \myeqref{all-ones} $1/2^{#d#-1}=2/2^{#d#}$
  (ker moramo imeti $b_1,\ldots,b_{d-1}=1,\ldots,1$).  Če velja $r < #w#-#d#$,
  potem moramo imeti $b_{#w#-r-1},\ldots,b_{#w#-r-#d#}=0,\ldots,0$ ali
  $b_{#w#-r-1},\ldots,b_{#w#-r-#d#}=1,\ldots,1$.  Verjetnost posamezne
  od teh možnosti je $1/2^{#d#}$ pri čemer so vse vzajemno izključujoče, tako da je
  verjetnost da se zgodi katerakoli $2/2^{#d#}$. S tem zaključimo dokaz.
\end{proof}

\subsection{Summary}

Sledeči izrek prikaže preformanse podatkovne strukture #ChainedHashTable# :


\begin{thm}\thmlabel{hashtable}
  #ChainedHashTable# uporablja vmesnik #USet#.  V kolikor ignoriramo ceno
  klicev na #grow()#, #ChainedHashTable# izvaja operacije #add(x)#,
  #remove(x)#, in #find(x)# v $O(1)$ pričakovanem času na operacijo.

  Če začnemo s prazno #ChainedHashTable#, bo kakršnokoli zaporedje
  $m$ #add(x)# in #remove(x)# operacij rezlutiralo v skupaj $O(m)$
  časa porabljenega med izvajanjem #grow()#.
\end{thm}


\begin{proof}
%str 113-114
  Zato ima , produkt $(#z#-#z#')q$  manj kot #w# zadnjih 
  ničel od v njegovi binarni zastopanosti:
  \[ 
   (#z#-#z#')q = (\star,\cdots,\star,1,\underbrace{0,\ldots,0}_{<#w#})_2 
    \enspace .
  \]
  Tako $(#z#-#z#')q$ ne more zadovoljiti \myeqref{factors}, 
  dobimo protislovje, kar dokončuje dokaz.
\end{proof}

Uporabnost \lemref{hashing-mapping} prihaja od naslednjih opazovanja: 
Če je #z# izbran enakomerno, naključno od $S$, potem je #zt# enakomerno 
porazdeljen čez $S$. V naslednjem dokazu, pomaga razmišljati o binarni 
predstavitvi #z#, ki je sestavljen iz $#w#-1$ naključni bitov čemur sledi 1.

\begin{proof}[Dokaz \lemref{universal-hashing}]
  Najprej smo ugotovili, da je pogoj $#hash(x)#=#hash(y)#$ enakovreden izjavi 
  ``najvišji vrstni red #d# bitov od $#z# #x#\bmod2^{#w#}$
  in izjavi najvišji vrstni red #d# bitov od $#z# #y#\bmod 2^{#w#}$ sta enaka.''
  Nujen pogoj za to izjavo je ta, da je najvišji vrstni red
  #d# bitov v binarnem zastopanju od $#z#(#x#-#y#)\bmod 2^{#w#}$
  je bodisi vse ničle ali vse enke.  To je,
  \begin{equation}
      #z#(#x#-#y#)\bmod 2^{#w#} = 
      (\underbrace{0,\ldots,0}_{#d#},\underbrace{\star,\ldots,\star}_{#w#-#d#})_2 
      \eqlabel{all-zeros}
  \end{equation}
  kadar $#zx#\bmod 2^{#w#} > #zy#\bmod 2^{#w#}$ ali
  \begin{equation}
      #z#(#x#-#y#)\bmod 2^{#w#} = 
      (\underbrace{1,\ldots,1}_{#d#},\underbrace{\star,\ldots,\star}_{#w#-#d#})_2 
       \enspace .
      \eqlabel{all-ones}
  \end{equation}
  kadar je $#zx#\bmod 2^{#w#} < #zy#\bmod 2^{#w#}$.
  Torej moramo samo vezati verjetnost da 
  $#z#(#x#-#y#)\bmod 2^{#w#}$ izgleda kot \myeqref{all-zeros} ali \myeqref{all-ones}.
  
  Naj bo $q$ edinstveno liho število tako da je $(#x#-#y#)\bmod
  2^{#w#}=q2^r$ za nekatero število $r\ge 0$. Po
  \lemref{hashing-mapping}, ima $#z#q\bmod
  2^{#w#}$ binarno zastopanje  $#w#-1$ naključnih bitov, katerim sledi 1:
  \[
   #z#q\bmod 2^{#w#}  = (\underbrace{b_{#w#-1},\ldots,b_{1}}_{#w#-1},1)_2
  \]
  Torej, binarno zastopanje $#z#(#x#-#y#)\bmod 2^{#w#}=#z#q2^r\bmod 2^{#w#}$ ima
  $#w#-r-1$ naključnih bitov, katerim sledi 1, kateri sledi tudi $r$ ničel:
  \[
  #z#(#x#-#y#)\bmod 2^{#w#}  =
  #z#q2^{r}\bmod 2^{#w#} =
      (\underbrace{b_{#w#-r-1},\ldots,b_{1}}_{#w#-r-1},1,\underbrace{0,0,\ldots,0}_{r})_2
  \]
  Sedaj lahko končamo dokaz:  Če je $r > #w#-#d#$, potem #d#
  biti višjega reda od $#z#(#x#-#y#)\bmod 2^{#w#}$  vsebujejo tako ničle
  kot tudi enke, zato je verjetnost, da bi  $#z#(#x#-#y#)\bmod 2^{#w#}$ izgledal kot,
  \myeqref{all-zeros} ali \myeqref{all-ones} enaka 0.  Če je $#r#=#w#-#d#$,
  potem je verjetnost, da bo le-ta izgledal kot  \myeqref{all-zeros} enaka 0, a je verjetnost
  da bo izgledal kot \myeqref{all-ones} enaka $1/2^{#d#-1}=2/2^{#d#}$
  (saj moramo imeti $b_1,\ldots,b_{d-1}=1,\ldots,1$).  Če je $r < #w#-#d#$,
  potem moramo imeti $b_{#w#-r-1},\ldots,b_{#w#-r-#d#}=0,\ldots,0$ ali pa
  $b_{#w#-r-1},\ldots,b_{#w#-r-#d#}=1,\ldots,1$.  Verjetnost teh posameznih primerov je $1/2^{#d#}$ in so 
  medsebojno izključujoči, na tak način da je
  verjetnost kateregakoli primera enaka $2/2^{#d#}$.  To zaključuje
  dokaz.
\end{proof}

\subsection{Povzetek}
\translatedby{Edin Beganovic}{sl}

Naslednji izrek povzema uspešnost #ChainedHash-Table# podatkovne strukture:

\begin{thm}\thmlabel{hashtable}
  #ChainedHashTable# implementira vmesnik #USet#. Če ignoriramo ceno klicev 
  metode #grow()#, #ChainedHashTable# podpira operacije #add(x)#, #remove(x)#, 
  #find(x)#, v pričakovanem $O(1)$ času na operacijo.
  
  Poleg tega, da je začetna #ChainedHashTable# prazna, vsaka sekvenca od $m$ 
  #add(x)# in #remove(x)# operacije rezultira v skupni porabi $O(m)$ časa za
  vse klice na #grow()#.
\end{thm}

\section{#LinearHashTable#: Linearno naslavljanje}
\translatedby{Igor Plavšić,Edin Beganovic}{sl}

\index{LinearHashTable@#LinearHashTable#}%
Podatkovna struktura #ChainedHashTable# uporablja polje seznamov, kjer #i# 
seznam shrani vse elemente #x# tako da je $#hash(x)#=#i#$. Alternativa po imenu 
\emph{odprto nasljavljanje} 
\index{open addressing}%
je namenjena shranjevanju elementov neposredno v polje, #t#, z vsako lokacijo 
polja v #t# pa shrani največ eno vrednost. Tak pristop se uporablja v #LinearHashTable# 
in je opisan v tem poglavju. Ponekod je ta podatkovna struktura opisana 
kot \emph{odprto linearno naslavljanje}.
\index{linear probing}%

Glavna ideja #LinearHashTable# je da bi mi lahko, idealno, shranili element #x# 
z razpršilno vrednostjo #i=hash(x)# v lokacijo tabele #t[i]#. Če tega ne moremo 
storiti (ker je nek element že shranjen tam) potem ga skušamo shraniti v lokaciji $#t#[(#i#+1)\bmod#t.length#]$; če tudi to ni mogoče, potem poskusimo 
z $#t#[(#i#+2)\bmod#t.length#]$, in tako naprej, dokler ne najdemo mesta za #x#.
%str 113-114


\section{#LinearHashTable#: Linearno naslavljanje}
\translatedby{Igor Plavšić}{sl}
\subsection{Analysis of Linear Probing}


%strani 119/120
\translatedby{Tejo Ličen}{sl}
\begin{proof}
Če se začetek dolžine $k$ začne pri #i#, je natanko $k$
elementov $#x#_j$, ki so $#hash#(#x#_j)\in\{#i#,\ldots,#i#+k-1\}$.
Verjetnost za to je točno
\[
  p_k  = \binom{#q#}{k}\left(\frac{k}{#t.length#}\right)^k\left(\frac{#t.length#-k}{#t.length#}\right)^{#q#-k} \enspace ,
\]
ker za vsako izbiro $k$ elementov, teh $k$ elementov mora zgoščevati k eni izmed $k$ lokacij. Preostalih $#q#-k$ pa mora zgoščovati k preostalim $#t.length#-k$ lokacijam v tabeli.\footnote{Upoštevajte, da je $p_k$ večje kot verjetnost, da se izvajanje dolžine k začne pri #i#, ker definicija od $p_k$ ne upošteva pogoja $#t#[#i#-1]=#t#[#i#+k]=#null#$.}

V naslednji izpeljavi bomo pogoljufali in zamenjali $r!$ z
$(r/e)^r$. Stirlingova aproksimacija (\secref{factorials}) nam pove da je to le faktor $O(\sqrt{r})$ od pravilnosti. To naredimo zato, da si poenostavimo izpeljavo; \excref{linear-probing} od bralca zahteva, da natančneje in v celoti ponovi izračun z uporabo Stirlingove aproksimacije.

Vrednost $p_k$ je maksimalna, ko je #t.length# minimum in podatkovna struktura obdrži nespremnjen $#t.length# \ge 2#q#$, torej
\begin{align*}
   p_k & \le \binom{#q#}{k}\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} \\
  & = \left(\frac{#q#!}{(#q#-k)!k!}\right)\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} \\
  & \approx \left(\frac{#q#^{#q#}}{(#q#-k)^{#q#-k}k^k}\right)\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} && \text{[Stirlingova aproksimacija]} \\
  & = \left(\frac{#q#^{k}#q#^{#q#-k}}{(#q#-k)^{#q#-k}k^k}\right)\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} \\
 & = \left(\frac{#q#k}{2#q#k}\right)^k
     \left(\frac{#q#(2#q#-k)}{2#q#(#q#-k)}\right)^{#q#-k} \\
 & = \left(\frac{1}{2}\right)^k
     \left(\frac{(2#q#-k)}{2(#q#-k)}\right)^{#q#-k} \\
 & = \left(\frac{1}{2}\right)^k
     \left(1+\frac{k}{2(#q#-k)}\right)^{#q#-k} \\
 & \le \left(\frac{\sqrt{e}}{2}\right)^k \enspace .
\end{align*}
(V zadnjem koraku uporabimo neenakost $(1+1/x)^x \le e$, ki drži za vse $x>0$.).  Ker je $\sqrt{e}/{2}< 0.824360636 < 1$, dokaz lahko potrdimo.
\end{proof}

Uporaba \lemref{linear-probing} za dokaz zgornje meje na času izvajanja #find(x)#, #add(x)# in #remove(x)# je sedaj enostavna.  Upoštevaj najenostavnješi primer, kjer izvršimo #find(x)# za neko vrednost #x#, ki ni bila nikoli shranjena v #LinearHashTable#.  V tem primeru $#i#=#hash(x)#$ dobi naključno vrednost v $\{0,\ldots,#t.length#-1\}$, ki je neodvisna od vsebine #t#.  Če je #i# del izvajanja dolžine $k$, potem je čas izvajanja operacije #find(x)# v najboljšem primeru $O(1+k)$.  Potemtakem, zgornja meja pričakovanega časa izvajanja je
\[
  O\left(1 + \left(\frac{1}{#t.length#}\right)\sum_{i=1}^{#t.length#}\sum_{k=0}^{\infty} k\Pr\{\text{#i# is part of a run of length $k$}\}\right) \enspace .
\]
Upoštevajte, da vsako izvajanje dolžine $k$ prispeva k notranji vsoti $k$-krat za končni prispevek $k^2$,  torej lahko navedeno vsoto ponovno napišemo kot
\begin{align*}
  & { } O\left(1 + \left(\frac{1}{#t.length#}\right)\sum_{i=1}^{#t.length#}\sum_{k=0}^{\infty} k^2\Pr\{\mbox{#i# starts a run of length $k$}\}\right) \\
  & \le O\left(1 + \left(\frac{1}{#t.length#}\right)\sum_{i=1}^{#t.length#}\sum_{k=0}^{\infty} k^2p_k\right) \\
  & = O\left(1 + \sum_{k=0}^{\infty} k^2p_k\right) \\
  & = O\left(1 + \sum_{k=0}^{\infty} k^2\cdot O(c^k)\right) \\
  & = O(1) \enspace .
\end{align*}
Zadnji korak v tej izpeljavi prihaja iz dejstva, da $\sum_{k=0}^{\infty} k^2\cdot O(c^k)$ eksponentno zmanjšuje vrsto.\footnote{V večih vsebinah matematičnih terminologij nam ta vsota poda koeficient:  Obstaja pozitivno celo število $k_0$, ki velja za vse $k\ge k_0$, $\frac{(k+1)^2c^{k+1}}{k^2c^k} < 1$.}
Potemtakem lahko sklepamo, da je pričakovan čas izvajanja operacije #find(x)# za vrednost #x#, ki ni vsebovana v #LinearHashTable# enaka,  $O(1)$.

Če zanemarimo ceno operacije #resize()#, potem nam gornja analiza poda vse kar potrebujemo za analiziranje cene ostalih operacij v #LinearHashTable#.

Analiza gornje operacije #find(x)# velja pri operaciji #add(x)# kadar, #x# ni v tabeli.  Za analizo operacije #find(x)# kadar, #x# je vsebovan v tabeli moramo upoštevati samo to, da je vena enaka operaciji #add(x)# s katero smo dodali #x# v tabelo.  Za konec, cena operacije #remove(x)# je enaka ceni operacije #find(x)#.

V povzetku, če zanemarimo ceno klicev operacije #resize()#, so vse ostale operacije v #LinearHashTable# izvršene v $O(1)$ pričakovanega časa.  Da upoštevamo ceno operacije resize, lahko uporabimo enako amortizirano analizo izvedeno za #ArrayStack# podatkovno strukturo v \secref{arraystack}.



\subsection{Povzetek}
\translatedby{Igor Plavšić}{sl}
Spodnji izrek je povzetek časovnih zahtevnosti, metod, podatkovne strukture #LinearHashTable#:

\begin{thm}\thmlabel{linear-probing}
  #LinearHashTable# implementira vmesnik #USet#.  Če ignoriramo
  ceno klicev metode #resize()#, je pričakovana časovna zahtevnost metod 
  #add(x)#, #remove(x)#, in #find(x)#, podatkovne strukture #LinearHashTable#,
  enaka $O(1)$.  

  Če začenjamo z prazno #LinearHashTable#, velja, da za 
  katero koli zaporedje $m$ operacij metod #add(x)# in #remove(x)#, 
  porabimo $O(m)$ časa za klice metode #resize()#.
\end{thm}

\subsection{Tabelarno zgoščevanje}
\translatedby{Igor Plavšić}{sl}
\seclabel{tabulation}

\index{tabulation hashing}%
Med analizo podatkove strukture #LinearHashTable#, smo naredili zelo
močno predpostavko:  Da so za katero koli množico elementov, 
$\{#x_1#,\ldots,#x_n#\}$, zgoščevalne vrednosti $#hash(x_1)#,\ldots,#hash(x_n)#$
neodvisno in uniformno razporejene po množici $\{0,\ldots,#t.length#-1\}$.  
En način, kako to doseči je, da hranimo ogromno polje, #tab#, dolžine $2^{#w#}$,
kjer je vsak zapis naključno #w#-bitno celo število, neodvisno od vseh ostalih zapisov.  
Na ta način bi lahko implementirali #hash(x)#, tako da bi izbrali #d#-bitno celo število 
iz tabele #tab[x.hashCode()]#:
\codeimport{ods/LinearHashTable.idealHash(x)}

Na žalost, je hranjenje polja velikosti $2^{#w#}$ neoptimalna rešitev, 
kar se tiče prostorke porabe.  Pristop, ki ga uporablja 
\emph{tabulation hashing} je, da #w#-bitna cela števila obravnava kot 
cela števila, ki jih sestavljajo $#w#/#r#$ celih števil, ki imajo samo
$#r#$ bitov. Tako, pri tabelarnem zgoščevanju potrebujemo samo  $#w#/#r#$ 
polj velikosti $2^{#r#}$.  Vsi zapisi v teh poljih so neodvina #w#-bitna 
cela števila.  Da pridobimo vrednost #hash(x)#, razdelimo #x.hashCode()# 
v $#w#/#r#$ #r#-bitnih celih števil ter jih uporabimo kot indekse za polja.  
Nato vse te vrednosti združimo z bitnim operatorjem izključni-ali(XOR), 
da pridobimo #hash(x)#.
Spodnja programska koda prikazuje kako to deluje za $#w#=32$ in $#r#=4$:
\codeimport{ods/LinearHashTable.hash(x)}
V temu primeru je #tab# dvodimenzionalno polje s štirimi stolpci in $2^{32/4}=256$ vrsticami.

Enostavno lahko preverimo, da je, za poljubni #x#, #hash(x)# enakomerno razporejen 
čez $\{0,\ldots,2^{#d#}-1\}$.  Z malo dodatnega dela, lahko tudi preverimo, da ima 
poljubni par vrednosti, neodvisne zgoščene vrednosti. 
To pomeni, da bi se za implementacijo #ChainedHashTable#, namesto zgoščevalne funkcije - metode množenja 
uporabilo tabelatno zgoščevanje.

Dejstvo, da ima poljubna množica #n# različnih vrednosti množico #n# neodvisnih 
zgoščenih vrednosti ne velja.  Ne glede na to, pa velja, da ko uporabljamo tabelarno zgoščevanje, 
še vedno velja meja \thmref{linear-probing}.  
Reference za to lahko najdete na koncu tega poglavja.

% Podpoglavje 5.3
\section{Zgoščevalne vrednosti}
\translatedby{Andrej Rolih}{sl}

\index{Zgoščevalne vrednosti}%
Zgoščevalne tabele, ki smo si jih pogledali v prejšnjem podpoglavju se uporabljajo za povezovanje podatkov s celoštevilskimi ključi sestavljenimi iz #w# bitov. Velikokrat pa uporabljamo ključe, ki niso cela števila. Lahko so nizi znakov, objekti, tabele ali ostale sestavljene strukture. Da lahko uporabimo zgoščevalne funkcije na takih tipih podatkov moramo prej preslikati te podatke v #w#-bitne zgoščevalne vrednosti. Preslikave zgoščevalnih funkcij morajo imeti naslednje lastnosti:

\begin{enumerate}
  \item Če sta #x# in #y# enaka, potem morata biti enaka tudi #x.hashCode()# in #y.hashCode()# .

  \item Če #x# in #y# nista enaka, potem mora biti verjetnost, da sta
  $#x.hashCode()#=#y.hashCode()#$ majhna (blizu
  $1/2^{#w#}$).
\end{enumerate}

Prva lastnost nam zagotavlja, da če v zgoščevalni tabeli hranimo #x# in kasneje iščemo vrednost #y# (ki je enaka #x# ), da bomo našli #x# . Druga lastnost pa nam preprečuje izgubo podatkov pri pretvarjanju objektov v cela števila. Zagotavlja nam, da bodo različni objekti imeli različno zgoščevalno vrednost in bodo tako zelo verjetno shranjeni na različnih mestih v naši zgoščevalni tabeli. 

\subsection{Zgoščevalne vrednosti osnovnih podatkovnih tipov}

\index{Zgoščevalne vrednosti osnovnih podatkovnih tipov}%
Za majhne osnovne podatkovne tipe kot so #char#, #byte#, #int#, in #float# lahko ponavadi hitro najdemo zgoščevalno vrednost. Ti podatkovni tipi imajo vedno binarno predstavitev sestavljeno iz #w# ali manj bitov. \javaonly{(V Javi je, #byte# 8-bitni podatkovni tip in #float# 32-bitni.)}\cpponly{(V C++ #char# ponavadi 8-bitni in #float# 32-bitni.)} . V teh primerih te bite obravnavamo kot cela števila na intervalu $\{0,\ldots,2^#w#-1\}$ . Če sta dve vrednosti različni potem dobijo različni zgoščevalni vrednosti. Če sta vrednosti enaki pa dobita enako zgoščevalno vrednost.

Nekateri podatkovni tipi pa so sestavljeni iz več kot #w# bitov. Ponavadi $c#w#$ bitov za neko konstantno celo število $c$ . (V Javi sta #long# in #double# primera tipov pri katerih je $c=2$.) Te podatkovne tipe lahko obravnavamo kot  objekte sestavljene iz $c$ delov, kot je opisano v naslednjem podpoglavju.

\subsection{Zgoščevalne vrednosti sestavljenih podatkovnih tipov}
\seclabel{stringhash}

\index{Zgoščevalne vrednosti sestavljenih podatkovnih tipov}%
Za sestavljene objekte si želimo zgraditi zgoščevalno funkcijo, ki bi kombinirala zgoščevalne vrednosti podatkovnih tipov, ki ta objekt sestavljajo. Vendar pa to ni tako enostavno kot zveni. Kljub temu, da lahko najdemo kar nekaj bljižnic s katerimi to lahko naredimo (na primer sestavljanje zgoščevalnih vrednosti z operacijo XOR) pa to ni rešitev problema, saj lahko hitro pridemo do primerov kjer take bljižnice odpovedo (glej naloge ~\ref{exc:hash-hack-first}--\ref{exc:hash-hack-last}). A vendar obstajajo hitri in robustni načini reševanja tega problema, če si lahko privoščimo računanje z $2#w#$ bitno natančnostjo. Zamislimo si objekt sestavljen iz delov $P_0,\ldots,P_{r-1}$ katerih zgoščevalne vrednosti so $#x#_0,\ldots,#x#_{r-1}$. Potem si lahko izberemo neodvisna in naključna  #w#-bitna števila $#z#_0,\ldots,#z#_{r-1}$ in eno liho in naključno celo število #z# sestavljeno iz $2#w#$ bitov. Iz tega lahko izračunamo zgoščevalno vrednost za naš objekt na naslednji način:
\[
   h(#x#_0,\ldots,#x#_{r-1}) =  
   \left(\left(#z#\sum_{i=0}^{r-1} #z#_i #x#_i\right)\bmod 2^{2#w#}\right)
   \ddiv 2^{#w#} \enspace .
\]
%naslednji prevajalec naj nadaljuje od tu - vrstica 638


%delam od vrstice 754 do 824
\translatedby{Danilo Poje}{sl}
\begin{thm}\thmlabel{stringhash-eqlen}
  Vzemimo $#p#>2^{#w#}+1$ da je naravno število, vzemimo $#x#_0,\ldots,#x#_{r-1}$ in
  $#y#_0,\ldots,#y#_{r-1}$ vsako je sekvenca #w#-bit celih števil v
  $\{0,\ldots,2^{#w#}-1\}$ in predpostavimo $#x#_i \neq #y#_i$ za vsaj en indeks $i\in\{0,\ldots,r-1\}$. Potem
  \[
     \Pr\{ h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1}) \} 
          \le (r-1)/#p# \} \enspace .  
  \] 
\end{thm}

\begin{proof}
  Enačba $h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1})$
  je lahko napisana kot
  \begin{equation}  \eqlabel{strhash-eqlen}
    \left(
       (#x#_0-#y#_0)#z#^0+\cdots+(#x#_{r-1}-#y#_{r-1})#z#^{r-1} 
    \right)\bmod #p# = 0.
  \end{equation}
  Ker $#x_i#\neq #y_i#$, je ta polinom netrivialen. Potemtakem,
  po \thmref{prime-polynomial}, ima največ $r-1$ rešitev v #z#.
  Verjetnost, da izberemo #z#, ki je ena od teh rešitev, je potemtakem v najboljšem 
  primeru $(r-1)/#p#$.
\end{proof}

Opozorimo, da ima ta razpršitvena funkcija, prav tako opravka s primeri v katerih imata dve
sekvenci različno dolžino, čeprav je ena od sekvenc predpona drugi.
To je zaradi tega, ker ta funkcija efektivno razpršuje neskončno sekvenco
\[
  #x#_0,\ldots,#x#_{r-1}, #p#-1,0,0,\ldots \enspace .
\]
To zagotavlja, da če imamo dve sekvenci dolžine $r$ in $r'$
z $r > r'$, potem se ti dve sekvenci razlikujeta v indeksu $i=r$. V tem primeru
 \myeqref{strhash-eqlen} postane
\[
  \left(
     \sum_{i=0}^{i=r'-1}(#x#_i-#y#_i)#z#^i + (#x#_{r'} - #p# + 1)#z#^{r'}
     +\sum_{i=r'+1}^{i=r-1}#x#_i#z#^i + (#p#-1)#z#^{r}
  \right)\bmod #p# = 0 \enspace ,
\]
katero, po \thmref{prime-polynomial}, ima največ $r$ rešitev v $#z#$.
Skupaj z \thmref{stringhash-eqlen} to zadostuje za dokaz naslednjega bolj
splošnega teorema:

\begin{thm}\thmlabel{stringhash}
  Vzemimo $#p#>2^{#w#}+1$ da je naravno število, vzemimo $#x#_0,\ldots,#x#_{r-1}$ in
  $#y#_0,\ldots,#y#_{r'-1}$ , da sta unikatne sekvence #w#-bit celih števil v
  $\{0,\ldots,2^{#w#}-1\}$. Potem
  \[
     \Pr\{ h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1}) \} 
          \le \max\{r,r'\}/#p#  \enspace .  
  \] 
\end{thm}

Sledeči primer kode prikazuje kako je ta razpršitvena funkcija uporabljena na objektu, 
ki vsebuje polje #x#, ki vsebuje vrednosti:
\javaimport{junk/GeomVector.hashCode()}
\cppimport{ods/GeomVector.hashCode()}

Predstavljena koda žrtvuje nekaj verjetnosti kolizije zaradi implementacijske uporabnosti.
 Zlasti zaradi tega, ker aplicira multiplikativno razpršitveno funkcijo
iz \secref{multihash}, z $#d#=31$ za zmanjšanje #x[i].hashCode()# v 31-bit vrednost. 
To je zaradi tega, da seštevanje in množenje, ki sta narejena po operaciji modula 
naravnega števila $#p#=2^{32}-5$, se lahko izvede z uporabo nepodpisane 
63-bit aritmetike. Zaradi tega, je verjetnost dveh različnih sekvenc, od tega ima
daljša dolžino $r$, da imata enako razpršitveno kodo v najslabšem primeru
\[
    2/2^{31} + r/(2^{32}-5)
\]
za razliko od $r/(2^{32}-5)$ specificirano v \thmref{stringhash}.


% Podpoglavje 5.4, prevedeno od vrstice 902 do konca
\section{Razprave in primeri}
\translatedby{Mitja Zakrajšek}{sl}
Ideja \emph{multiplicative hashing}
\index{multiplicative hashing}%
\index{hashing!multiplicative}%
je zelo stara in je del zgoščevalne folklore \cite[Section~6.4]{k97v3}. Vendar je ideja, da izberemo množitelja #z# kot naključno \emph{sodo} število in analiza \secref{multihash}, zastarela po mnenju Dietzfelbingerja \etal\
\cite{dhkp97}.  Ta različica multiplikativnega zgoščevanja je ena od najpreprostejših, ampak njena verjetnost kolizije $2/2^{#d#}$ je za dva faktorja večja kot pri naključni funkciji $2^{#w#}\to
2^{#d#}$. \emph{multiply-add hashing}
\index{hashing!multiply-add}%
\index{multiply-add hashing}%
metoda uporablja funkcijo
\[
   h(#x#) = ((#z##x# + b) \bmod 2^{#2w#}) \ddiv 2^{#2w#-#d#}
\]
kjer sta #z# in #b# naključno izbrana iz $\{0,\ldots,2^{#2w#}-1\}$.
Zmnoži-dodaj zgoščevanje ima verjetnost kolizije samo $1/2^{#d#}$
\cite{d96}, ampak zahteva $2#w#$-bitne aritmetične operacije.

Obstaja kar nekaj metod za pridobivanje zgoščevalnih vrednosti iz zaporedja fiksne dolžine, vsebujoč #w#-bitnih celih števil. Še posebej hitra metoda
\cite{bhkkr99} je funkcija
\[\begin{array}{l}
  h(#x#_0,\ldots,#x#_{r-1}) \\
   \quad = \left(\sum_{i=0}^{r/2-1} ((#x#_{2i}+#a#_{2i})\bmod 2^{#w#})((#x#_{2i+1}+#a#_{2i+1})\bmod 2^{#w#})\right) \bmod 2^{2#w#}
\end{array}
\]
kjer je $r$ parno število in $#a#_0,\ldots,#a#_{r-1}$ naključno izbrani iz
$\{0,\ldots,2^{#w#}\}$. To ustvari $2#w#$-bitno zgoščevalno vrednost, katere možnost kolizije je $1/2^{#w#}$.  To se lahko zmanjša na #w#-bitno zgoščevalno vrednost z uporabo multiplikativne zgoščevalne funkcije. Ta metoda je hitra, ker zahteva samo $r/2$ $2#w#$-bitnih multiplikacij, metoda omenjena v \secref{stringhash} pa zahteva $r$ multiplikacij.
($\bmod$ operacije se dogajajo zaporedno z uporabo #w# in $2#w#$-bitne
aritmetične operacije za seštevanje in multiplikacije.)

Metoda iz \secref{polyhash}, ki uporablja polinome in polja praštevil za zgoščevanje tabel in nizov spremenljive dolžine je zastarela po mnenju Dietzfelbingerja \etal\
\cite{dgmp92}.  Zaradi njene uporabe $\bmod$ operatorja, ki se zanaša na potrošne strojne ukaze je na žalost počasna.
Nekatere različice te metode določijo praštevilo #p# iz obrazca $2^{#w#}-1$. V tem primeru se lahko operator $\bmod$ zamenja s prištevanjem (#+#) in logično in(#&#) operacijo \cite[Section~3.6]{k97v2}. Druga možnost je uporaba hitrejše metode za nize fiksne velikosti pri blokih dolžine $c$ za neko konstanto $c>1$ in potem metode s polji praštevil za zaporedje $\lceil r/c\rceil$ zgoščevalnih vrednosti.

\begin{exc}
  Nekatere univerze vsakemu študentu določijo študentsko številko, ko se prvič prijavijo za katerikoli predmet. Te številke so zaporedna cela števila, ki so se začela z 0 mnogo let nazaj in so sedaj zapisana že v milijonih. Recimo, da imamo razred stotih novih študentov in bi radi vsakemu študentu dodelili zgoščevalno vrednost, ki je odvisna od njihovih študentskih številk. Ali ima več smisla uporabiti prvi dve števki ali zadnji dve števki študentske številke? Pojasni svoj odgovor.
\end{exc}

\translatedby{Davor Vertelj, Lenč Skumavec}{sl}
\begin{exc}
  Upoštevajte zgoščevalno funkcijo iz odstavka \secref{multihash}, in predpostavite, da je
  $#n#=2^{#d#}$ and $#d#\le #w#/2$.
  \begin{enumerate}
    \item Pokažite, da za vsakega izbranega množitelja, #z#, obstajajo vrednosti #n#, ki imajo enako zgoščevalno vrednost. (Namig: Gre za preprosto rešitev, ki ne zahteva
nobene teorije števil).
    \item Glede na podanega množitelja, #z#, opišite tiste vrednosti  #n#, ki imajo enako
zgoščevalno vrednost. (Hint: Ta primer je zahtevnejši in zahteva poznavanje osnov teorije števil.)
  \end{enumerate}
\end{exc}

\begin{exc}
  Pokažite, da je meja dovoljene vrednosti $2/2^{#d#}$ v trditvi \lemref{universal-hashing} najboljša možna meja, če je $x=2^{#w#-#d#-2}$ in
  $#y#=3#x#$, then $\Pr\{#hash(x)#=#hash(y)#\}=2/2^{#d#}$.  (Namig: Poglejte si binarni prikaz za $#zx#$ in $#z#3#x#$ in upoštevajte dejstvo, da je $#z#3#x# = #z#x#+2#z#x#$.)
\end{exc}

\begin{exc}\exclabel{linear-probing}
  Dokažite trditev \lemref{linear-probing} z uporabo Stirlingove aproksimacije iz poglavja \secref{factorials}.
\end{exc}

\begin{exc}
  Upoštevajte spodnjo poenostavljeno verzijo kode za dodajanje elementa #x# v #LinearHashTable# (linearno razpršeno tabelo), ki element #x# shrani v
prvo polje v tabeli, ki vsebuje vrednost #null#. Opišite zakaj je ta način dodajanja elementov zelo počasen. Pokažite to na primeru zaporednega izvajanja operacij  $O(#n#)$ #add(x)#, #remove(x)#,
  in #find(x)#, ki za izvedbo porabijo $#n#^2$ časa.
\codeimport{ods/LinearHashTable.addSlow(x)}
\end{exc}

\begin{exc}
  Zgodnejše verzije metode Java #hashCode()# za razred #String# ni delovala
  tako, da bi uporabila vse znake v dolgem nizu. Naprimer, za 16 znakov dolg
  niz se je koda razpršitve izračunala glede na osem sodo indeksiranih znakov. 
  Na primeru pojasnite zakaj to ni bila pametna ideja. Primer naj sestoji
  iz večjega nabora nizov, pri čemer naj imajo vsi enako kodo razpršitve.
\end{exc}

\begin{exc}\exclabel{hash-hack-first}
  Predpostavite da imate objekt sestavljen iz dveh #w#-bitnih števil, #x# in #y#. 
  Pokažite zakaj $#x#\oplus#y#$ ni dobra koda razpršitve za vaš objekt. Pokažite tudi 
  primer večje množice objektov, kjer bi vsi imeli kodo razpršitve 0.
\end{exc}

\begin{exc}
  Predpostavite da imate objekt sestavljen iz dveh #w#-bitnih števil, #x# in #y#. 
  Pokažite zakaj $#x#+#y#$ ni dobra koda razpršitve za vaš objekt. Pokažite tudi 
  primer večje množice objektov, kjer bi vsi imeli enako kodo razpršitve.
\end{exc}

\begin{exc}\exclabel{hash-hack-last}
  Predpostavite da imate objekt sestavljen iz dveh #w#-bitnih števil, #x# in #y#. Predpostavite
  tudi, da je koda razpršitve za vaš objekt definirana z deterministično funkcijo $h(#x#,#y#)$, ki ustvari eno samo #w#-bitno število. Dokažite da obstaja večja množica objektov, ki 
  imajo enako kodo razpršitve.
\end{exc}

\begin{exc}
  Naj za neko pozitivno število #w# velja $p=2^{#w#}-1$. Razložite zakaj za pozitivno število 
  $x$ velja 
  \[
      (x\bmod 2^{#w#}) + (x\ddiv 2^{#w#}) \equiv x \bmod (2^{#w#}-1) \enspace .
  \]
  (Dobimo algoritem za računanje $x \bmod (2^{#w#}-1)$ s pomočjo zaporednega nastavljanja 
  \javaonly{\[
    #x = x&((1<<w)-1) + x>>>w#
  \]}
  \cpponly{\[
    #x = x&((1<<w)-1) + x>>w#
  \]}
  dokler ne velja $#x# \le 2^{#w#}-1$.)
\end{exc}

\begin{exc}
  Izberite neko pogostokrat uporabljeno implementacijo zgoščene tabele kot je recimo \javaonly{JavaCollection Framework #HashMap#}\cpponly{The C++ STL #unordered\_map#} ali #HashTable# oziroma #LinearHashTable# iz te knjige in napišite program, ki v to podatkovno strukturo shranjuje števila, #x#, tako da je časovna zahtevnost funkcije #find(x)# linearna. Se pravi, poiščite množico #n# števil v kateri je $c#n#$ elementov, katerih koda razpršitve je na isti lokaciji v tabeli.
  Odvisno od kvalitete implementacije boste to mogoče lahko dosegli že samo z natančnim pregledom kode ali pa boste morali napisati nekaj vrstic kode, ki bo poskušala z vstavljanjem in iskanjem elementov ter merjenjem časa za dodajanje in iskanje posameznih vrednosti. (To se lahko, se tudi že je, uporabi za napad DOS(denial of service) na strežnike \cite{cw03}.)
  \index{algorithmic complexity attack}%
\end{exc}