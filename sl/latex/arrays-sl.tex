\chapter{Izvedba seznama s poljem}
\chaplabel{arrays}
\translatedby{Jan Bratina}{sl}

V tem poglavju si bomo pogledali izvedbe vmesnikov #Seznama# in #Vrste#,
kjer je osnoven podatek hranjen v polju, imenovanem
\emph{podporno polje}.
\index{podporno polje}%
V spodnji tabeli imamo prikazane časovne zahtevnosti operacij za podatkovne strukture predstavljene v tem poglavju:
\newlength{\tabsep}
\setlength{\tabsep}{\itemsep}
\addtolength{\tabsep}{\parsep}
\addtolength{\tabsep}{-2pt}
\begin{center}
\vspace{\tabsep}
\begin{tabular}{|l|l|l|} \hline
& #get(i)#/#set(i,x)# & #add(i,x)#/#remove(i)# \\ \hline
#ArrayStack# & $O(1)$ & $O(#n#-#i#)$ \\
#ArrayDeque# & $O(1)$ & $O(\min\{#i#,#n#-#i#\})$ \\
#DualArrayDeque# & $O(1)$ & $O(\min\{#i#,#n#-#i#\})$ \\
#RootishArrayStack# & $O(1)$ & $O(#n#-#i#)$ \\ \hline
\end{tabular}
\vspace{\tabsep}
\end{center}
Podatkovne strukture, kjer podatke shranjujemo v enojno polje imajo veliko prednosti,
a tudi omejitev:
\index{arrays}%
\begin{itemize}
\item V polju imamo vedno konstantni čas za dostop do kateregakoli podatka.
To nam omogoča, da se operaciji #get(i)# in #set(i,x)# izvedeta v konstantnem času.

\item Polja niso dinamična. Če želimo vstaviti ali izbrisati element v sredini polja moramo premakniti veliko elementov, da naredimo prostor za novo vstavljen element oz. da zapolnimo praznino po tem, ko smo element izbrisali. Zato je časovna zahtevnost operacij #add(i,x)# in #remove(i)# odvisna od spremenljivk #n# in #i#.

\item Polja ne moremo širiti ali krčiti. Ko imamo večje število elementov, kot je veliko naše podporno polje, moramo ustvariti novo, dovolj veliko polje, v katerega kopiramo podatke iz prejšnjega polja. Ta operacija pa je zelo draga.
\end{itemize}
Tretja točka je zelo pomembna, saj časovne zahtevnosti iz zgornje tabele ne vključujejo spreminjanja velikosti polja. V nadaljevanju bomo videli, da širjenje in krčenje polja ne dodata veliko k \emph{povprečni} časovni zahtevnosti, če jih ustrezno upravljamo. Natančneje, če začnemo s prazno podatkovno strukturo in izvedemo zaporedje operacij $m$ #add(i,x)# ali #remove(i)#
,potem bo časovna zahtevnost širjenja in krčenja polja za $m$ operacij $O(m)$. Čeprav so nekatere operacije dražje je povprečna časovna zahtevnost nad vsemi $m$ operacijami samo $O(1)$ za operacijo.

\cpponly{
V tem poglavju in v celotni knjigi je priročno uporabljati polja, ki imajo števec za velikost. Navadna polja v C++ nimajo te funkcije, zato definiramo razred, #array#, ki hrani dolžino polja. Implementacija tega razreda je enostavna.
Implementiran je kot običajno C++ polje, #a#, in število, #length#:}
\cppimport{ods/array.a.length}
\cpponly{
Velikost polja #array# je določena od kreaciji:
}
\cppimport{ods/array.array(len)}
\cpponly{Elementi v polju so lahko indeksirani:}
\cppimport{ods/array.operator[]}
\cpponly{Na koncu, ko imamo eno polje dodeljeno drugemu, potrebujemo samo še premikanje kazalca, ki pa se izvede v konstantnem času:}
\cppimport{ods/array.operator=}

\section{#ArrayStack#: Izvedba sklada s poljem}
\seclabel{arraystack}

\index{ArrayStack@#ArrayStack#}%
Z operacijo #ArrayStack# implementiramo vmesnik za seznam z uporabo polja #a#, imenovanega the \emph{podporno polje}. Element v seznamu na indeksu #i# je hranjen v #a[i]#. V večini primerov je velikost polja #a# večja, kot je potrebno, zato uporabimo število #n# kot števec števila elementov spravljenih v polju #a#. Tako imamo elemente spravljene v
#a[0]#,\ldots,#a[n-1]# in v vseh primerih velja, $#a.length# \ge #n#$.

\codeimport{ods/ArrayStack.a.n.size()}

\subsection{Osnove}

Dostop in spreminjanje elementov v #ArrayStack# z uporabo operacij #get(i)#
in #set(i,x)# je zelo lahko. Po izvedbi potrebnih mejnih preverjanj polja vrnemo množico oz. #a[i]#.

\codeimport{ods/ArrayStack.get(i).set(i,x)}

Operaciji vstavljanja in brisanja elementov iz #ArrayStack#
sta predstavljeni v \figref{arraystack}. Za implementacijo #add(i,x)#
operacije najprej preverimo če je polje #a# polno. Če je, kličemo metodo #resize()# za povečanje velikosti polja #a#. Kako je metoda #resize()#
implementirana, si bomo pogledali kasneje, saj nas trenutno zanima samo to, da potem, ko kličemo metodo #resize()# še vedno ohranjamo pogoj $#a.length#
> #n#$. Sedaj lahko premaknemo elemente
$#a[i]#,\ldots,#a[n-1]#$ za ena v desno, da naredimo prostor za #x#,
množico #a[i]# spravimo v #x# in povečamo #n#, saj smo vstavili nov element.

\begin{figure}
\begin{center}
\includegraphics[scale=0.90909]{figs/arraystack}
\end{center}
\caption[Dodajanje elementa v ArrayStack]{Zaporedje operacij #add(i,x)# in #remove(i)# v #ArrayStack#. Puščice označujejo elemente, ki jih je potrebno kopirati. Operacije, po katerih moramo klicati metodo #resize()# so označene z zvezdico.}
\figlabel{arraystack}
\end{figure}

\codeimport{ods/ArrayStack.add(i,x)}
Če zapostavimo časovno zahtevnost ob morebitnem klicanju metode #resize()#, potem je časovna zahtevnost operacije #add(i,x)# sorazmerna številu elementov, ki jih moramo premakniti, da naredimo prostor za novo vstavljen element #x#. Zato je časovna zahtevnost operacije (zanemarimo časovno zahtevnost spreminjanja polja #a#) $O(#n#-#i#)$.

Implementacija operacije #remove(i)# je zelo podobna. Premaknemo elemente
$#a[i+1]#,\ldots,#a[n-1]#$ za ena v levo (prepišemo #a[i]#) in zmanjšamo vrednost #n#. Potem preverimo, če števec #n# postaja občutno manjši kot #a.length# s preverjanjem $#a.length# \ge 3#n#$. Če je občutno manjši kličemo metodo #resize()# za zmanjšanje velikosti polja #a#.

\codeimport{ods/ArrayStack.remove(i)}
% TODO: Add shifting figure
Če zanemarimo časovno zahtevnost metode #resize()# je časovna zahtevnost operacije #remove(i)#
sorazmerna s številom elementov, ki jih moramo premakniti. To pomeni, da je časovna zahtevnost $O(#n#-#i#)$.

\translatedby{Luka Zorc}{sl}
\subsection{Večanje in krčenje}

Metoda #resize()# je dokaj enostavna; alocira novo polje #b# velikosti $2#n#$ in skopira #n# elementov iz polja #a# v
prvih #n# mest polja #b# in nato postavi #a# v #b#. Tako po klicu #resize()#, $#a.length# = 2#n#$.

\codeimport{ods/ArrayStack.resize()}

Analiza cene operacije #resize()# je lahka. Metoda naredi polje #b# velikosti $2#n#$ in kopira #n# elementov iz #a#
v #b#. To traja $O(#n#)$ časa.

Pri analizi časa delovanja iz prejšnjega poglavja ni bila všteta cena klica #resize()# funkcije.
V tem poglavju bomo analizirali to ceno z uporabo tehnike znane pod imenom \emph{amortizirana analiza}.
Ta način ne poskuša ugotoviti cene za spreminjanje velikosti med vsako #add(i,x)#
in #remove(i)# operacijo. Namesto tega, se posveti ceni vseh klicev
#resize()# med zaporedjem $m$ klicev funkcije #add(i,x)# ali #remove(i)#.

Predvsem pokažemo:

\begin{lem}\lemlabel{arraystack-amortized}
Če je ustvarjen prazen #ArrayList# in katerokoli zaporedje, ko je $m\ge 1$ kliče #add(i,x)# ali #remove(i)# potem je skupen porabljen čas za vse klice #resize()# enak $O(m)$.
\end{lem}

\begin{proof}
Pokazali bomo, da vsakič ko je klican #resize()#, je število klicev #add# ali #remove# od zadnjega klica #resize()# funkcije, vsaj
$#n#/2-1$. Torej, če $#n#_i$ označuje vrednost #n# med
$i$tim klicem metode #resize()# in $r$ označuje število klicev funkcije
#resize()#, potem je skupno število klicev #add(i,x)# ali
#remove(i)# vsaj
\[
\sum_{i=1}^{r} (#n#_i/2-1) \le m \enspace ,
\]
kar je enako kot
\[
\sum_{i=1}^{r} #n#_i \le 2m + 2r \enspace .
\]
Na drugi strani, je skupno število časa uporabljenega med vsem #resize()# klici enako
\[
\sum_{i=1}^{r} O(#n#_i) \le O(m+r) = O(m) \enspace ,
\]
ker $r$ ni več kot $m$. Vse kar nam ostane je pokazati, da je število klicev #add(i,x)# ali #remove(i)# med $(i-1)$tim
in $i$tim klicem za #resize()# enako vsaj $#n#_i/2$.

Upoštevati moramo dva primera. V prvem primeru, je bila metoda #resize()# klicana
s strani funkcije #add(i,x)#, ker je bilo polje #a# polno, t.j.,
$#a.length# = #n#=#n#_i$. Gledano na prejšnji klic funkcije #resize()#:
je bila velikost #a#-ja po klicu enaka #a.length#, vendar je bilo število
elementov shranjenih v #a#-ju največ $#a.length#/2=#n#_i/2$.
Zdaj pa je število elementov shranjenih v #a# enako $#n#_i=#a.length#$,
torej se je moralo, od prejšnjega klica #resize()# izvesti vsaj $#n#_i/2$ klicev #add(i,x)#.
% TODO: Add figure
Drugi primer se zgodi, ko je #resize()# klicana s strani funkcije
#remove(i)#, ker je $#a.length# \ge 3#n#=3#n#_i$. Enako kot prej
je po prejšnjemu klicu #resize()# bilo število elementov shranjenih
v #a# najmanj $#a.length/2#-1$.\footnote{${}-1$ v tej formuli pomeni
poseben primer ko je $#n#=0$ in $#a.length# = 1$.} Zdaj pa je v #a#
shranjenih $#n#_i\le#a.length#/3$ elementov.
Zato je število #remove(i)# operacij od zadnjega #resize()# klica vsaj
\begin{align*}
R & \ge #a.length#/2 - 1 - #a.length#/3 \\
& = #a.length#/6 - 1 \\
& = (#a.length#/3)/2 - 1 \\
& \ge #n#_i/2 -1\enspace .
\end{align*}
V vsakem primeru je število klicev #add(i,x)# ali #remove(i)#, ki se
zgodijo med $(i-1)$tim klicem za #resize()# in $i$tim klicem za
#resize()# je natanko toliko $#n#_i/2-1$ , kot je tudi potrebno za
dokončanje dokaza.
\end{proof}

\subsection{Povzetek}

Naslednji izrek povzema učinkovitost izvedbe podatkovne strukture #ArrayStack#:

\begin{thm}\thmlabel{arraystack}
#ArrayStack# implementira #List# vmesnik. Z ignoriranjem cene klicev funkcije
#resize()# #ArrayStack# podpira naslednje operacije:
\begin{itemize}
\item #get(i)# in #set(i,x)# v času $O(1)$ a eno operacijo; in
\item #add(i,x)# in #remove(i)# v času $O(1+#n#-#i#)$ na operacijo.
\end{itemize}
Poleg tega, če začnemo z prazno strukturo #ArrayStack# in potem izvajamo katerokoli
zaporedje od $m$ #add(i,x)# in #remove(i)# operacij privede v skupno $O(m)$
časa uporabljenega med vsem klici funkcije #resize()#.
\end{thm}

#ArrayStack# je učinkovit način za implementiranje #Sklada#.
Funkcijo #push(x)# lahko implementiramo kot #add(n,x)# in funkcijo #pop()#
kot #remove(n-1)#, V tem primeru bodo te operacije potrebovale $O(1)$
amortiziranega časa.

\section{#FastArrayStack#: Optimiziran ArrayStack}
\seclabel{fastarraystack}

\index{FastArrayStack@#FastArrayStack#}%
#ArrayStack# opravi večino dela z zamenjevanjem (s
#add(i,x)# in #remove(i)#) in kopiranjem (z #resize()#) podatkov.
V izvedbah prikazanih zgoraj, je bilo to narejeno s pomočjo #for#
zanke. Izkaže se, da ima veliko programskih okolij posebne funkcije,
ki so zelo učinkovite pri kopiranju in premikanju blokov podatkov.
V programskem jeziku C, obstajajo funkcije #memcpy(d,s,n)# in #memmove(d,s,n)#.
V C++ jeziku je #std::copy(a0,a1,b)# algoritem.
V Javi je metoda #System.arraycopy(s,i,d,j,n)#.
\index{memcpy@#memcpy(d,s,n)#}%
\index{std::copy@#std::copy(a0,a1,b)#}%
\index{System.arraycopy@#System.arraycopy(s,i,d,j,n)#}%

\codeimport{ods/FastArrayStack.add(i,x).remove(i).resize()}

Te funkcije so ponavadi zelo optimizirane in lahko uporabljajo tudi posebne strojne ukaze,
ki lahko kopirajo veliko hitreje, kot z uporabo zanke #for#.
Vseeno s pomočjo teh funkcij ne moremo asimptotično zmanjšati izvajalnih časov,
a je ta optimizacija še vedno koristna.
V \lang\ izvedbah Jave, uporaba nativnega
\javaonly{#System.arraycopy(s,i,d,j,n)#}
povzroči pohitritve za faktor med 2 in 3, odvisno od vrste izvajanih operacij.
Izvajane pohitritve se lahko razlikujejo od sistema do sistema.


\translatedby{Jan Tomšič}{sl}
\section{#ArrayQueue#: Vrsta na osnovi polja}
\seclabel{arrayqueue}

\index{ArrayQueue@#ArrayQueue#}%
V tem poglavju bomo predstavili podatkovno strukturo #ArrayQueue#, ki implementira FIFO vrsto; elemente iz vrste odstranjujemo (z uporabo operacije #remove()#) v istem vrstnem redu, kot so bili dodani (z uporabo operacije #add(x)#).

Opazimo, da #ArrayStack# ni dobra izbira za izvedbo FIFO vrste in sicer zato, ker moramo izbrati en konec seznama, na katerega dodajamo elemente, nato pa elemente odstranjujemo z drugega konca. Ena izmed operacij mora delovati na glavi seznama, kar vključuje klicanje #add(i,x)# ali #remove(i)#, kjer je vrednost $#i#=0$. To nudi čas izvajanja sorazmeren #n#.

Da bi dosegli učinkovito implementacijo vrste na osnovi seznama, najprej opazimo, da bi bil problem enostaven, če bi imeli neskočno veliko polje #a#. Lahko bi hranili indeks #j#, ki hrani naslednji element za odstranitev ter celo število #n#, ki šteje število elementov v vrsti. Elementi vrste bi bili vedno shranjeni v \[ #a[j]#,#a[j+1]#,\ldots,#a[j+n-1]# \enspace . \]
Sprva bi bila #j# in #n# nastavljena na 0. Na novo dodan element bi uvrstili v #a[j+n]# in povečali #n#. Za odstranitev elementa bi ga odstranili iz #a[j]#, povečali #j# in zmanjšali #n#.

Težava te rešitve je potreba po neskončno velikem polju. #ArrayQueue# to simulira z uporabo končnega polja in \emph{kongruence}.
\index{kongruenca}%
To je vrsta aritmetike, ki jo uporabljamo pri izračunu časa. Na primer 10:00 plus pet ur je 3:00. Formalno pravimo, da je
\[
10 + 5 = 15 \equiv 3 \pmod{12} \enspace .
\]
Zadnji del enačbe beremo kot ``15 je skladno s 3 po modulu 12.'' Operator $\bmod$ lahko obravnavamo tudi kot binarni operator, da je
\[
15 \bmod 12 = 3 \enspace .
\]

V splošnem je za celo število $a$ in pozitivno celo število $m$, $a \bmod m$ enolično celo število $r\in\{0,\ldots,m-1\}$ tako, da velja $a = r + km$ za poljubno celo število $k$. Poenostavljeno vrednost $r$ predstavlja ostanek pri deljenju $a$ z $m$. V večini programskih jezikov, vključno \javaonly{z Javo}\cpponly{s C++}, je operator $\bmod$ predstavljen z znakom #%#.\footnote{Temu včasih rečemo operator \emph{brain-dead}, ker nepravilno implementira matematični operator mod, ko je prvi argument negativno število.}

Modularna aritmetika je uporabna za simulacijo neskončno velikega polja, ker $#i#\bmod #a.length#$ vedno vrne vrednost na intervalu $0,\ldots,#a.length-1#$. Z uporabo kongruence lahko elemente vrste shranimo na naslednja mesta v polju
\[ #a[j%a.length]#,#a[(j+1)%a.length]#,\ldots,#a[(j+n-1)%a.length]#
\enspace. \]
To obravnava polje #a# kot \emph{krožno polje}
\index{krožno polje}%
\index{polje!krožno}%
kjer polje indekse večje kot $#a.length#-1$ ``ovije naokrog'' na začetek polja.
% TODO: figure

Paziti moramo le še, da število elementov v #ArrayQueue# ne preseže velikosti #a#.

\codeimport{ods/ArrayQueue.a.j.n}

Zaporedje operacij #add(x)# in #remove()# nad #ArrayQueue# je prikazano na \figref{arrayqueue}. Za izvedbo #add(x)# moramo najprej preveriti, če je #a# poln, in s klicem #resize()# velikost #a# povečati. Nato #x# shranimo v #a[(j+n)%a.length]# in povečamo #n#.

\begin{figure}
\begin{center}
\includegraphics[scale=0.90909]{figs/arrayqueue}
\end{center}
\caption[Dodajanje in odstranjevanje iz ArrayQueue]{Zaporedje operacij #add(x)# in #remove(i)# nad #ArrayQueue#. Puščice označujejo kopiranje elementov. Operacije, ki se zaključijo s klicem #resize()# so označene z zvezdico.}
\figlabel{arrayqueue}
\end{figure}



\codeimport{ods/ArrayQueue.add(x)}

Za izvedbo #remove()# moramo najprej za kasnejšo rabo shraniti #a[j]#. Nato zmanjšamo #n# in povečamo #j# (po modulu #a.length#) tako, da nastavimo $#j#=(#j#+1)\bmod #a.length#$. Na koncu vrnemo shranjeno vrednost #a[j]#. Po potrebi lahko zmanjšamo velikost #a# s klicem #resize()#.

\codeimport{ods/ArrayQueue.remove()}

Operacija #resize()# je zelo podobna operaciji #resize()# pri #ArrayStack#. Dodeli novo polje #b# velikosti $2#n#$ in prepiše
\[
#a[j]#,#a[(j+1)%a.length]#,\ldots,#a[(j+n-1)%a.length]#
\]
na
\[
#b[0]#,#b[1]#,\ldots,#b[n-1]#
\]
in nastavi $#j#=0$.

\codeimport{ods/ArrayQueue.resize()}

\subsection{Povzetek}

Naslednji izrek povzema učinkovitost podatkovne strukture #ArrayQueue#:

\begin{thm}
#ArrayQueue# implementira vmesnik (FIFO) #Vrste#. Če izvzamemo ceno klica #resize()#, omogoča #ArrayQueue# izvajanje operacij #add(x)# in #remove()# v času $O(1)$ na operacijo. Poleg tega, začenši s prazno vrsto #ArrayQueue#, vsako zaporedje $m$ operacij #add(i,x)# in #remove(i)# porabi skupno $O(m)$ časa za vse klice #resize()#.
\end{thm}

%TODO: Discuss the use of bitwise-and as a replacement for the mod operator

\section{#ArrayDeque#: Hitra obojestranska vrsta z uporabo polja}
\seclabel{arraydeque}

\index{ArrayDeque@#ArrayDeque#}%
Struktura #ArrayQueue# iz prejšnjega poglavja je podatkovna struktura za predstavitev zaporedja, ki omogoča učinkovito dodajanje na en konec in odstranjevanje z drugega konca. Podatkovna struktura #ArrayDeque# pa omogoče tako učinkovito dodajanje kot tudi odstranjevanje z obeh koncev. Ta struktura implementira vmesnik #List# z uporabo enake tehnike krožnega polja, ki je uporabljena pri #ArrayQueue#.

\codeimport{ods/ArrayDeque.a.j.n}

Operaciji #get(i)# in #set(i,x)# nad #ArrayDeque# sta enostavni. Vrneta oziroma nastavita element polja $#a[#{#(j+i)#\bmod#a.length#}#]#$.

\codeimport{ods/ArrayDeque.get(i).set(i,x)}

Implementacija operacije #add(i,x)# je bolj zanimiva. Kot ponavadi, najprej preverimo, če je #a# poln in ga po potrebi povečamo s klicem #resize()#. Želimo, da je ta operacija hitra tako, ko je #i# majhen (blizu 0), kot tudi, ko je #i# velik (blizu #n#). Zato preverimo, če drži $#i#<#n#/2$. Če drži, zamaknemo elemente $#a[0]#,\ldots,#a[i-1]#$ za eno mesto v levo. Sicer ($#i#\ge#n#/2$), elemente $#a[i]#,\ldots,#a[n-1]#$ zamaknemo za eno mesto v desno. \figref{arraydeque} prikazuje operaciji #add(i,x)# in #remove(x)# nad #ArrayDeque#.

\begin{figure}
\begin{center}
\includegraphics[scale=0.90909]{figs/arraydeque}
\end{center}
\caption[Dodajanje in odstranjevanje iz ArrayDeque]{Zaporedje operacij #add(i,x)# in #remove(i)# nad #ArrayDeque#. Puščice označujejo prestavljanje elementov.}
\figlabel{arraydeque}
\end{figure}


\codeimport{ods/ArrayDeque.add(i,x)}

S prestavljanjem elementov na tak način zagotovimo, da #add(i,x)# nikoli ne potrebuje prestaviti več not $\min\{ #i#, #n#-#i# \}$ elementov. Čas izvajanja operacije #add(i,x)#, (če ignoriramo ceno operacije #resize()#), je potemtakem $O(1+\min\{#i#,#n#-#i#\})$.

Operacija #remove(i)# je izvedena podobno. Odvisno od $#i#<#n#/2$, #remove(i)# bodisi zamakne elemente $#a[0]#,\ldots,#a[i-1]#$ za eno mesto v desno, bodisi elemente $#a[i+1]#,\ldots,#a[n-1]#$ zamakne za eno mesto v levo. To spet pomeni, da #remove(i)# za zamik elementov nikoli ne potrebuje več kot $O(1+\min\{#i#,#n#-#i#\})$ časa.

\codeimport{ods/ArrayDeque.remove(i)}

\subsection{Povzetek}

Naslednji izrek povzema učinkovitost podatkovne strukture #ArrayDeque#:
\begin{thm}\thmlabel{arraydeque}
#ArrayDeque# implementira vmesnik #List#. Če izvzamemo ceno klica #resize()#, omogoča #ArrayDeque# izvajanje operacij
\begin{itemize}
\item #get(i)# in #set(i,x)# v času $O(1)$ na operacijo; in
\item #add(i,x)# in #remove(i)# v času $O(1+\min\{#i#,#n#-#i#\})$ na operacijo.
\end{itemize}
Poleg tega, začenši s prazno obojestransko vrsto #ArrayDeque#, vsako zaporedje $m$ operacij #add(i,x)# in #remove(i)# porabi skupno $O(m)$ časa za vse klice #resize()#.
\end{thm}

\section{#DualArrayDeque#: Gradnja obojestranske vrste z dveh skladov}
\seclabel{dualarraydeque}

\index{DualArrayDeque@#DualArrayDeque#}%
V sledečem poglavju bomo predstavili podatkovno strukturo #DualArrayDeque#, ki za dosego enakih meja učinkovitosti kot #ArrayDeque#, uporablja dve skladovni polji (#ArrayStack#). Čeprav ni asimptotična učinkovitost #DualArrayDeque# nič boljša kot pri #ArrayDeque#, je struktura vseeno zanimiva, ker nudi dober primer napredne strukture z združitvijo dveh enostavnih.

#DualArrayDeque# predstavlja seznam z uporabo dveh #ArrayStack#ov. Spomnimo se, da #ArrayStack# deluje hitro, ko operacije nad njim spreminjajo elementa z njegovega konca. #DualArrayDeque# sestoji iz dveh #ArrayStack#ov, enega #spredaj# (#front#) in enega #zadaj# (#back#), s konci nasproti, da to operacije hitre na obeh straneh.

\codeimport{ods/DualArrayDeque.front.back}

#DualArrayDeque# ne hrani eksplicitno števila elementov, #n#, ki jih vsebuje. Števila ni potrebno hraniti, saj vsebuje $#n#=#front.size()# + #back.size()#$ elementov. Vseeno pa bomo pri analizi #DualArrayDeque# uporabljali #n# za označevanje števila vsebovanih elementov.

\codeimport{ods/DualArrayDeque.size()}

#Sprednji# #ArrayStack# hrani seznam elementov z indeksi $0,\ldots,#front.size()#-1$, vendar jih hrani v obratnem vrstnem vredu. #Zadnji# #ArrayStack# pa hrani seznam elementov z indeksi $#front.size()#,\ldots,#size()#-1$ v običajnem vrstnem redu. Na tak način se #get(i)# in #set(i,x)# prevedeta v primerne klice #get(i)# ali #set(i)# na bodisi #sprednjem# ali #zadnjem# koncu, kar potrebuje $O(1)$ časa na operacijo.

\codeimport{ods/DualArrayDeque.get(i).set(i,x)}

Če je indeks $#i#<#front.size()#$, potem opazimo da ustreza elementu #spredaj# na položaju $#front.size()#-#i#-1$, ker so elementi #spredaj# shranjeni v obratnem vrstnem redu.

Dodajanje in odstranjevanje elementov iz #DualArrayDeque# je prikazano na sliki \figref{dualarraydeque}. Operacija #add(i,x)# doda element #spredaj# ali #zadaj#, odvisno od stanja:

\begin{figure}
\begin{center}
\includegraphics[scale=0.90909]{figs/dualarraydeque}
\end{center}
\caption[Dodajanje in odstranjevanje v DualArrayDeque]{Zaporedje operacij #add(i,x)# in #remove(i)# nad #DualArrayDeque#. Puščice označujejo prestavljanje elementov. Operacije, po katerih se seznam uravnoteži s klicem #balance()#, so označene z zvezdico.}
\figlabel{dualarraydeque}
\end{figure}



\codeimport{ods/DualArrayDeque.add(i,x)}

Metoda #add(i,x)# uravnoteži #sprednji# in #zadnji# #ArrayStack# s klicom metode #balance()#. Izvedba #balance()# je prikazana spodaj, za enkrat pa je dovolj, če vemo, da razen če je $#size()#<2$, #balance()# poskrbi za to, da se #front.size()# in #back.size()# ne razlikujeta več kot za faktor 3. Natančneje, $3\cdot#front.size()# \ge #back.size()#$ in $3\cdot#back.size()# \ge #front.size()#$.

Nato, analiziramo ceno metode #add(i,x)#, pri tem ne upoštevamo ceno klicev metode #balance()#. Če $#i#<#front.size()#$, potem se #add(i,x)# izvede s klicem na $#front.add(front.size()-i-1,x)#$.  Ker je #front# #ArrayStack# je cena tega
\begin{equation}
  O(#front.size()#-(#front.size()#-#i#-1)+1) = O(#i#+1) \enspace .
  \eqlabel{das-front}
\end{equation}
Po drugi strani pa, če drži $#i#\ge#front.size()#$, potem je #add(i,x)# implementirana kot $#back.add(i-front.size(),x)#$. Cena tega pa je
\begin{equation}
  O(#back.size()#-(#i#-#front.size()#)+1) = O(#n#-#i#+1) \enspace .
  \eqlabel{das-back}
\end{equation}

Opazimo, da se prvi primer \myeqref{das-front} pojavi, ko velja $#i#<#n#/4$.
Drugi primer \myeqref{das-back} se pojavi, ko velja $#i#\ge 3#n#/4$.  Kadar velja $#n#/4\le#i#<3#n#/4$, ne moremo biti prepričani ali delovanje vpliva na #front# ali #back#, ampak v vsakem primeru se postopek izvaja $O(#n#)=O(#i#)=O(#n#-#i#)$ časa, saj je $#i#\ge #n#/4$ in $#n#-#i#>#n#/4$.  Če povzamemo situacijo imamo
\[
     \mbox{Čas izvajanja } #add(i,x)# \le 
          \left\{\begin{array}{ll}
            O(1+ #i#) & \mbox{if $#i#< #n#/4$} \\
            O(#n#) & \mbox{if $#n#/4 \le #i# < 3#n#/4$} \\
            O(1+#n#-#i#) & \mbox{if $#i# \ge 3#n#/4$}
          \end{array}\right.
\]
Tako je čas izvajanja #add(i,x)#, če zanemarimo ceno klicev metode #balance()# sledeč $O(1+\min\{#i#, #n#-#i#\})$.

Metoda #remove(i)# in njene analize spominjajo na #add(i,x)# metodo.

\codeimport{ods/DualArrayDeque.remove(i)}

\subsection{Uravnoteženje}

Osredotočimo se na metodo #balance()# izvedeno z metodo #add(i,x)# in #remove(i)#.  Ta postopek zagotavlja, da niti #front# in niti #back# ne postaneta prevelika (ali premajhna). Zagotavlja, da razen, če obstajata manj kot dva elementa, tako #front# in #back# vsebujeta vsaj $#n#/4$ elementov. Če temu ni tako, potem se premika elemente med njima tako, da #front# in #back# vsebujeta natanko $\lfloor#n#/2\rfloor$ elementov in $\lceil#n#/2\rceil$ elementov.

\codeimport{ods/DualArrayDeque.balance()}

Če metoda #balance()# izvede uravnoteženje, potem premakne $O(#n#)$ elementov in za to potrebuje $O(#n#)$ časa. To je slabo zato, ker je metoda #balance()# klicana z vsakim #add(i,x)# in #remove(i)# klicem.  V vsakem primeruu, sledeč dokaz dokazuje, da metoda #balance()# v povprečju porabi samo konstantno količino časa na operacijo.

\begin{lem}\lemlabel{dualarraydeque-amortized}
Če ustvarimo prazen #DualArrayDeque#, potem zaporedje $m\ge 1$ izvede klice metode #add(i,x)# in #remove(i)#, potem je skupen porabljen čas za klice metode #balance()# $O(m)$.
\end{lem}

\begin{proof}
Dokazali bomo, da če metoda #balance()# premeša elemente, potem je število #add(i,x)# in #remove(i)# operacij vsaj $#n#/2-1$, od kar so bili elementi nazadnje premešani z metodo #balance()#.
Z dokazom v \lemref{arraystack-amortized} lahko dokažemo, da je skupen porabljen čas metode #balance()# $O(m)$.

Izvedli bomo našo analizo z uporabo tehnike, poznane kot \emph{potencialna metoda}.
  \index{potential}%
  \index{potential method}%
  Določimo \emph{potencialni} $\Phi$ za
  #DualArrayDeque# kot razliko v dolžini med #front# in #back#:
  \[  \Phi = |#front.size()# - #back.size()#| \enspace . \]
  Zanimiva stvar glede potenciala je, da klic metode #add(i,x)#
  ali #remove(i)#, ki ne opravi nobenega uravnoteženja, lahko poveča potencial skoraj največ za 1.


  Potrebno je upoštevati, da je takoj po klicu metode #balance()#, ki premeša elemente, potencial $\Phi_0$ največ 1, saj
  \[ \Phi_0 = \left|\lfloor#n#/2\rfloor-\lceil#n#/2\rceil\right|\le 1  \enspace .\]

Razmislite o trenutku takoj pred klicem funkcije #balance()#, ki premeša elemente in domnevajte, da #balance()# premeša elemente zaradi $3#front.size()# < #back.size()#$.
  To opazimo v sledečem primeru,
  \begin{eqnarray*}
   #n# & = & #front.size()#+#back.size()# \\
       & < & #back.size()#/3+#back.size()# \\
       & = & \frac{4}{3}#back.size()#
  \end{eqnarray*}
  Poleg tega je s časom potencial na tem mestu
  \begin{eqnarray*}
  \Phi_1 & = & #back.size()# - #front.size()# \\
      &>& #back.size()# - #back.size()#/3 \\
      &=& \frac{2}{3}#back.size()# \\
      &>& \frac{2}{3}\times\frac{3}{4}#n# \\
      &=& #n#/2
  \end{eqnarray*}
  Zato je število klicev metode #add(i,x)# ali #remove(i)#, od kar je metoda #balance()# nazadnje premešala elemente, najmanj $\Phi_1-\Phi_0 > #n#/2-1$. To zaključuje dokaz.
\end{proof}

\subsection{Povzetek}

Naslednji izrek povzame lastnosti #DualArrayDeque#:

\begin{thm}\thmlabel{dualarraydeque}
  #DualArrayDeque# implementira vmesnik #List#. Z ignoriranjem cene klicev metod #resize()# in #balance()# #DualArrayDeque# podpira operacije
  \begin{itemize}
    \item #get(i)# in #set(i,x)# v času $O(1)$ na operacijo; in
    \item #add(i,x)# in #remove(i)# v času $O(1+\min\{#i#,#n#-#i#\})$ na operacijo.
  \end{itemize}
  Poleg tega, če začnemo z praznim #DualArrayDeque#, potem zaporedje $m$ #add(i,x)# in #remove(i)# metod, konča z skupnim rezultatom $O(m)$ časa porabljenega med vsemi klici metod #resize()# in #balance()#.
\end{thm}

\translatedby{Tadej Mittoni}{sl}
\section{#RootishArrayStack#: Prostorsko učinkovit #ArrayStack#}
\seclabel{rootisharraystack}

\index{RootishArrayStack@#RootishArrayStack#}%
Ena izmed slabosti vseh prejšnjih podatkovnih struktur v tem poglavju je ta, da ker se shranjujejo podatki v eni ali dveh tabelah, ki se izogibajo spreminjanju velikosti, se pogosto zgodi, da so tabele precej prazne.
Na primer, takoj po operaciji #resize()# nad #ArrayStack#-om, je tabela #a# le na pol polna. Še huje, veliko je primerov, kjer samo $1/3$ tabele #a# vsebuje podatke.

Ta razdelek je namenjen podatkovni strukturi #RootishArrayStack#, ki se posveča problemu zapravljenega prostora. #RootishArrayStack# vsebuje #n# elementov z uporabo $O(\sqrt{#n#})$ tabel. V teh tabelah je največ $O(\sqrt{#n#})$ lokacij neuporabljenih v poljubnem času. Vse preostale lokacije v tabeli so uporabljene za shrambo podatkov. Potemtakem te podatkovne strukture zapravijo največ $O(\sqrt{#n#})$ prostora pri shranjevanju #n# elementov.

#RootishArrayStack# shrani svoje elemente v seznam #r# tabel poimenovanih \emph{blocks}, ki so oštevilčene $0,1,\ldots,#r#-1$. Glej \figref{rootisharraystack}. Blok $b$ vsebuje $b+1$ elemente, zato vsi #r# bloki vsebujejo največ 
\[
1+ 2+ 3+\cdots +#r# = #r#(#r#+1)/2
\]
elementov. Zgornja formula se izpelje kot je prikazano na \figref{gauss}.

\begin{figure}
\begin{center}
\includegraphics[width=\ScaleIfNeeded]{figs/rootisharraystack}
\end{center}
\caption[Dodajanje in odstranjevanje v RootishArrayStack]{Sekvenca #add(i,x)# in #remove(i)# operacij na #RootishArrayStack#. Puščice označujejo kopirane elemente.}
\figlabel{rootisharraystack}
\end{figure}

\codeimport{ods/RootishArrayStack.blocks.n}

\begin{figure}
\begin{center}
\includegraphics[scale=0.90909]{figs/gauss}
\end{center}
\caption{Število belih kvadratov je $1+2+3+\cdots+#r#$. Število osenčenih kvadratov je isto. Beli in osenčeni kvadrati skupaj tvorijo pravokotnik, ki vsebuje $#r#(#r#+1)$ kvadratov.}
\figlabel{gauss}
\end{figure}

Kot lahko pričakujemo, so elementi v seznamu razvrščeni po vrsti v bloku. Element v seznamu z indeksom 0 je shranjen v blok 0, elementa z indeksoma 1 in 2 sta shranjena v blok 1, elementi z indeksi 3, 4 in 5 so shranjeni v blok 2, itn. Glavni problem ki ga je potrebno nasloviti, je pri odločanju, ko nam je podan indeks $#i#$, kateri blok vsebuje tako #i#, kot tudi ustrezni indeks do #i# v samem bloku.

Določanje indeksa #i# v njegovem bloku se izkaže kot lahko. Če je indeks #i# v bloku #b#, potem je število elementov v blokih $0,\ldots,#b#-1$ $#b#(#b#+1)/2$. Potemtakem je #i# shranjen na lokaciji 
\[
#j# = #i# - #b#(#b#+1)/2
\]

v bloku #b#. Malo bolj zahteven je problem določanja vrednosti bloku #b#. Število elementov, ki ima indekse manj ali enake #i# je $#i#+1$. Na drugi strani pa je število elementov v blokih 0,\ldots,b, ki je enako $(#b#+1)(#b#+2)/2$. Potemtakem je #b# najmanjše število, ki še ustreza
\[
(#b#+1)(#b#+2)/2 \ge #i#+1 \enspace .
\]
To enačbo lahko preoblikujemo tako
\[
#b#^2 + 3#b# - 2#i# \ge 0 \enspace .
\]

Ustrezno kvadratna enačba $#b#^2 + 3#b# - 2#i# = 0$ ima dve rešitvi: $#b#=(-3 + \sqrt{9+8#i#}) / 2$ in $#b#=(-3 - \sqrt{9+8#i#}) / 2$.

Druga rešitev nima smisla za našo uporabo, ker da vedno negativno rešitev. Zato uporabimo $#b# = (-3 +
\sqrt{9+8i}) / 2$. V splošnem ta rešitev ni število, vendar če se vrnemo k naši neenakosti, hočemo najmanjšo število $#b#$, tako, da velja $#b# \ge (-3 + \sqrt{9+8i}) / 2$. To je preprosto 
\[
#b# = \left\lceil(-3 + \sqrt{9+8i}) / 2\right\rceil \enspace .
\]

\codeimport{ods/RootishArrayStack.i2b(i)}

Ko je to jasno, sta tudi metodi #get(i)# in #set(i,x)# jasni. Najprej izračunamo ustrezen blok #b# in ustrezen indeks #j# v bloku. Potem izvedemo primerno operacijo:

\codeimport{ods/RootishArrayStack.get(i).set(i,x)}

V primeru, da uporabimo katerokoli podatkovno strukturo v tem poglavju za zastopanje #blocks# seznam, potem se #get(i)# in #set(i,x)# izvajata v konstantnem času.

Metoda #add(i,x)# nam je že poznana. Najprej preverimo, če je naša podatkovna strukura polna tako, da je število blokov #r# tako, da drži $#r#(#r#+1)/2 = #n#$. Če je, pokličemo #grow()#, ki nam doda še en blok. Ko to naredimo, zamaknemo elemente z indeksi $#i#,\ldots,#n#-1$ v desno za eno pozicijo, da naredimo prostor za nov element z indeksom #i#:

\codeimport{ods/RootishArrayStack.add(i,x)}

Metoda #grow()# naredi pričakovano. Doda nov blok:

\codeimport{ods/RootishArrayStack.grow()}

Če ignoriramo ceno operacije #grow()#, potem je cena #add(i,x)# dominirana z vrednostjo zamikanja in je potemtakem enaka $O(1+#n#-#i#)$, kar je enako, kot pri #ArrayStack#.

Operacija #remove(i)# je podobna metodi #add(i,x)#. Le ta zamakne elemente z indeksi $#i#+1,\ldots,#n#$ levo za eno pozicijo. Za tem, če je več kot en blok še prazen, pokliče metodo #shrink()#, da odstrani vse, razen enega še ne uporabljenega bloka:

\codeimport{ods/RootishArrayStack.remove(i)}
\codeimport{ods/RootishArrayStack.shrink()}

Če spet ignoriramo ceno operacije #shrink()#, je cena #remove(i)# dominirana z vrednostjo zamikanja in je potemtakem enaka $O(#n#-#i#)$.

\subsection{Analiza rasti in krčenja}

Zgornja analiza #add(i,x)# in #remove(i)# ne vzema v zakup cene metodi #grow()# in #shrink()#. Upoštevajte, da metodi #grow()# in #shrink()# ne kopirata nobenih podatkov, kot to dela operacija #ArrayStack.resize()#, temveč le alocirajo ali izpraznijo tabelo velikosti #r#. V določenih okoljih se to zgodi v konstantnem času, dočim zna v drugih to zahtevati proporcionalen čas glede na #r#.

Takoj po klicu #grow()# ali #shrink()# se situacija počisti. Zanji blok je popolnoma prazen, vsi ostali pa so povsem zapolnjeni. Dodaten klic #grow()# ali #shrink()# se ne bo zgodil dokler vsaj $#r#-1$ elementov ni bilo dodanih ali odstranjenih. Četudi vzamejo #grow()# in #shrink()# $O(#r#)$ časa, je lahko vrednost cene #grow()# in #shrink()# amortizirana na $O(1)$ za vsako posamezno operacijo.

\subsection{Poraba prostora}
\seclabel{rootishspaceusage}

Sedaj bomo analizirali količino dodatnega prostora, ki ga uporablja #RootishArrayStack#. Bolj natančno, hočemo prešteti ves prostor, ki ga uporablja #RootishArrayStack# in le ta ni element tabele, ki je trenutno uporabljen za držanje elementa seznama. Takemu prostoru rečemo \emph{wasted space}.
\index{wasted space}%

Operacija #remove(i)# zagotavlja, da #RootishArrayStack# nikoli nima več kot dva zapolnjena bloka. Število blokov, #r#, uporabljenih s strani #RootishArrayStack#, ki imajo shranjenih #n# elementov potemtakem zadovoljijo
\[
(#r#-2)(#r#-1) \le #n# \enspace .
\]
Če uporabimo kvadratno enačbo nam da
\[
#r# \le (3+\sqrt{1+4#n#})/2 = O(\sqrt{#n#}) \enspace .
\]

Zadnje dva bloka sta velikosti #r# in #r-1#, zato je največ zapravljenega prostora $2#r#-1 = O(\sqrt{#n#})$. Če shranimo bloka v (npr.) #ArrayList#, ima potem #List#, ki shranjuje #r# bloke, $O(#r#)=O(\sqrt{#n#})$ zapravljenega prostora. Ostali prostor, ki ga potrebujemo za shrambo #n# in ostalih informacij je potemtakem $O(1)$. Skupaj je zapravljenega prostora v #RootishArrayStack# $O(\sqrt{#n#})$.

Nato trdimo, da je tak način uporabe prostora optimalen za katerokoli podatkovno strukturo, ki je na začetku prazna in podpira seštevanje enega elementa v določenem času. Bolj natančno smo zmožni prikazati, da v točno določenem času med seštevanjem #n# elementov, podatkovna struktura zapravlja vsaj $\sqrt{#n#}$ prostora (čeprav je to le za trenutek).

Predpostavimo, da začnemo s prazno podatkovno strukturo in dodamo #n# elementov vsakega posebej. Na koncu procesa je vseh #n# elementov shranjenih v strukturi in porazdeljenih med #r# kolekcijo spominskih blokov. Če velja $#r#\ge \sqrt{#n#}$, potem mora podatkovna struktura uporabljati #r# kazalcev (ali referenc), da sledi vsem #r# blokom. Te kazalci so zapravljen prostor. Na drugi strani če velja $#r# < \sqrt{#n#}$, potem morajo zaradi načela predalčkanja, določeni bloki biti vsaj $#n#/#r# > \sqrt{#n#}$ veliki. Vpoštevajoč moment v katerem je bil blok najprej alociran. Takoj po alociranju, je bil blok prazen in je zato zapravljal $\sqrt{#n#}$ prostora. Zaradi tega je bilo ob točno določenem času med vstavljanjem #n# elemntov, zapravljenega  $\sqrt{#n#}$ prostora s strani podatkovne strukture. 

\subsection{Povzetek}

Sledeč teorem povzema našo diskusijo o podatkovni strukturi #RootishArrayStack#:

\begin{thm}\thmlabel{rootisharraystack}
#RootishArrayStack# implementira vmesnik #List#. #RootishArrayStack# ignorira cene klicev metod #grow()# in #shrink()# ter podpira operacije
\begin{itemize}
\item #get(i)# in #set(i,x)# z $O(1)$ časom na operacijo; in
\item #add(i,x)# in #remove(i)# z $O(1+#n#-#i#)$ časom na operacijo.
\end{itemize}

Še več, če začnemo s praznim #RootishArrayStack#, bo katerakoli sekvenca $m$ #add(i,x)# in #remove(i)# operacij potrebovala v celoti $O(m)$ časa za vse klice teh dveh metod.

Prostor (merjen v besedah),\footnote{Spomnimo se \secref{model} za diskusijo kako se meri spomin.} ki ga #RootishArrayStack# porabi za shrambo #n# elementov, je $#n# +O(\sqrt{#n#})$.
\end{thm}

\subsection{Računanje Kvadratnih Korenov}

\index{square roots}%
Bralec ki je imel nekaj stika z modeli računanja, morda opazi da zgoraj opisan 
#RootishArrayStack#, ne spada v običajni model računanja besedni-RAM (\secref{model}, 
ker zahteva računanje kvadratnih korenov. Operacija kvadratnega korena ni 
smatrana za navadno operacijo in navadno ni del besednega-RAM modela.

V tej sekciji pokažemo, da se lahko implementacijo kvadratnega korena 
učinkovito implementira. Še posebej pokažemo, da  je vsako število
$#x#\in\{0,\ldots,#n#\}$, $\lfloor\sqrt{#x#}\rfloor$lahko izračunano 
v konstantnem-času, nato ko $O(\sqrt{#n#})$ predpriprava ustvari dve 
tabeli dolžine  $O(\sqrt{#n#})$. Sledeča lema kaže, da lahko zmanjšamo 
problem računanja kvadratnega korena spremenljivke #x# v kvadratni 
koren sorodne vrednosti #x'#.

\begin{lem}\lemlabel{root}
Naj bo $#x#\ge 1$ in $#x'#=#x#-a$, kjer je $0\le a\le\sqrt{#x#}$. Potem sledi da
$\sqrt{x'} \ge \sqrt{#x#}-1$.
\end{lem}

\begin{proof}
Zadostuje pokazati da
\[
\sqrt{#x#-\sqrt{#x#}} \ge \sqrt{#x#}-1 \enspace .
\]
Kvadriramo obe strani te neenačbe, da dobimo
\[
#x#-\sqrt{#x#} \ge #x#-2\sqrt{#x#}+1
\]
nato poračunamo do konca, da dobimo
\[
\sqrt{#x#} \ge 1
\]
kar drži za vsak $#x#\ge 1$.
\end{proof}

Začnemo tako, da malo omejimo problem in predpostavimo da je $2^{#r#} \le
#x# < 2^{#r#+1}$, tako da $\lfloor\log #x#\rfloor=#r#$, t.j., #x# je
število z $#r#+1$ biti v binarni predstavitvi števil. Uzamemo
$#x'#=#x# - (#x#\bmod 2^{\lfloor r/2\rfloor})$. Sedaj, #x'# zadošča
pogojem \lemref{root}, zato je $\sqrt{#x#}-\sqrt{#x'#} \le 1$.
Poleg tega ima #x'# vse spodnje $\lfloor #r#/2\rfloor$ bite
enake 0, zato obstaja samo ena
\[
2^{#r#+1-\lfloor #r#/2\rfloor} \le 4\cdot2^{#r#/2} \le 4\sqrt{#x#}
\]
od možnih vrednosti #x'#. To pomeni da lahko uporabimo tabelo, #sqrttab#,
ki shrani vrednost od $\lfloor\sqrt{#x'#}\rfloor$ za vsako možno vrednost 
spremenljivke #x'#. Bolj natančno, imamo
\[
#sqrttab#[i]
= \left\lfloor
\sqrt{i 2^{\lfloor #r#/2\rfloor}}
\right\rfloor \enspace .
\]
Na ta način je $#sqrttab#[i]$ znotraj dveh $\sqrt{#x#}$ za vsak
$#x#\in\{i2^{\lfloor r/2\rfloor},\ldots,(i+1)2^{\lfloor r/2\rfloor}-1\}$.
Drugače povedano, vhodni niz
$#s#=#sqrttab#[#x##>>#\lfloor #r#/2\rfloor]$ je bodisi enak
$\lfloor\sqrt{#x#}\rfloor$,
$\lfloor\sqrt{#x#}\rfloor-1$, ali
$\lfloor\sqrt{#x#}\rfloor-2$. S spremenljivko #s# lahko določimo vrednost
$\lfloor\sqrt{#x#}\rfloor$ s
povečevanjem #s# dokler
$(#s#+1)^2 > #x#$.
\codeimport{ods/FastSqrt.sqrt(x,r)}

Vendarle to deluje samo pri $#x#\in\{2^{#r#},\ldots,2^{#r#+1}-1\}$ in
#sqrttab# je posebna tabela, ki deluje samo za določeno vrednost 
$#r#=\lfloor\log #x#\rfloor$. Da to rešimo, lahko izračunamo
$\lfloor\log #n#\rfloor$ drugačnih #sqrttab# tabel, eno za vsako možno
vrednost odf $\lfloor\log #x#\rfloor$. Velikosti teh tabel oblikujejo eksponentno 
zaporedje, katerega največja vrednost je kvečjemu $4\sqrt{#n#}$, tako da 
skupna velikost vseh tabel je $O(\sqrt{#n#})$.

Kakorkoli, izkaže se, da ne potrebujemo več kot ene #sqrttab# tabele;
potrebujemo samo eno #sqrttab# tabelo za vrednost $#r#=\lfloor\log
#n#\rfloor$. Vsaka vrednost #x# z $\log#x#=#r'#<#r#$ je lahko \emph{upgraded}
z množenjem #x# z $2^{#r#-#r'#}$ in uporabo enačbe
\[
\sqrt{2^{#r#-#r'#}x} = 2^{(#r#-#r#')/2}\sqrt{#x#} \enspace .
\]
Količina $2^{#r#-#r#'}x$ je v obsegu
$\{2^{#r#},\ldots,2^{#r#+1}-1\}$ zato lahko pogledamo njen kvadratni koren
v #sqrttab#. Sledeča koda dopolni to idejo za izračun
$\lfloor\sqrt{#x#}\rfloor$ za vsa ne-negativna števila #x# v
obsegu $\{0,\ldots,2^{30}-1\}$ z uporabo tabele, #sqrttab#, velikosti $2^{16}$.
\codeimport{ods/FastSqrt.sqrt(x)}

Nekaj kar smo si vzeli za samoumnevno je vprašanje kako izračunati
$#r#'=\lfloor\log#x#\rfloor$.Spet, to je problem ki ga lahko rešimo z tabelo, 
#logtab#, velikosti $2^{#r#/2}$. V tem primeru je
koda še posebej enostavna, ker je $\lfloor\log #x#\rfloor$ samo kazalo
pomembnega 1 bita v binarni predstavitni #x#.
To pomeni, da za $#x#>2^{#r#/2}$, lahko premaknemo v desno bite od
#x# za $#r#/2$ pozicij, preden ga uporabimo za kazalo v  #logtab#.
Sledeča koda naredi to, z uporabo tabele #logtab# velikosti $2^{16}$ za izračun
$\lfloor\log #x#\rfloor$ za vse #x# v obsegu $\{1,\ldots,2^{32}-1\}$.
\codeimport{ods/FastSqrt.log(x)}

Nazadnje, z namenom dopolnitve vključimo sledečo kodo ki inicializira #logtab# in #sqrttab#:
\codeimport{ods/FastSqrt.inittabs()}

Za povzetek, izračuni ki so nastali od #i2b(i)# metode lahko implementiramo 
v konstantnem času na besednem-RAM z uporabo $O(\sqrt{n})$ dodatnega
spomina za shranjevanje #sqrttab# in #logtab# arrays. Te tabele lahko
obnovimo ko #n#narase ali se zmanjša za faktor ali dva in strošek te obnovitve 
je lahko amortiziran čez števila od #add(i,x)# and #remove(i)# operaciji, ki sta povzročili spremembo v 
#n# enako kot je strošek #resize()# analiziran v #ArrayStack# implementaciji.

\translatedby{Andra\v{z} Polanec}{sl}
\section{Razprava in vaje}

Ve\v{c}ina podatkovnih struktur, opisanih v tem poglavju je del folklore.
Njihove implementacije so stare tudi ve\v{c} kot 30 let. Na primer,
implementacije skladov, vrst in dvojnih vrst so lahko generalizirajo v
#ArrayStack#, #ArrayQueue# and #ArrayDeque# opisani v tej knjigi, razloži Knuth
\cite[Section~2.2.2]{k97v1}

Brodnik \etal\ \cite{bcdms99} je prvi opisal #RootishArrayStack# in dokazal
$\sqrt{n}$ spodnjo omejenost, kot v \secref{rootishspaceusage}. Prikazujejo tudi
druga\v{c}ne strukture, ki uporabljajo bolj sofisticirano izbiro velikosti
bloka, zato da se izognejo ra\v{c}unanju kvadratnih korenov v  #i2b(i)# metodi.
Znotraj njihove sheme, blok, ki vsebuje #i# je blok $\lfloor\log
(#i#+1)\rfloor$, ki je indeks vode\v{c}ega 1 bita v binarni representaciji
$#i#+1$. Nekatere ra\v{c}unalniške arhitekture imajo ukaz, ki izra\v{c}una
indeks vode\v{c}ega bita v integer-ju. \javaonly{ V
Java-i, #Integer# ima razred metodo #numberOfLeadingZeros(i)#
s katero se lahko izra\v{c}una $\lfloor\log (#i#+1)\rfloor$.}

Struktura sorodna #RootishArrayStack# je dvo-nivojski \emph{tiered-vector} of
Goodrich and Kloss \cite{gk99}.
\index{tiered-vector}%
Ta struktura omogo\v{c}a #get(i,x)# in #set(i,x)# operacije v konstantnem
\v{c}asu, operacije #add(i,x)# in #set(i,x)# pa v $O(\sqrt{#n#})$ \v{c}asu. Ti
\v{c}asi so podobni \v{c}asom, ki jih zmore bolj previdna implementacija
#RootishArrayStack# opisana v \excref{rootisharraystack-fast}.

\javaonly{
\begin{exc}
V implementaciji #ArrayStack#, po prvem klicu operacije 
#remove(i)#, interno polje #a#, vsebuje $#n#+1$ non-#null# vrednost kljub
dejstvu, da #ArrayStack# vsebuje samo #n# elementov. Kje se nahaja dodatna
non-#null# vrednost? Razmislite kak\v{s}ne so posledice te non-#null# vrednosti
 za nadzor pomnilnika v Java Runtime Environment-u.
\index{Java Runtime Environment}%
\index{memory manager}%
\end{exc}
}

\begin{exc}
Metoda #addAll(i,c)# v #List# vstavi vse elemente iz #Collection#
#c# v seznam na  pozicijo #i#. (Metoda #add(i,x)# je poseben primer, kjer je 
$#c#=\{#x#\}$.) Razlo\v{z}ite zakaj je za podatkovne strukture, opisane v tem
poglavju, neu\v{c}inkovito implementirati #addAll(i,c)# z zaporednimi klici
#add(i,x)#. Razvijte bolj u\v{c}inkovito implementacijo.
\end{exc}

\begin{exc}
Razvijte \emph{#RandomQueue#}.
\index{RandomQueue@#RandomQueue#}%
To je implementacija #Queue# vmesnika v kateri operacija #remove()# odstrani
naklju\v{c}en element izmed vseh elementov, ki so trenutno v vrsti (Razmislite
o #RandomQueue# kot o torbi, v katero lahko dodajamo elemente ali odstranimo
nnaklju\v{c}en element.). Operacije #add(x)# in #remove()# naj se v
#RandomQueue# izvajajo v konstantnem \v{c}asu.
\end{exc}

\begin{exc}
Razvijte #Treque# (trojna vrsta).
\index{Treque@#Treque#}%
To je implementacija vmesnika #List#,
v katerem se operacije #get(i)# and #set(i,x)# izvajajo v konstantnem \v{c}asu,
operacije #add(i,x)# in  #remove(i)# pa v \v{c}asu
\[
O(1+\min\{#i#, #n#-#i#, |#n#/2-#i#|\}) \enspace .
\]
Z drugimi besedami, modifikacije so hitre, \v{c}e so blizu kateremukoli koncu
ali \v{c}e so blizu sredine seznama.
\end{exc}

\begin{exc}
Implementirajte metodo #rotate(a,r)# tako da, ``rotira'' polje #a#,
tako da je #a[i]# premik v $#a#[(#i#+#r#)\bmod #a.length#]$, za vsak
$#i#\in\{0,\ldots,#a.length#\}$.
\end{exc}

\begin{exc}
Implementirajte metodo #rotate(r)# tako da ``rotira'' seznam #List#,
 tako da element #i# postane element seznama na $(#i#+#r#)\bmod #n#$. \v{C}e
 se izvaja na #ArrayDeque# ali #DualArrayDeque#, potem naj se metoda #rotate(r)#
 izvaja v \v{c}asu $O(1+\min\{#r#,#n#-#r#\})$.
\end{exc}

\begin{exc}
Popravite implementacijo #ArrayDeque# tako, da bo se premikanje, ki ga
spro\v{z}ijo operacije #add(i,x)#, #remove(i)#, and #resize()#, izvajalo hitreje
kot #System.arraycopy(s,i,d,j,n)# metoda.
\end{exc}

\begin{exc}
Popravite implementacijo #ArrayDeque# tako, da ne uporablja
#%# operatorja (na nekaterih sistemih po\v{c}asna operacija). Namesto tega 
naj se poslu\v{z}i dejstva, \v{c}e  je #a.length# potenca 2, potem
\[ #k%a.length#=#k&(a.length-1)# \enspace .
\]
(Operator #&# se tu smatra kot bitni.)
\end{exc}

\begin{exc}
Razvijte varijanto #ArrayDeque#, ki ne izvaja nobene modularne aritmetike.
Namesto tega so vsi podatki v zaporednem bloku, urejeno znotraj polja.
Ko podatki preplavijo za\v{c}etek ali konec tega polja, se spro\v{z}i prirejena
operacija #rebuild()#.
Amortizirana cena vseh operacij mora biti enaka kot #ArrayDeque#.

\noindent Namig: Ustreznost delovanja je tu povsem odvisna od tega, kako je
implementirana operacija #rebuild()#.
\v{Z}elja je, da operacija #rebuild()# postavi podatkovno strukturo v stanje, 
kjer podatki ne morejo zbe\v{z}ati, proti kateremukoli koncu, dokler se ne
izvede vsaj $#n#/2$ operacij.

Testirajte va\v{s}o implementacijo z primerjanjem performans z #ArrayDeque#.
Optimizirajte va\v{s}o implemetacijo (z uporabo #System.arraycopy(a,i,b,i,n)#)
 in preverite \v{c}e lahko deluje bolje kot implementacija #ArrayDeque# .
\end{exc}

\begin{exc}
Razvijte verzijo #RootishArrayStack#, ki ima samo 
$O(\sqrt{#n#})$ porabljenega prostora in lahko izvaja operacije #add(i,x)#,
 #remove(i,x)# v $O(1+\min\{#i#,#n#-#i#\})$ \v{c}asu.
\end{exc}

\begin{exc}\exclabel{rootisharraystack-fast}
Razvijte verzijo #RootishArrayStack#, ki ima samo $O(\sqrt{#n#})$ 
porabljenega prostora in lahko izvaja operacije #add(i,x)#, 
#remove(i,x)# v $O(1+\min\{\sqrt{#n#},#n#-#i#\})$
\v{c}asu. (Namig, glej \secref{selist}.)
\end{exc}

\begin{exc}
Razvijte verzijo #RootishArrayStack#, ki ima samo $O(\sqrt{#n#})$ porabljenega
prostora in lahko izvaja operacije #add(i,x)#, #remove(i,x)#
v $O(1+\min\{#i#,\sqrt {#n#},#n#-#i#\})$ \v{c}asu.
(Namig, glej \secref{selist}.)
\end{exc}

\begin{exc}
Razvijte #CubishArrayStack#.
\index{CubishArrayStack@#CubishArrayStack#}%
To je tri nivojska struktura, ki implementira #List# vmesnik, in
porabi $O(n^{2/3})$ prostora.
V tej strukturi se operacije #get(i)# in #set(i,x)# izvajajo v konstantnem
\v{c}asu; medtem ko se operacije #add(i,x)# in #remove(i)# izvajajo 
$O(#n#^{1/3})$ amortizirano.
\end{exc}
