\chapter{Zgoščevalne tabele}
\chaplabel{hashtables}
\chaplabel{hashing}
\translatedby{Matej Romih}{sl}
\translatedby{Aleš Lokovšek}{sl}
\translatedby{Ariel David Jančar}{sl}
Zgoščevalne tabele predstavljajo učinkovito metodo za shranjevanje majhnega števila celih števil
#n#, iz velikega obsega $U=\{0,\ldots,2^{#w#}-1\}$.
Izraz \emph{zgoščevalna tabela}
\index{Zgoščevalna tabela}%
sicer označuje širok spekter podatkovnih struktur. 
Prvi del poglavja se osredotoča na dve najbolj pogosti implementaciji: zgoščevanje z veriženjem in linearno naslavljanje.

Zelo pogosto se uporabljajo za shranjevanje podatkov, katerih
tip niso cela števila.
V tem primeru je celoštevilska \emph{zgoščevalna koda}
\index{zgoščevalna koda}%
povezana z vsako podatkovno enoto in uporabljena v zgoščevalni tabeli. 
Drugi del predstavi, kako so zgoščevalne kode ustvarjene.

Nekatere uporabljene metode iz tega poglavja potrebujejo naključno izbrana števila v določenem razponu.
V primerih kode, so nekatera ``naključna'' cela števila
enolično določena z uporabo naključnih bitov generiranih iz atmosferskega šuma.

\section{Zgoščevalna tabela z veriženjem}
\seclabel{hashtable}
Podatkovna struktura zgoščevalna tabela z veriženjem za shranjevanje tabele t seznamov uporablja zgoščevanje z veriženjem. Za hranjenje skupnega števila podatkov v vseh seznamih se uporablja celo število n.
(glej \figref{chainedhashtable}):
\codeimport{ods/ChainedHashTable.t.n}

\begin{figure}
   \begin{center}
     \includegraphics[width=\ScaleIfNeeded]{figs/chainedhashtable}
   \end{center}
   \caption[A ChainedHashTable]{Primer zgoščevalne tabele z veriženjem z $#n#=14$ in $#t.length#=16$.  V tem primeru je $#hash(x)#=6$}
   \figlabel{chainedhashtable}
\end{figure}

\emph{Zgoščena vrednost} podatkovnega elementa #x#, označena z #hash(x)# predstavlja vrednost v razponu $\{0,\ldots,#t.length#-1\}$. Vsi podatki z zgoščeno vrednostjo #i#
so shranjeni v seznamu na lokaciji #t[i]#.  Da se izognemo prevelikim 
seznamom, ohranjamo invarianto
\[
    #n# \le #t.length#
\]
tako da je povprečno število elementov shranjenih v posameznem seznamu
$#n#/#t.length# \le 1$.

Pri dodajanju elementa #x#, v zgoščevalno tabelo, najprej preverimo če je potrebno povečati #t.length#. V kolikor je to potrebno ga povečamo.
Potem razpršimo #x#, da dobimo število #i#, v razponu $\{0,\ldots,#t.length#-1\}$, in pripnemo #x# seznamu #t[i]#:
\codeimport{ods/ChainedHashTable.add(x)}
Povečevanje tabele, v kolikor je le-to potrebno, vključuje podvojitev dolžine tabele #t# in ponovno vstavljanje elementov vanjo. Ta strategija je popolnoma enaka kot pri implementaciji
ArrayStacka in tudi tu velja enako pravilo: Cena rasti je amortizirano po nekaj sekvencah vstavljanja  samo konstantna (glej~\lemref{arraystack-amortized} na strani~\pageref{lem:arraystack-amortized}).

Poleg rasti je edino potrebno opravilo ob vstavljanju nove vrednosti #x# v zgoščevalno tabelo z veriženjem dodajanje #x#-a seznamu #t[hash(x)]#. Za katerokoli od implementacij seznama 
opisanih v poglavjih~\ref{chap:arrays}
in \ref{chap:linkedlists}, potrebujemo le konstanten čas.

Za odstranitev elementa #x# iz zgoščevalne tabele se sprehodimo čez seznam #t[hash(x)]#, dokler n najdemo elementa #x#, tako da ga lahko odstranimo:
\codeimport{ods/ChainedHashTable.remove(x)}
Časovna zahtevnost je $O(#n#_{#hash(x)#})$, pri čemer  $#n#_{#i#}$ označuje dolžino seznama shranjenega v #t[i]#.

Iskanje elementa #x# v zgoščevalni tabeli poteka podobno. Izvedemo linearno iskanje nad seznamom #t[hash(x)]#:
\codeimport{ods/ChainedHashTable.find(x)}
Podobno tudi tu potrebujemo čas sorezmeren z dolžino seznama #t[hash(x)]#.

Hitrosti zgoščevalnih tabel so odvisne predvsem od izbire zgoščevalne funkcije. Dobra zgoščevalna funkcija razporedi elemente enakomerno med #t.length# seznamov, tako da je pričakovana
velikost seznama #t[hash(x)]# $O(#n#/#t.length)# = O(1)$. Po drugi strani pa slaba zgoščevalna funkcija zgosti vse vrednosti(vključno z #x#) na isto lokacijo v tabeli. V tem primeru bo velikost
seznama #t[hash(x)]# #n#. V naslednjem poglavju je opisan primer dobre zgoščevalne funckije. 

\subsection{Zgoščevanje z množenjem}
\seclabel{multihash}

\index{hashing!multiplicative}%
\index{multiplicative hashing}%

Zgoščevanje z množenjem je učinkovita metoda tvorbe zgoščevalnih vrednosti osnovana na kongruenci(opisana v poglavju  \secref{arrayqueue}) in celoštevilskemu deljenju. Uporablja operator $\ddiv$ , 
ki obdrži celoštevilski del kvocienta, ostanek pa zanemari. Praktično za vsako število velja $a\ge 0$ in $b\ge 1$, $a\ddiv b = \lfloor
a/b\rfloor$. 

Pri zgoščevanju z množenjem uporabljamo tabele velikosti $2^{#d#}$ pri čemer je #d# neko celo število(imenovano \emph{dimenzija}). Formula za zgoščevanje celega števila $#x#\in\{0,\ldots,2^{#w#}-1\}$ je
\[
    #hash#(#x#) = ((#z#\cdot#x#) \bmod 2^{#w#}) \ddiv 2^{#w#-#d#} \enspace .
\]

Pri tem je #z# neko naključno izbrano \emph{celo} število v $\{1,\ldots,2^{#w#}-1\}$.
Zgoščevalna funkcija je lahko realizirana zelo učinkovito, z obzirom na to, da so operacije nad celimi števili že v osnovi izvedene nad $2^{#w#}$ biti, kjer je $#w#$ število bitov v celem številu. 
(Glej \figref{multihashing}.) Poleg tega je celoštevilsko deljenje z $2^{#w#-#d#}$ enako izločanju skrajno desnih $#w#-#d#$ bitov v binarni predstavitvi (kar uredimo s premikom za $#w#-#d#$ bitov).
S tem dosežemo, da ima koda lažjo implementacijo kot matematična formula:
\codeimport{ods/ChainedHashTable.hash(x)}

\begin{figure}
  \begin{center}
    \resizebox{.98\textwidth}{!}{
    \setlength{\arrayrulewidth}{1pt}
    \begin{tabular}{|lr@{}r|}\hline
    $2^#w#$ (4294967296)&            #1#&#00000000000000000000000000000000# \\
    #z# (4102541685)&                   &#11110100100001111101000101110101# \\
    #x# (42) &                          &#00000000000000000000000000101010# \\
    $#z#\cdot#x#$ &             #101000#&#00011110010010000101110100110010# \\
    $(#z#\cdot#x#)\bmod 2^{#w#}$ &      &#00011110010010000101110100110010# \\
    $((#z#\cdot#x#)\bmod 2^{#w#})\ddiv 2^{#w#-#d#}$ &&
                      \multicolumn{1}{@{}l|}{#00011110#} \\\hline
    \end{tabular}}
    \setlength{\arrayrulewidth}{.4pt}
  \end{center}
  \caption{Operacija večkratne zgoščevalne funkcije z $#w#=32$
    in $#d#=8$.}
  \figlabel{multihashing}
\end{figure}

Pri naslednjem primeru, čigar dokaz je prikazan kasneje v poglavju, pokažemo, da igra zgoščevalna funkcija z množenjem odlično vlogo pri izmikanju trkov.

\begin{lem}\lemlabel{universal-hashing}
  Naj bosta #x# in #y# dve vrednosti izmed $\{0,\ldots,2^{#w#}-1\}$ in
  $#x#\neq #y#$. Potem sledi, da $\Pr\{#hash(x)#=#hash(y)#\} \le 2/2^{#d#}$.
\end{lem}

Pri primeru \lemref{universal-hashing}, je učinkovitost funkcij #odstrani(x)# in #najdi(x)# možno preprosto analizirati:

\begin{lem}
  Za katerokoli podatkovno vrednost #x# je pričakovana dolžina seznama #t[hash(x)]# največ $#n#_{#x#} + 2$, pri čemer je $#n#_{#x#}$ število pojavitev #x# v zgoščevalni tabeli.
\end{lem}


\begin{proof}
  Naj bo $S$ (večkratna-) zbirka elementov shranjenih v zgoščevalni tabeli, ki ni enaka #x#. Za element $#y#\in S$ definiramo indikatorsko spremenljivko
    \[ I_{#y#} = \left\{\begin{array}{ll}
       1 & \mbox{če je $#hash(x)#=#hash(y)#$} \\
       0 & \mbox{drugače}
       \end{array}\right.
    \]
  in opazimo, da je po primeru \lemref{universal-hashing}, $\E[I_{#y#}] \le
  2/2^{#d#}=2/#t.length#$ pričakovana dolžina lista #t[hash(x)]#
  podana v naslednji obliki
  \begin{eqnarray*}
   \E\left[#t[hash(x)].size()#\right] &=& \E\left[#n#_{#x#} + \sum_{#y#\in S} I_{#y#}\right] \\
    &=& #n#_{#x#} + \sum_{#y#\in S} \E [I_{#y#} ] \\
    &\le& #n#_{#x#} + \sum_{#y#\in S} 2/#t.length# \\
    &\le& #n#_{#x#} + \sum_{#y#\in S} 2/#n# \\
    &\le& #n#_{#x#} + (#n#-#n#_{#x#})2/#n# \\
    &\le& #n#_{#x#} + 2 \enspace ,
  \end{eqnarray*}
\end{proof}

Sedaj bi želeli dokazati primer \lemref{universal-hashing}, a za slednje, najprej potrebujemo rezultat iz teorije števil. Pri naslednjem dokazu uporabljamo notacijo 
$(b_r,\ldots,b_0)_2$ pri označevanju $\sum_{i=0}^r b_i2^i$, kjer je vsak $b_i$
bitna vrednost, ali 0 ali 1. Z drugimi besedami je $(b_r,\ldots,b_0)_2$ celo številčna vrednost, čigar dvojiška predstavitev je podana kot $b_r,\ldots,b_0$.
Z uporabo $\star$ označimo neznano bitno vrednost.

\begin{lem}\lemlabel{hashing-mapping}
  Naj bo $S$ zbirka lihih celih števil na intervalu $\{1,\ldots,2^{#w#}-1\}$; prav tako naj bosta $q$ in $i$ dva, katera koli, elementa izmed vseh elementov v $S$. Potem takem obstaja točno ena vrednost $#z#\in S$ za katero velja $#z#q\bmod 2^{#w#} = i$.
\end{lem}

\begin{proof}
  Ker je število izbira za $#z#$ in $i$ enaka, je zadostljivo dokazati, \emph{največ} ena vrednost $#z#\in S$ za katero velja $#z#q\bmod 2^{#w#} = i$.

  Predpostavimo da sta, za voljo nasprotij, dve vrednosti #z# and #z'#, kjer velja $#z#>#z#'$.  Potem je
  \[
     #z#q\bmod 2^{#w#} = #z#'q \bmod 2^{#w#} = i
  \]
  Kar sledi k
  \[ 
     (#z#-#z#')q\bmod 2^{#w#} = 0 
  \]
  Slednje pomeni, da je
  \begin{equation}
    (#z#-#z#')q = k 2^{#w#} \eqlabel{factors} 
  \end{equation}
  za neko celo število $k$. V smislu dvojiških števil, bi slednje pomenilo da imamo 
  \[
    (#z#-#z#')q = k\cdot(1,\underbrace{0,\ldots,0}_{#w#})_2 \enspace ,
  \]
  tako da so #w# zadnje bitne vrednosti v dvojiški predstavitvi 
  $(#z#-#z#')q$ vse ničle (0).

  Poleg tega velja tudi da je $k\neq 0$, ker velja da je $q\neq 0$ in $#z#-#z#'\neq 0$.  Ker je $q$ liho število, nima ničel kot zadnje vrednosti v bitni predstavitvi:
  \[
    q = (\star,\ldots,\star,1)_2 \enspace .
  \]
  Ker velja da ima $|#z#-#z#'| < 2^{#w#}$, $#z#-#z#'$ manj, kot #w#, ničelnih zadnjih vrednosti v bitni predstavitvi slednjega:
  \[
    #z#-#z#' = (\star,\ldots,\star,1,\underbrace{0,\ldots,0}_{<#w#})_2
      \enspace .
  \]
\end{proof}

Uporabnost \lemref{hashing-mapping} izhaja iz sledeče predpostavke:
Če je #z# izbran enakomerno naključno iz $S$, potem je #zt#
enakomerno porazdeljen nad $S$.  V sledečem dokazu, si pomagamo
z dvojiško predstavitvijo #z#, katera sestoji iz $#w#-1$
naključnih bitov s pripono 1.

\begin{proof}[Dokaz za \lemref{universal-hashing}]
  Začnemo z ugotovitvijo da je $#hash(x)#=#hash(y)#$ ekvivalenten
  trditvi `` #d# najpomembnejših bitov v $#z# #x#\bmod2^{#w#}$
  in #d# najpomembnejših bitov $#z# #y#\bmod 2^{#w#}$ je enakih.''
  Pri prejšnji trditvi je potrebno poudariti, da je #d# najpomembnejših bitov
  v dvojiški predstavitvi $#z#(#x#-#y#)\bmod 2^{#w#}$
  vseh enakih 1 ali enakih 0.  Torej velja,
  \begin{equation}
      #z#(#x#-#y#)\bmod 2^{#w#} = 
      (\underbrace{0,\ldots,0}_{#d#},\underbrace{\star,\ldots,\star}_{#w#-#d#})_2 
      \eqlabel{all-zeros}
  \end{equation}
  ko velja $#zx#\bmod 2^{#w#} > #zy#\bmod 2^{#w#}$ ali
  \begin{equation}
      #z#(#x#-#y#)\bmod 2^{#w#} = 
      (\underbrace{1,\ldots,1}_{#d#},\underbrace{\star,\ldots,\star}_{#w#-#d#})_2 
       \enspace .
      \eqlabel{all-ones}
  \end{equation}
  ko velja $#zx#\bmod 2^{#w#} < #zy#\bmod 2^{#w#}$.
  Potemtakem, ugotavljamo le verjetnost, da
  $#z#(#x#-#y#)\bmod 2^{#w#}$ izgleda kot \myeqref{all-zeros} or \myeqref{all-ones}.
  
  Naj bo $q$ enolično liho število, za katero velja $(#x#-#y#)\bmod
  2^{#w#}=q2^r$ za neko število $r\ge 0$. Po
  \lemref{hashing-mapping}, ima dvojiška predstavitev $#z#q\bmod
  2^{#w#}$ $#w#-1$ naključnih bitov, zaključenih z 1:
  \[
   #z#q\bmod 2^{#w#}  = (\underbrace{b_{#w#-1},\ldots,b_{1}}_{#w#-1},1)_2
  \]
  Iz tega sledi, da ima dvojiška predstavitev $#z#(#x#-#y#)\bmod 2^{#w#}=#z#q2^r\bmod 2^{#w#}$ 
  $#w#-r-1$ naključnih bitov, zaključenih z 1, zaključenih z $r$ ponovitvami 0:
  \[
  #z#(#x#-#y#)\bmod 2^{#w#}  =
  #z#q2^{r}\bmod 2^{#w#} =
      (\underbrace{b_{#w#-r-1},\ldots,b_{1}}_{#w#-r-1},1,\underbrace{0,0,\ldots,0}_{r})_2
  \]
  S tem zaključimo dokaz. Če je $r > #w#-#d#$, potem #d#
  najpomembnejših bitov $#z#(#x#-#y#)\bmod 2^{#w#}$  vsebuje tako ničle
   kot enice , tako da je verjetnost da $#z#(#x#-#y#)\bmod 2^{#w#}$ izgleda kot
  \myeqref{all-zeros} ali \myeqref{all-ones} nična.  Če je $#r#=#w#-#d#$,
  potem je verjetnost da izgleda kot \myeqref{all-zeros} nična, vendar je
  verjetnost da izgleda kot \myeqref{all-ones} $1/2^{#d#-1}=2/2^{#d#}$
  (ker moramo imeti $b_1,\ldots,b_{d-1}=1,\ldots,1$).  Če velja $r < #w#-#d#$,
  potem moramo imeti $b_{#w#-r-1},\ldots,b_{#w#-r-#d#}=0,\ldots,0$ ali
  $b_{#w#-r-1},\ldots,b_{#w#-r-#d#}=1,\ldots,1$.  Verjetnost posamezne
  od teh možnosti je $1/2^{#d#}$ pri čemer so vse vzajemno izključujoče, tako da je
  verjetnost da se zgodi katerakoli $2/2^{#d#}$. S tem zaključimo dokaz.
\end{proof}



\subsection{Povzetek}
\translatedby{Edin Beganovic}{sl}

Naslednji izrek povzema uspešnost #ChainedHashTable# podatkovne strukture:

\begin{thm}\thmlabel{hashtable}
  #ChainedHashTable# implementira vmesnik #USet#. Če ignoriramo ceno klicev 
  metode #grow()#, #ChainedHashTable# podpira operacije #add(x)#, #remove(x)#, 
  #find(x)#, v pričakovanem $O(1)$ času na operacijo.
  
  Poleg tega, da je začetna #ChainedHashTable# prazna, vsaka sekvenca od $m$ 
  #add(x)# in #remove(x)# operacije rezultira v skupni porabi $O(m)$ časa za
  vse klice na #grow()#.
\end{thm}

\section{#LinearHashTable#: Linearno naslavljanje}
\translatedby{Igor Plavšić,Edin Beganovic}{sl}

\index{LinearHashTable@#LinearHashTable#}%
Podatkovna struktura #ChainedHashTable# uporablja polje seznamov, kjer #i# 
seznam shrani vse elemente #x# tako da je $#hash(x)#=#i#$. Alternativa po imenu 
\emph{odprto nasljavljanje} 
\index{open addressing}%
je namenjena shranjevanju elementov neposredno v polje, #t#, z vsako lokacijo 
polja v #t# pa shrani največ eno vrednost. Tak pristop se uporablja v #LinearHashTable# 
in je opisan v tem poglavju. Ponekod je ta podatkovna struktura opisana 
kot \emph{odprto naslavljanje}.
\index{linear probing}%

Glavna ideja #LinearHashTable# je da bi mi lahko, idealno, shranili element #x# 
z razpršilno vrednostjo #i=hash(x)# v lokacijo tabele #t[i]#. Če tega ne moremo 
storiti (ker je nek element že shranjen tam) potem ga skušamo shraniti v lokaciji $#t#[(#i#+1)\bmod#t.length#]$; če tudi to ni mogoče, potem poskusimo 
z $#t#[(#i#+2)\bmod#t.length#]$, in tako naprej, dokler ne najdemo mesta za #x#.
%str 113-114

\translatedby{Ariel David Jančar}{sl}
%nadaljevanje - Ariel David Jančar
V #t# imamo shranjene tri tipe vhodov: 
\begin{enumerate}
  \item podatkovne vrednosti: dejanske vrednosti iz #USet# katere predstavljamo;
  \item #null# vrednosti: na lokacijah v tabeli kjer ni in ni bilo nikoli kakršnihkoli podatkov; in
  \item #del# vrednosti: na lokacijah tabele kjer so bili podatki nekoč shranjeni ampak so od takrat bili izbrisani.
\end{enumerate}

Poleg števca, #n#, ki skrbi za spremljanje številov elementov v #LinearHashTable#, imamo še števec, #q#, ki skrbi za spremljanje števila elementov Tipov~1 in 3. To pomeni, #q# je enak #n# z dodanimi števili #del# vrednosti v #t#. Za učinkovito delovanje potrebujemo da je #t# precej večji od #q#, tako da je veliko #null# vrednosti v #t#. Operacije na #LinearHashTable# torej ohranjajo invarianto, da je $#t.length#\ge 2#q#$.

Torej, #LinearHashTable# hrani tabelo, #t#, ki hrana podatkovne elemente in cela števila ali integers #n# in #q# ki spremljata število dejanski podatkovnih elementov in ne-#null# vrednosti v #t#. Ker vrsta zgoščevalnih funkcij deluje le za tabele katerih velikosti potence števila 2, prav tako hranimo celo število #d# in ohranjamo invarianto da je $#t.length#=2^#d#$.
\codeimport{ods/LinearHashTable.t.n.q.d}

\translatedby{Matej Adamič}{sl}

Delovanje iskanja #find(x)#  je v #LinearHashTable# preprosto. Začnemo z vpisom v tabelo #t[i]# kjer je $#i#=#hash(x)#$ in iskanih elementov #t[i]#, $#t#[(#i#+1)\bmod #t.length#]$ , $#t#[(#i#+2)\bmod #t.length#]$, in tako naprej dokler ne najedmo indeksa #i'#
tako, da je bodisi #t[i']=x#, ali #t[i']=null#. V prvem primeru bomo vrnili  #t[i']#. V drugem primeru pa lahko ugotovimo, da x ni vsebovan v razpršeni tabeli in vrnemo #null#.
\codeimport{ods/LinearHashTable.find(x)}

Delovanje #add(x)# je tudi dokaj enostavno izvajati. Po preverjanju, da #x# slučajno že ni shranjena v tabeli (uporabimo #find(x)#), iščemo
#t[i]#, $#t#[(#i#+1)\bmod #t.length#]$, $#t#[(#i#+2)\bmod #t.length#]$,
in tako naprej, dokler ne najdemo #null# ali #del# in shranimo #x# na lokaciji, če je potrebno povečamo #n# in #q#.
\codeimport{ods/LinearHashTable.add(x)}

Do sedaj naj bi bilo delovanje izvajanja #remove(x)# očitno.
Iščemo #t[i]#, $#t#[(#i#+1)\bmod #t.length#]$, $#t#[(#i#+2)\bmod
#t.length#]$, in tako naprej dokler ne najdemo indeksa #i'# tako, da bo #t[i']=x# ali #t[i']=null#.  V prvem primeru nastavimo #t[i']=del# in vrnemo #true#. V drugem primeru ugotovimo, da #x# wni bil shranjen v tabeli (zato ga ne moremo odstraniti) in vrnemo #false#.
\codeimport{ods/LinearHashTable.remove(x)}

Pravilnost metod #find(x)#, #add(x)# in #remove(x)# je lahko preveriti, čeprav temelji na uporabi #del# vrednosti. Opazimo lahko, da nobena od teh operacij nikoli ne postavi ne-#null# vnosa na #null#. Zato ko dosežemo indeks #i'#, kot je recimo #t[i']=null#, je to dokaz da element #x#, ki ga iščemo, ni shranjen v tabeli; #t[i']# je bil vedno #null#, zato ni razloga da bi prejšnja operacija #add(x)# nadaljevala čez indeks #i'#.

Metodo resize() pokliče metoda #add(x)# ko število ne-#null# vnosov preseže $#t.length#/2$ ali pa metoda #remove(x)#, ko je število podatkovnih vnosov manjše od #t.length/8#. Metoda deluje enako kot v drugih podatkovih strukturah, ki temeljijo na tabelah. Najdemo najmanjše pozitivno število #d#, tako da je $2^{#d#}\ge 3#n#$. Tabelo #t# dodelimo tako da dobimo tabelo velikosti $2^{#d#}$ in nato vse elemente iz stare verzije tabele #t# vstavimo v novo ustvarjeno kopijo tabele #t#. Medtem ponastavimo #q# na vrednost #n#, saj nova tabela #t# ne vsebuje #del# vrednosti.

\codeimport{ods/LinearHashTable.resize()}
\translatedby{Klemen Hiti}{sl}
\translatedby{Igor Plavšić}{sl}
\subsection{Analiza odprtega naslavljanja}

Vsaka od operacij #add(x)#, #remove(x)# in #find(x)# se konča najkasneje takoj ko odkrije prvi #null# vnos v #t#. Intuicija za to analizo temelji na tem, da je najmanj polovica elementov v tabeli #t# enakih #null#, zato operacija ne bi smela potrebovati veliko časa za zaključitev, saj zelo hitro naleti na #null# vnos. Na to intuicijo se ne smemo preveč trdno zanašati, ker bi nas pripeljala do (napačnega) sklepa da je pričakovano število lokacij v tabeli #t#, ki jo poda ta operacija, največ 2.

Za preostanek tega poglavja bomo domnevali, da so vse razpršene vrednosti neodvisno in enotno porazdeljene v $\{0,\ldots,#t.length#-1\}$. To ni realistišna domneva, vendar nam bo omogočila analizo linearnega naslavljanja. Kasneje v tem poglavju bomo opisali metodo imenovano tabelarno zgoščevanje, ki ustvari razpršeno funkcijo, ki je ``dovolj dobra'' za linearno naslavljanje. Prav tako bomo predpostavili, da so vsi indeksi v položajih #t# celoštevilsko deljeni z #t.length#, tako da je #t[i]# okrajšava za $#t#[#i#\bmod#t.length#]$.

\index{run}%
Pravimo da se \emph{izvršitev dolžine $k$, ki se začne pri #i#} zgodi, kadar noben od elementov $#t[i]#, #t[i+1]#,\ldots,#t#[#i#+k-1]$ ni #null# in $#t#[#i#-1]=#t#[#i#+k]=#null#$. Število elementov tabele #t# ki niso #null# je enako #q#, metoda #add(x)# pa zagotavlja, da vedno velja $#q#\le#t.length#/2$. Obstaja #q# elementov $#x#_1,\ldots,#x#_{#q#}$ ki so bili vstavljeni v #t# po zadnji #rebuild()# operaciji. Po naši domnevi ima vsak izmed teh elementov zgočevalno vrednost $#hash#(#x#_j)$, ki je enotna in neodvisna od drugih. S tako nastavitvijo lahko dokažemo glavno trditev potrebno za analiziranje linearnega naslvljanja.

\begin{lem}\lemlabel{linear-probing}
Določimo vrednost $#i#\in\{0,\ldots,#t.length#-1\}$. Potem je možnost, da se izvršitev dolžine $k$ začne pri #i#, enaka $O(c^k)$ za konstanto $0<c<1$.
\end{lem}
\translatedby{Klemen Hiti}{sl}

%strani 119/120
\translatedby{Tejo Ličen}{sl}
\begin{proof}
Če se začetek dolžine $k$ začne pri #i#, je natanko $k$
elementov $#x#_j$, ki so $#hash#(#x#_j)\in\{#i#,\ldots,#i#+k-1\}$.
Verjetnost za to je točno
\[
  p_k  = \binom{#q#}{k}\left(\frac{k}{#t.length#}\right)^k\left(\frac{#t.length#-k}{#t.length#}\right)^{#q#-k} \enspace ,
\]
ker za vsako izbiro $k$ elementov, teh $k$ elementov mora zgostiti k eni izmed $k$ lokacij. Preostalih $#q#-k$ pa mora zgostiti k preostalim $#t.length#-k$ lokacijam v tabeli.\footnote{Upoštevajte, da je $p_k$ večje kot verjetnost, da se izvajanje dolžine k začne pri #i#, ker definicija od $p_k$ ne upošteva pogoja $#t#[#i#-1]=#t#[#i#+k]=#null#$.}

V naslednji izpeljavi bomo pogoljufali in zamenjali $r!$ z
$(r/e)^r$. Stirlingova aproksimacija (\secref{factorials}) nam pove da je to le faktor $O(\sqrt{r})$ od pravilnosti. To naredimo zato, da si poenostavimo izpeljavo; \excref{linear-probing} od bralca zahteva, da natančneje in v celoti ponovi izračun z uporabo Stirlingove aproksimacije.

Vrednost $p_k$ je maksimalna, ko je #t.length# minimum in podatkovna struktura obdrži nespremnjen $#t.length# \ge 2#q#$, torej
\begin{align*}
   p_k & \le \binom{#q#}{k}\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} \\
  & = \left(\frac{#q#!}{(#q#-k)!k!}\right)\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} \\
  & \approx \left(\frac{#q#^{#q#}}{(#q#-k)^{#q#-k}k^k}\right)\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} && \text{[Stirlingova aproksimacija]} \\
  & = \left(\frac{#q#^{k}#q#^{#q#-k}}{(#q#-k)^{#q#-k}k^k}\right)\left(\frac{k}{2#q#}\right)^k\left(\frac{2#q#-k}{2#q#}\right)^{#q#-k} \\
 & = \left(\frac{#q#k}{2#q#k}\right)^k
     \left(\frac{#q#(2#q#-k)}{2#q#(#q#-k)}\right)^{#q#-k} \\
 & = \left(\frac{1}{2}\right)^k
     \left(\frac{(2#q#-k)}{2(#q#-k)}\right)^{#q#-k} \\
 & = \left(\frac{1}{2}\right)^k
     \left(1+\frac{k}{2(#q#-k)}\right)^{#q#-k} \\
 & \le \left(\frac{\sqrt{e}}{2}\right)^k \enspace .
\end{align*}
(V zadnjem koraku uporabimo neenakost $(1+1/x)^x \le e$, ki drži za vse $x>0$.).  Ker je $\sqrt{e}/{2}< 0.824360636 < 1$, dokaz lahko potrdimo.
\end{proof}

Uporaba \lemref{linear-probing} za dokaz zgornje meje na času izvajanja #find(x)#, #add(x)# in #remove(x)# je sedaj enostavna.  Upoštevajmo najenostavnješi primer, kjer izvršimo #find(x)# za neko vrednost #x#, ki ni bila nikoli shranjena v #LinearHashTable#.  V tem primeru $#i#=#hash(x)#$ dobi naključno vrednost v $\{0, \ldots, #t.length#-1\}$, ki je neodvisna od vsebine #t#.  Če je #i# del izvajanja dolžine $k$, potem je čas izvajanja operacije #find(x)# v najboljšem primeru $O(1+k)$.  Potemtakem, zgornja meja pričakovanega časa izvajanja je
\[
  O\left(1 + \left(\frac{1}{#t.length#}\right)\sum_{i=1}^{#t.length#}\sum_{k=0}^{\infty} k\Pr\{\text{#i# je del obhoda dolžine $k$}\}\right) \enspace .
\]
Upoštevajte, da vsako izvajanje dolžine $k$ prispeva k notranji vsoti $k$-krat za končni prispevek $k^2$,  torej lahko navedeno vsoto ponovno napišemo kot
\begin{align*}
  & { } O\left(1 + \left(\frac{1}{#t.length#}\right)\sum_{i=1}^{#t.length#}\sum_{k=0}^{\infty} k^2\Pr\{\mbox{#i# začne obhod dolžine $k$}\}\right) \\
  & \le O\left(1 + \left(\frac{1}{#t.length#}\right)\sum_{i=1}^{#t.length#}\sum_{k=0}^{\infty} k^2p_k\right) \\
  & = O\left(1 + \sum_{k=0}^{\infty} k^2p_k\right) \\
  & = O\left(1 + \sum_{k=0}^{\infty} k^2\cdot O(c^k)\right) \\
  & = O(1) \enspace .
\end{align*}
Zadnji korak v tej izpeljavi prihaja iz dejstva, da $\sum_{k=0}^{\infty} k^2\cdot O(c^k)$ eksponentno zmanjšuje vrsto.\footnote{V terminologiji več matematičnih učbenikov nam ta vsota poda razmerje:  Obstaja pozitivno celo število $k_0$, ki velja za vse $k\ge k_0$, $\frac{(k+1)^2c^{k+1}}{k^2c^k} < 1$.}
Potemtakem lahko sklepamo, da je pričakovan čas izvajanja operacije #find(x)# za vrednost #x#, ki ni vsebovana v #LinearHashTable# enaka,  $O(1)$.

Če zanemarimo ceno operacije #resize()#, potem nam gornja analiza poda vse kar potrebujemo za analiziranje cene ostalih operacij v #LinearHashTable#.

Analiza gornje operacije #find(x)# velja pri operaciji #add(x)# kadar, #x# ni v tabeli.  Za analizo operacije #find(x)# kadar, #x# je vsebovan v tabeli moramo upoštevati samo to, da je cena enaka operaciji #add(x)# s katero smo dodali #x# v tabelo.  Za konec, cena operacije #remove(x)# je enaka ceni operacije #find(x)#.

V povzetku, če zanemarimo ceno klicev operacije #resize()#, so vse ostale operacije v #LinearHashTable# izvršene v pričakovanem času $O(1)$.  Da upoštevamo ceno operacije resize, lahko uporabimo enako amortizirano analizo izvedeno za podatkovno strukturo #ArrayStack# v \secref{arraystack}.


%uredil Anže Premrl 
\subsection{Povzetek}
\translatedby{Igor Plavšić}{sl}
Spodnji izrek je povzetek časovnih zahtevnosti, metod, podatkovne strukture #LinearHashTable#:

\begin{thm}\thmlabel{linear-probing}
  #LinearHashTable# implementira vmesnik #USet#.  Če ignoriramo
  ceno klicev metode #resize()#, je pričakovana časovna zahtevnost metod 
  #add(x)#, #remove(x)#, in #find(x)#, podatkovne strukture #LinearHashTable#,
  enaka $O(1)$.  

  Če začenjamo s prazno #LinearHashTable#, velja, da za 
  katerokoli zaporedje $m$ operacij metod #add(x)# in #remove(x)#, 
  porabimo $O(m)$ časa za klice metode #resize()#.
\end{thm}

\subsection{Tabelarno zgoščevanje}
\translatedby{Igor Plavšić}{sl}
\seclabel{tabulation}

\index{tabulation hashing}%
Med analizo podatkove strukture #LinearHashTable#, smo naredili zelo
močno predpostavko:  Da so za katerokoli množico elementov, 
$\{#x_1#,\ldots,#x_n#\}$, zgoščevalne vrednosti $#hash(x_1)#,\ldots,#hash(x_n)#$
neodvisno in enakomerno razporejene po množici $\{0,\ldots,#t.length#-1\}$.  
En način, kako to doseči je, da hranimo ogromno polje, #tab#, dolžine $2^{#w#}$,
kjer je vsak zapis naključno #w# bitno celo število, neodvisno od vseh ostalih zapisov.  
Na ta način bi lahko implementirali #hash(x)#, tako da bi izbrali #d# bitno celo število 
iz tabele #tab[x.hashCode()]#:
\codeimport{ods/LinearHashTable.idealHash(x)}

Na žalost je hranjenje polja velikosti $2^{#w#}$ neoptimalna rešitev, 
kar se tiče prostorske porabe.  Pristop, ki ga uporablja 
\emph{tabelarno zgoščevanje} je, da #w# bitna cela števila obravnava kot 
cela števila, ki so sestavljena iz $#w#/#r#$ celih števil, ki imajo dolžino le 
$#r#$ bitov. Tako pri tabelarnem zgoščevanju potrebujemo samo  $#w#/#r#$ 
polj velikosti $2^{#r#}$.  Vsi zapisi v teh poljih so neodvisna #w#-bitna 
cela števila.  Da pridobimo vrednost #hash(x)#, razdelimo #x.hashCode()# 
v $#w#/#r#$ #r#-bitnih celih števil ter jih uporabimo kot indekse za polja.  
Nato vse te vrednosti združimo z bitnim operatorjem izključni ali(XOR), 
da pridobimo #hash(x)#.
Spodnja programska koda prikazuje kako to deluje za $#w#=32$ in $#r#=4$:
\codeimport{ods/LinearHashTable.hash(x)}
V temu primeru je #tab# dvodimenzionalno polje s štirimi stolpci in $2^{32/4}=256$ vrsticami.

Enostavno lahko preverimo, da je, za poljubni #x#, #hash(x)# enakomerno razporejen 
po intervalu $\{0,\ldots,2^{#d#}-1\}$.  Z malo dodatnega dela lahko tudi preverimo, da ima 
poljubni par vrednosti neodvisne zgoščene vrednosti. 
To pomeni, da bi se za implementacijo #ChainedHashTable#, namesto zgoščevalne funkcije - metode množenja 
uporabilo tabelarno zgoščevanje.

Dejstvo, da ima poljubna množica #n# različnih vrednosti množico #n# neodvisnih 
zgoščenih vrednosti ne velja.  Ne glede na to, pa velja, da ko uporabljamo tabelarno zgoščevanje, 
še vedno velja meja \thmref{linear-probing}.  
Reference za to lahko najdete na koncu tega poglavja.

% Podpoglavje 5.3
\section{Zgoščene vrednosti}
\translatedby{Andrej Rolih}{sl}

\index{Zgoščene vrednosti}%
Zgoščene tabele, ki smo si jih pogledali v prejšnjem podpoglavju se uporabljajo za povezovanje podatkov s celoštevilskimi ključi sestavljenimi iz #w# bitov. Velikokrat pa uporabljamo ključe, ki niso cela števila. Lahko so nizi znakov, objekti, tabele ali ostale sestavljene strukture. Da lahko uporabimo zgoščevalne funkcije na takih tipih podatkov moramo prej preslikati te podatke v #w#-bitne zgoščene vrednosti. Preslikave zgoščevalnih funkcij morajo imeti naslednje lastnosti:

\begin{enumerate}
  \item Če sta #x# in #y# enaka, potem morata biti enaka tudi #x.hashCode()# in #y.hashCode()# .

  \item Če #x# in #y# nista enaka, potem mora biti verjetnost, da sta
  $#x.hashCode()#=#y.hashCode()#$ majhna (blizu
  $1/2^{#w#}$).
\end{enumerate}

Prva lastnost nam zagotavlja, da če v zgoščeni tabeli hranimo #x# in kasneje iščemo vrednost #y# (ki je enaka #x# ), da bomo našli #x# . Druga lastnost pa nam preprečuje izgubo podatkov pri pretvarjanju objektov v cela števila. Zagotavlja nam, da bodo različni objekti imeli različno zgoščeno vrednost in bodo tako zelo verjetno shranjeni na različnih mestih v naši zgoščeni tabeli. 

\subsection{Zgoščene vrednosti osnovnih podatkovnih tipov}

\index{Zgoščene vrednosti osnovnih podatkovnih tipov}%
Za majhne osnovne podatkovne tipe kot so #char#, #byte#, #int#, in #float# lahko ponavadi hitro najdemo zgoščeno vrednost. Ti podatkovni tipi imajo vedno binarno predstavitev sestavljeno iz #w# ali manj bitov. \javaonly{(V Javi je, #byte# 8-bitni podatkovni tip in #float# 32-bitni.)}\cpponly{(V C++ #char# ponavadi 8-bitni in #float# 32-bitni.)} . V teh primerih te bite obravnavamo kot cela števila na intervalu $\{0,\ldots,2^#w#-1\}$ . Če sta dve vrednosti različni potem dobijo različni zgoščeni vrednosti. Če sta vrednosti enaki pa dobita enako zgoščeno vrednost.

Nekateri podatkovni tipi pa so sestavljeni iz več kot #w# bitov. Ponavadi $c#w#$ bitov za neko konstantno celo število $c$ . (V Javi sta #long# in #double# primera tipov pri katerih je $c=2$.) Te podatkovne tipe lahko obravnavamo kot  objekte sestavljene iz $c$ delov, kot je opisano v naslednjem podpoglavju.

\subsection{Zgoščene vrednosti sestavljenih podatkovnih tipov}
\seclabel{stringhash}

\index{Zgoščene vrednosti sestavljenih podatkovnih tipov}%
Za sestavljene objekte si želimo zgraditi zgoščevalno funkcijo, ki bi kombinirala zgoščene vrednosti podatkovnih tipov, ki ta objekt sestavljajo. Vendar pa to ni tako enostavno kot zveni. Kljub temu, da lahko najdemo kar nekaj bljižnic s katerimi to lahko naredimo (na primer sestavljanje zgoščenih vrednosti z operacijo XOR) pa to ni rešitev problema, saj lahko hitro pridemo do primerov kjer take bljižnice odpovedo (glej naloge ~\ref{exc:hash-hack-first}--\ref{exc:hash-hack-last}). A vendar obstajajo hitri in robustni načini reševanja tega problema, če si lahko privoščimo računanje z $2#w#$ bitno natančnostjo. Zamislimo si objekt sestavljen iz delov $P_0,\ldots,P_{r-1}$ katerih zgoščene vrednosti so $#x#_0,\ldots,#x#_{r-1}$. Potem si lahko izberemo neodvisna in naključna  #w#-bitna števila $#z#_0,\ldots,#z#_{r-1}$ in eno liho in naključno celo število #z# sestavljeno iz $2#w#$ bitov. Iz tega lahko izračunamo zgoščeno vrednost za naš objekt na naslednji način:
\[
   h(#x#_0,\ldots,#x#_{r-1}) =  
   \left(\left(#z#\sum_{i=0}^{r-1} #z#_i #x#_i\right)\bmod 2^{2#w#}\right)
   \ddiv 2^{#w#} \enspace .
\]

%naslednji prevajalec naj nadaljuje od tu - vrstica 638
% Borut Zupančič : vrstice 638 - 691
\translatedby{Borut Zupančič}{sl}

Upoštevajte, da ima ta zgoščena vrednost zadnji korak (deljenje z #z# in
deljenje z $2^{#w#}$), ki uporablja multiplikativno zgoščevalno funkcijo
iz \secref{multihash}, da vzame $2#w#$-bitni vmesni rezultat in
ga pomanjša v #w#-bitni končni rezultat. Tukaj je primer te metode uporabljene na enostavnemu sestavljenemu podatkovnemu tipu s tremi deli #x0#, #x1#, and #x2#:
\javaimport{junk/Point3D.x0.hashCode()}
\cppimport{ods/Point3D.hashCode()}
% \pcodeimport{ods/Point3d.hashCode()}
Naslednji izrek nam pokaže, da je metoda, ob tem da je enostavna za implementacijo, tudi dokazano dobra:

\begin{thm}\thmlabel{multihash}
Naj bosta $#x#_0,\ldots,#x#_{r-1}$ in $#y#_0,\ldots,#y#_{r-1}$ sekvenci #w# bitnih integerjev v $\{0,\ldots,2^{#w#}-1\}$ in predvidevamo, da $#x#_i \neq #y#_i$ za vsaj en indeks $i\in\{0,\ldots,r-1\}$. Potem 
\[
   \Pr\{ h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1}) \} 
        \le 3/2^{#w#} \enspace .  
\] 
\end{thm}

\begin{proof}
  Najprej bomo ignorirali zadnji multiplikativni zgoščevalni korak in si kasneje pogledali kako
  ta korak prispeva.  Opredeli:
  \[
    h'(#x#_0,\ldots,#x#_{r-1}) =  
       \left(\sum_{j=0}^{r-1} #z#_j #x#_j\right)\bmod 2^{2#w#} \enspace .
  \]
  Predvidevamo, da $h'(#x#_0,\ldots,#x#_{r-1}) =  h'(#y#_0,\ldots,#y#_{r-1})$.
  To lahko zapišemo kot:
  \begin{equation}  \eqlabel{bighash-x}
      #z#_i(#x#_i-#y#_i) \bmod 2^{2#w#} = t
  \end{equation}
  kjer 
  \[
     t = \left(\sum_{j=0}^{i-1} #z#_j(#y#_j-#x#_j) + \sum_{j=i+1}^{r-1} #z#_j(#y#_j-#x#_j)\right) \bmod 2^{2#w#}
  \]
  Če predvidevamo, da je brez izgube splošnosti $#x#_i> #y#_i$, potem
  \myeqref{bighash-x} postane
  \begin{equation}
      #z#_i(#x#_i-#y#_i) = t \eqlabel{bighash-xx} \enspace ,
  \end{equation}
  saj je vsak od $#z#_i$ in $(#x#_i-#y#_i)$ največ $2^{#w#}-1$, torej
  je njun produkt največ $2^{2#w#}-2^{#w#+1}+1 < 2^{2#w#}-1$.
  Po domnevi, $#x#_i-#y#_i\neq 0$, torej \myeqref{bighash-xx} ima največ eno
  rešitev v $#z#_i$.  Zato, ker sta $#z#_i$ in $t$ 
  neodvisna ($#z#_0,\ldots,#z#_{r-1}$ sta medsebojno neodvisna), 
  verjetnost, da izberemo $#z#_i$
  tako da je $h'(#x#_0,\ldots,#x#_{r-1})=h'(#y#_0,\ldots,#y#_{r-1})$ največ
  $1/2^{#w#}$.

  Zadnji korak zgoščevalne funkcije se uporablja za multiplikativno zgoščevanje, 
  da zmanjšamo naše $2#w#$-bitne vmesne rezultate $h'(#x#_0,\ldots,#x#_{r-1})$ 
  v #w#-bitni končni rezultat $h(#x#_0,\ldots,#x#_{r-1})$.  Po teoremu \thmref{multihash},
  če $h'(#x#_0,\ldots,#x#_{r-1})\neq h'(#y#_0,\ldots,#y#_{r-1})$, potem
  $\Pr\{h(#x#_0,\ldots,#x#_{r-1}) = h(#y#_0,\ldots,#y#_{r-1})\} \le 2/2^{#w#}$.

% Nejc Štebe - delam od vrstice 691 do 754
 \translatedby{Nejc Štebe}{sl}


  %   /*****************************************************************/
  %
  %     Sem notri pridejo še vrstice od 656 do 689!
  %     begin{proof} sem dal samo zato, da lahko prevedem svoj del,
  %     ki vključuje del proofa
  %
  %   /****************************************************************/

  
  Če povzamemo,
    \begin{align*}
      & \Pr\left\{\begin{array}{l}
            h(#x#_0,\ldots,#x#_{r-1}) \\
            \quad = h(#y#_0,\ldots,#y#_{r-1})\end{array}\right\} \\
        &= \Pr\left\{\begin{array}{ll}
              \mbox{$h'(#x#_0,\ldots,#x#_{r-1}) = h'(#y#_0,\ldots,#y#_{r-1})$ ali} \\
              \mbox{$h'(#x#_0,\ldots,#x#_{r-1}) \neq h'(#y#_0,\ldots,#y#_{r-1})$} \\
                    \mbox{\quad in
  $#z#h'(#x#_0,\ldots,#x#_{r-1})\ddiv2^{#w#} = #z# h'(#y#_0,\ldots,#y#_{r-1})\ddiv 2^{#w#}$}
            \end{array}\right\} \\
        &\le 1/2^{#w#} + 2/2^{#w#} = 3/2^{#w#} \enspace . \qedhere
    \end{align*}
\end{proof}

\index{hash code!for strings}%
\index{hash code!for arrays}%
\subsection{Zgoščevalne funkcije za polja in nize}
\seclabel{polyhash}

Metoda iz prejšnjega dela deluje dobro za objekte, ki imajo stalno število komponent.
Vendar ne deluje dobro, ko jo želimo uporabiti za objekte, ki imajo spremenljivo število komponent,
saj potrebuje naključno #w#-bitno celo število za vsako komponento.
Lahko bi uporabili psevdonaključno zaporedje za generiranje toliko števil $#z#$ kolikor jih potrebujemo, 
toda števila $#z#$ niso medsebojno neodvisna, zaradi česar bi težko dokazali da psevdonaključna števila 
ne vplivajo na zgoščevalno funkcijo, ki jo uporabljamo.
Vrednosti $#t#$ in $#z#$ v dokazu \thmref{multihash} nista več neodvisni.

\index{prime field}%
Bolj temeljit pristop je, da uporabimo polinome nad praštevili. To pomeni le, da uporabimo običajne 
polinomske funkcije, ki dajo ostanek deljenja z nekim praštevilom #p#.
Ta metoda sloni nad sledečim teoremom, ki pravi, da se takšne funkcije obnašajo podobno kot
običajne polinomske funkcije:

\begin{thm}
  Naj bo $#p#$ praštevilo in $f(#z#) = #x#_0#z#^0 + #x#_1#z#^1 +
  \cdots + #x#_{r-1}#z#^{r-1}$ netrivialni polinom s koeficienti
  $#x#_i\in\{0,\ldots,#p#-1\}$. Takrat ima enačba $f(#z#)\bmod #p# = 0$
  največ $r-1$ rešitev za $#z#\in\{0,\ldots,p-1\}$.
\end{thm}

Da izkoristimo \thmref{prime-polynomial} , uporabimo zgoščevalno funkcijo nad
zaporedjem celih števil $#x#_0,\ldots,#x#_{r-1}$ kjer je vsak $#x#_i\in \{0,\ldots,#p#-2\}$ z uporabo
naključnega celega števila $#z#\in\{0,\ldots,#p#-1\}$ in funkcije 
\[
   h(#x#_0,\ldots,#x#_{r-1}) 
    = \left(#x#_0#z#^0+\cdots+#x#_{r-1}#z#^{r-1}+(#p#-1)#z#^r \right)\bmod #p# \enspace .
\]

Ste opazili $(#p#-1)#z#^r$ na koncu formule? To si lahko predstavljate kot zadnji element, $#x#_r$,
v zaporedju $#x#_0,\ldots,#x#_{r}$. Ta element se razlikuje od vseh ostalih (ki so v $\{0,\ldots,#p#-2\}$).
$#p#-1$ je kot znak, ki označuje konec zaporedja.

Sledeči teorem, ki upošteva primer, ko sta obe zaporedji enako dolgi, dokazuje, da
ta zgoščevalna funkcija daje dober rezutat pri majhni meri naključnosti pri izbiri #z#:

%delam od vrstice 754 do 824
\translatedby{Danilo Poje}{sl}
\begin{thm}\thmlabel{stringhash-eqlen}
  Vzemimo $#p#>2^{#w#}+1$ da je naravno število, vzemimo $#x#_0,\ldots,#x#_{r-1}$ in
  $#y#_0,\ldots,#y#_{r-1}$ vsako je sekvenca #w#-bit celih števil v
  $\{0,\ldots,2^{#w#}-1\}$ in predpostavimo $#x#_i \neq #y#_i$ za vsaj en indeks $i\in\{0,\ldots,r-1\}$. Potem
  \[
     \Pr\{ h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1}) \} 
          \le (r-1)/#p# \} \enspace .  
  \] 
\end{thm}

\begin{proof}
  Enačba $h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1})$
  je lahko napisana kot
  \begin{equation}  \eqlabel{strhash-eqlen}
    \left(
       (#x#_0-#y#_0)#z#^0+\cdots+(#x#_{r-1}-#y#_{r-1})#z#^{r-1} 
    \right)\bmod #p# = 0.
  \end{equation}
  Ker $#x_i#\neq #y_i#$, je ta polinom netrivialen. Potemtakem,
  po \thmref{prime-polynomial}, ima največ $r-1$ rešitev v #z#.
  Verjetnost, da izberemo #z#, ki je ena od teh rešitev, je potemtakem v najboljšem 
  primeru $(r-1)/#p#$.
\end{proof}

Opozorimo, da ima ta zgoščevalna funkcija, prav tako opravka s primeri v katerih imata dve
sekvenci različno dolžino, čeprav je ena od sekvenc predpona drugi.
To je zaradi tega, ker ta funkcija efektivno razpršuje neskončno sekvenco
\[
  #x#_0,\ldots,#x#_{r-1}, #p#-1,0,0,\ldots \enspace .
\]
To zagotavlja, da če imamo dve sekvenci dolžine $r$ in $r'$
z $r > r'$, potem se ti dve sekvenci razlikujeta v indeksu $i=r$. V tem primeru
 \myeqref{strhash-eqlen} postane
\[
  \left(
     \sum_{i=0}^{i=r'-1}(#x#_i-#y#_i)#z#^i + (#x#_{r'} - #p# + 1)#z#^{r'}
     +\sum_{i=r'+1}^{i=r-1}#x#_i#z#^i + (#p#-1)#z#^{r}
  \right)\bmod #p# = 0 \enspace ,
\]
katero, po \thmref{prime-polynomial}, ima največ $r$ rešitev v $#z#$.
Skupaj z \thmref{stringhash-eqlen} to zadostuje za dokaz naslednjega bolj
splošnega teorema:

\begin{thm}\thmlabel{stringhash}
  Vzemimo $#p#>2^{#w#}+1$ da je naravno število, vzemimo $#x#_0,\ldots,#x#_{r-1}$ in
  $#y#_0,\ldots,#y#_{r'-1}$ , da sta unikatne sekvence #w#-bit celih števil v
  $\{0,\ldots,2^{#w#}-1\}$. Potem
  \[
     \Pr\{ h(#x#_0,\ldots,#x#_{r-1}) =  h(#y#_0,\ldots,#y#_{r-1}) \} 
          \le \max\{r,r'\}/#p#  \enspace .  
  \] 
\end{thm}

Sledeči primer kode prikazuje kako je ta zgoščevalna funkcija uporabljena na objektu, 
ki vsebuje polje #x#, ki vsebuje vrednosti:
\javaimport{junk/GeomVector.hashCode()}
\cppimport{ods/GeomVector.hashCode()}

Predstavljena koda žrtvuje nekaj verjetnosti kolizije zaradi implementacijske uporabnosti.
 Zlasti zaradi tega, ker aplicira multiplikativno raz-pr-ši-tveno funkcijo
iz \secref{multihash}, z $#d#=31$ za zmanjšanje #x[i].hashCode()# v 31-bit vrednost. 
To je zaradi tega, da seštevanje in množenje, ki sta narejena po operaciji modula 
naravnega števila $#p#=2^{32}-5$, se lahko izvede z uporabo nepodpisane 
63-bit aritmetike. Zaradi tega, je verjetnost dveh različnih sekvenc, od tega ima
daljša dolžino $r$, da imata enako razpršitveno kodo v najslabšem primeru
\[
    2/2^{31} + r/(2^{32}-5)
\]
za razliko od $r/(2^{32}-5)$ specificirano v \thmref{stringhash}.


% Podpoglavje 5.4, prevedeno od vrstice 902 do konca
\section{Razprave in primeri}
\translatedby{Mitja Zakrajšek}{sl}
Ideja \emph{zgoščevanja z množenjem}
\index{multiplicative hashing}%
\index{hashing!multiplicative}%
je zelo stara in je del zgoščevalne folklore \cite[Razdelek~6.4]{k97v3}. Vendar je ideja, da izberemo množitelja #z# kot naključno \emph{sodo} število in analiza \secref{multihash}, zastarela po mnenju Dietzfelbingerja \etal\
\cite{dhkp97}.  Ta različica zgoščevanja z množenjem je ena od najpreprostejših, ampak njena verjetnost kolizije $2/2^{#d#}$ je za dva faktorja večja kot pri naključni funkciji $2^{#w#}\to
2^{#d#}$. Zgoščevalna metoda \emph{zmnoži-seštej}
\index{hashing!multiply-add}%
\index{multiply-add hashing}%
 uporablja funkcijo
\[
   h(#x#) = ((#z##x# + b) \bmod 2^{#2w#}) \ddiv 2^{#2w#-#d#}
\]
kjer sta #z# in #b# naključno izbrana iz $\{0,\ldots,2^{#2w#}-1\}$.
Zmnoži-seštej zgoščevanje ima verjetnost kolizije samo $1/2^{#d#}$
\cite{d96}, ampak zahteva $2#w#$-bitne aritmetične operacije.

Obstaja kar nekaj metod za pridobivanje zgoščenih vrednosti iz zaporedja fiksne dolžine, vsebujoč #w#-bitnih celih števil. Še posebej hitra metoda
\cite{bhkkr99} je funkcija
\[\begin{array}{l}
  h(#x#_0,\ldots,#x#_{r-1}) \\
   \quad = \left(\sum_{i=0}^{r/2-1} ((#x#_{2i}+#a#_{2i})\bmod 2^{#w#})((#x#_{2i+1}+#a#_{2i+1})\bmod 2^{#w#})\right) \bmod 2^{2#w#}
\end{array}
\]
kjer je $r$ parno število in $#a#_0,\ldots,#a#_{r-1}$ naključno izbrani iz
$\{0,\ldots,2^{#w#}\}$. To ustvari $2#w#$-bitno zgoščeno vrednost, katere možnost kolizije je $1/2^{#w#}$.  To se lahko zmanjša na #w#-bitno zgoščeno vrednost z uporabo množilne zgo-šče-valne funkcije. Ta metoda je hitra, ker zahteva samo $r/2$ $2#w#$-bitnih množenj, metoda omenjena v \secref{stringhash} pa zahteva $r$ množenj.
($\bmod$ operacije se dogajajo zaporedno z uporabo #w# in $2#w#$-bitne
aritmetične operacije za seštevanje in množenje.)

Metoda iz \secref{polyhash}, ki uporablja polinome in polja praštevil za zgoščevanje tabel in nizov spremenljive dolžine je zastarela po mnenju Dietzfelbingerja \etal\
\cite{dgmp92}.  Zaradi njene uporabe $\bmod$ operatorja, ki se zanaša na potrošne strojne ukaze je na žalost počasna.
Nekatere različice te metode določijo praštevilo #p# iz obrazca $2^{#w#}-1$. V tem primeru se lahko operator $\bmod$ zamenja s prištevanjem (#+#) in logično in(#&#) operacijo \cite[Section~3.6]{k97v2}. Druga možnost je uporaba hitrejše metode za nize fiksne velikosti pri blokih dolžine $c$ za neko konstanto $c>1$ in potem metode s polji praštevil za zaporedje $\lceil r/c\rceil$ zgoščenih vrednosti.

\begin{exc}
  Nekatere univerze vsakemu študentu določijo študentsko številko, ko se prvič prijavijo za katerikoli predmet. Te številke so zaporedna cela števila, ki so se začela z 0 mnogo let nazaj in so sedaj zapisana že v milijonih. Recimo, da imamo razred stotih novih študentov in bi radi vsakemu študentu dodelili zgoščeno vrednost, ki je odvisna od njihovih študentskih številk. Ali ima več smisla uporabiti prvi dve števki ali zadnji dve števki študentske številke? Pojasni svoj odgovor.
\end{exc}

\translatedby{Davor Vertelj, Lenč Skumavec}{sl}
\begin{exc}
  Upoštevajte zgoščevalno funkcijo iz odstavka \secref{multihash}, in predpostavite, da je
  $#n#=2^{#d#}$ and $#d#\le #w#/2$.
  \begin{enumerate}
    \item Pokažite, da za vsakega izbranega množitelja, #z#, obstajajo vrednosti #n#, ki imajo enako zgoščeno vrednost. (Namig: Gre za preprosto rešitev, ki ne zahteva teorije števil).
    \item Glede na podanega množitelja, #z#, opišite tiste vrednosti  #n#, ki imajo enako
zgoščeno vrednost. (Hint: Ta primer je zahtevnejši in zahteva poznavanje osnov teorije števil.)
  \end{enumerate}
\end{exc}

\begin{exc}
  Pokažite, da je meja dovoljene vrednosti $2/2^{#d#}$ v trditvi \lemref{universal-hashing} najboljša možna meja, če je $x=2^{#w#-#d#-2}$ in
  $#y#=3#x#$, then $\Pr\{#hash(x)#=#hash(y)#\}=2/2^{#d#}$.  (Namig: Poglejte si binarni prikaz za $#zx#$ in $#z#3#x#$ in upoštevajte dejstvo, da je $#z#3#x# = #z#x#+2#z#x#$.)
\end{exc}

\begin{exc}\exclabel{linear-probing}
  Dokažite trditev \lemref{linear-probing} z uporabo Stirlingove aproksimacije iz poglavja \secref{factorials}.
\end{exc}

\begin{exc}
  Upoštevajte spodnjo poenostavljeno verzijo kode za dodajanje elementa #x# v #LinearHashTable# (linearno razpršeno tabelo), ki element #x# shrani v
prvo polje v tabeli, ki vsebuje vrednost #null#. Opišite zakaj je ta način dodajanja elementov zelo počasen. Pokažite to na primeru zaporednega izvajanja operacij  $O(#n#)$ #add(x)#, #remove(x)#,
  in #find(x)#, ki za izvedbo porabijo $#n#^2$ časa.
\codeimport{ods/LinearHashTable.addSlow(x)}
\end{exc}

\begin{exc}
  Zgodnejše verzije metode Java #hashCode()# za razred #String# ni delovala
  tako, da bi uporabila vse znake v dolgem nizu. Naprimer, za 16 znakov dolg
  niz se je koda razpršitve izračunala glede na osem sodo indeksiranih znakov. 
  Na primeru pojasnite zakaj to ni bila pametna ideja. Primer naj sestoji
  iz večjega nabora nizov, pri čemer naj imajo vsi enako kodo razpršitve.
\end{exc}

\begin{exc}\exclabel{hash-hack-first}
  Predpostavite da imate objekt sestavljen iz dveh #w#-bitnih števil, #x# in #y#. 
  Pokažite zakaj $#x#\oplus#y#$ ni dobra koda razpršitve za vaš objekt. Pokažite tudi 
  primer večje množice objektov, kjer bi vsi imeli kodo raz-pr-ši-tve 0.
\end{exc}

\begin{exc}
  Predpostavite da imate objekt sestavljen iz dveh #w#-bitnih števil, #x# in #y#. 
  Pokažite zakaj $#x#+#y#$ ni dobra koda razpršitve za vaš objekt. Pokažite tudi 
  primer večje množice objektov, kjer bi vsi imeli enako kodo razpršitve.
\end{exc}

\begin{exc}\exclabel{hash-hack-last}
  Predpostavite da imate objekt sestavljen iz dveh #w#-bitnih števil, #x# in #y#. Predpostavite
  tudi, da je koda razpršitve za vaš objekt definirana z deterministično funkcijo $h(#x#,#y#)$, ki ustvari eno samo #w#-bitno število. Dokažite da obstaja večja množica objektov, ki 
  imajo enako kodo razpršitve.
\end{exc}

\begin{exc}
  Naj za neko pozitivno število #w# velja $p=2^{#w#}-1$. Razložite zakaj za pozitivno število 
  $x$ velja 
  \[
      (x\bmod 2^{#w#}) + (x\ddiv 2^{#w#}) \equiv x \bmod (2^{#w#}-1) \enspace .
  \]
  (Dobimo algoritem za računanje $x \bmod (2^{#w#}-1)$ s pomočjo zaporednega nastavljanja 
  \javaonly{\[
    #x = x&((1<<w)-1) + x>>>w#
  \]}
  \cpponly{\[
    #x = x&((1<<w)-1) + x>>w#
  \]}
  dokler ne velja $#x# \le 2^{#w#}-1$.)
\end{exc}

\begin{exc}
  Izberite neko pogostokrat uporabljeno implementacijo zgo-šče-ne tabele kot je recimo \javaonly{JavaCollection Framework #HashMap#}\cpponly{The C++ STL #unordered\_map#} ali #HashTable# oziroma #LinearHashTable# iz te knjige in napišite program, ki v to podatkovno strukturo shranjuje števila, #x#, tako da je časovna zahtevnost funkcije #find(x)# linearna. Se pravi, poiščite množico #n# števil v kateri je $c#n#$ elementov, katerih koda razpršitve je na isti lokaciji v tabeli.
  Odvisno od kvalitete implementacije boste to mogoče lahko dosegli že samo z natančnim pregledom kode ali pa boste morali napisati nekaj vrstic kode, ki bo poskušala z vstavljanjem in iskanjem elementov ter merjenjem časa za dodajanje in iskanje posameznih vrednosti. (To se lahko, se tudi že je, uporabi za napad DOS(denial of service) na strežnike \cite{cw03}.)
  \index{algorithmic complexity attack}%
\end{exc}
