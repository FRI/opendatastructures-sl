\chapter{Graphs}
\chaplabel{graphs}

%\textbf{Warning to the Reader:} This chapter is still being actively
%developed, meaning that the code has not been thoroughly tested and/or
%the text has not be carefully proofread.
V tem poglavju bomo pregledali dve predstavitvi grafov in osnovne algoritme, ki uporabljajo ti predstavitvi.
 
Matematično, je \emph{(usmerjen) graf}
\index{graph}%
\index{directed graph}%
par $G=(V,E)$ kjer je
$V$ množica \emph{točk}
\index{vertex}%
in $E$ ki je množica urejenih parov
točk in se imenujejo \emph{povezave}.
\index{edge}%
Povezava #(i,j)# je \emph{usmerjena}
\index{directed edge}%
od #i# do #j#;  #i# se imenuje \emph{izvor}
\index{source} povezave #j#
pa se imenuje \emph{tarča}.
\index{target}   \emph{Pot}%
\index{path} v $G$ je zaporedje
točk $v_0,\ldots,v_k$ za katere velja $i\in\{1,\ldots,k\}$,
katerih povezave $(v_{i-1},v_{i})$ so v $E$. Pot $v_0,\ldots,v_k$ je
\emph{cikel}
\index{cycle}%
če se povezava $(v_k,v_0)$ nahaja v $E$. Pot (ali
cikel) je \emph{preprosta}
\index{simple path/cycle}%
če so vse njegove točke unikatne.  Če obstaja pot od točke $v_i$ do neke točke $v_j$ potem rečemo da je
$v_j$ \emph{dosegljiv}
\index{reachable vertex} iz $v_i$. Primer grafa je prikazan v sliki \figref{graph}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph}
  \end{center}
  \caption{Graf z dvanajstimi točkami.  Točke so narisane kot oštevilčeni krogci ter povezave so narisane kot usmerjene krivulje od izvora do tarče.}
  \figlabel{graph}
\end{figure}

Zaradi njihove zmožnosti modeliranja mnogih pojavo imajo grafi ogromno število aplikacij. Obstaja mnogo očitnih primerov. Računalniško omrežje lahko zmodeliramo kot graf, s točkami ki pridstavljajo računalnike in povezave, ki predstavljajo (usmerjene) komunikacijske povezave med temi računalniki. Meste ulice lahko zmodeliramo kot grafe, katere tičke predstavljajo križišča, povezave pa predstavljajo ulice, ki se sekajo v teh križiščih.

Manj očitni primere se zgodijo, ko odkrijemo, da grafi lahko zmodelirajo vsa parna razmerja v množicah. Na primer na fakulteti imamo lahko urnik, ki predstavlja \emph{konflikten graf}
\index{conflict graph}%
njegove točke predstavljajo premete, ki jih nudi fakulteta, povezava #(i,j)# pa je prisotna, samo če obstaja študent, ki obiskuje predmet #i# in predmet #j#. Tukaj povezava predstavlja, da se rok izpita  #i# ne bi smel načrtovati istočasno kot rok za predmet #j#.

V tem poglavju bomo uporabljali #n# za označbo števila točk
grafa $G$ in #m# za označbo povezav grafa $G$. Torej je, $#n#=|V|$
in $#m#=|E|$. Kasneje, bomo predpostaavli $V=\{0,\ldots,#n#-1\}$.
Kakršni koli drug podatek, ki bi ga radi povezali z elmenti množice $V$ se lahko shrani kot tabela dolžine $#n#$.

Nekaj tipičnih operacij, ki se izvajajo nad grafom so:
\begin{itemize}
  \item #addEdge(i,j)#: Dodaj povezavo $(#i#,#j#)$ v $E$.
  \item #removeEdge(i,j)#: Odstrani povezavo $(#i#,#j#)$ iz $E$.
  \item #hasEdge(i,j)#: Preveri, če povezava $(#i#,#j#)\in E$ 
  \item #outEdges(i)#: Vrni #Seznam# vseh celih števil $#j#$ za katere velja $(#i#,#j#)\in E$
  \item #inEdges(i)#: Vrni #Seznam# vseh celih števil $#j#$ za katere velja  $(#j#,#i#)\in E$
\end{itemize}

Opazimo, da te operacije niso preveč zapletene za implementirati učinkovito. Na primer, prve tri operacije lahko implementiramo direktno z uporabo #USet#-a, tako so lahko implementirane v pričakovanem konstantem času z uporabo zgoščevalnih tabel, ki so opisane v \chapref{hashing}. Zadnji dve operaciji pa sta lahko implementirane v konstantnem času, tako da za vsako točko hranimo tudi njene sosedne točke.

However, different applications of graphs have different performance
requirements for these operations and, ideally, we can use the simplest
implementation that satisfies all the application's requirements.
For this reason, we discuss two broad categories of graph representations.

\section{#AdjacencyMatrix#: Representing a Graph by a Matrix}
\seclabel{adjacency-matrix}

\index{adjacency matrix}%
An \emph{adjacency matrix} is a way of representing an #n# vertex graph
$G=(V,E)$ by an $#n#\times#n#$ matrix, #a#, whose entries are boolean
values.
\codeimport{ods/AdjacencyMatrix.a.n.AdjacencyMatrix(n0)}

The matrix entry #a[i][j]# is defined as
\[  #a[i][j]#= 
    \begin{cases}
      #true# & \text{if $#(i,j)#\in E$} \\
      #false# & \text{otherwise}
    \end{cases}
\]
The adjacency matrix for the graph in \figref{graph} is
shown in \figref{graph-adj}.

In this representation, the operations #addEdge(i,j)#,
#removeEdge(i,j)#, and #hasEdge(i,j)# just
involve setting or reading the matrix entry #a[i][j]#:
\codeimport{ods/AdjacencyMatrix.addEdge(i,j).removeEdge(i,j).hasEdge(i,j)}
These operations clearly take constant time per operation.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph} \\[3ex]
    \begin{tabular}{c|cccccccccccc}
        &0&1&2&3&4&5&6&7&8&9&10&11 \\\hline
       0&0&1&0&0&1&0&0&0&0&0&0 &0\\
       1&1&0&1&0&0&1&1&0&0&0&0 &0\\
       2&1&0&0&1&0&0&1&0&0&0&0 &0\\
       3&0&0&1&0&0&0&0&1&0&0&0 &0\\
       4&1&0&0&0&0&1&0&0&1&0&0 &0\\
       5&0&1&1&0&1&0&1&0&0&1&0 &0\\
       6&0&0&1&0&0&1&0&1&0&0&1 &0\\
       7&0&0&0&1&0&0&1&0&0&0&0 &1\\
       8&0&0&0&0&1&0&0&0&0&1&0 &0\\
       9&0&0&0&0&0&1&0&0&1&0&1 &0\\
      10&0&0&0&0&0&0&1&0&0&1&0 &1\\
      11&0&0&0&0&0&0&0&1&0&0&1 &0\\
    \end{tabular} 
  \end{center}
  \caption{A graph and its adjacency matrix.}
  \figlabel{graph-adj}
\end{figure}

Where the adjacency matrix performs poorly is with the #outEdges(i)# and
#inEdges(i)# operations.  To implement these, we must scan all #n#
entries in the corresponding row or column of #a# and gather up all the
indices, #j#, where #a[i][j]#, respectively #a[j][i]#, is true.
\javaimport{ods/AdjacencyMatrix.outEdges(i).inEdges(i)}
\cppimport{ods/AdjacencyMatrix.outEdges(i,edges).inEdges(i,edges)}
These operations clearly take $O(#n#)$ time per operation.  

Another drawback of the adjacency matrix representation is that it
is large.  It stores an $#n#\times #n#$ boolean matrix, so it requires at
least $#n#^2$ bits of memory.  The implementation here uses a matrix
of \javaonly{#boolean#}\cpponly{#bool#} values so it actually uses on the
order of $#n#^2$ bytes of memory.  A more careful implementation, which
packs #w# boolean values into each word of memory, could reduce this
space usage to $O(#n#^2/#w#)$ words of memory.

\begin{thm}
The #AdjacencyMatrix# data structure implements the #Graph# interface.
An #AdjacencyMatrix# supports the operations
\begin{itemize}
  \item #addEdge(i,j)#, #removeEdge(i,j)#, and #hasEdge(i,j)# in constant
  time per operation; and
  \item #inEdges(i)#, and #outEdges(i)# in $O(#n#)$ time per operation.
\end{itemize}
The space used by an #AdjacencyMatrix# is  $O(#n#^2)$.
\end{thm}

Despite its high memory requirements and poor performance of the #inEdges(i)#
and #outEdges(i)# operations, an #AdjacencyMatrix# can still be useful for
some applications.  In particular, when the graph $G$ is \emph{dense},
i.e., it has close to $#n#^2$ edges, then a memory usage of $#n#^2$
may be acceptable.

The #AdjacencyMatrix# data structure is also commonly used because
algebraic operations on the matrix #a# can be used to efficiently compute
properties of the graph $G$.  This is a topic for a course on algorithms,
but we point out one such property here:  If we treat the entries of #a#
as integers (1 for #true# and 0 for #false#) and multiply #a# by itself
using matrix multiplication then we get the matrix $#a#^2$.  Recall,
from the definition of matrix multiplication, that
\[
    #a^2[i][j]# = \sum_{k=0}^{#n#-1} #a[i][k]#\cdot #a[k][j]# \enspace .
\]
Interpreting this sum in terms of the graph $G$, this formula counts the
number of vertices, $#k#$, such that $G$ contains both edges #(i,k)#
and #(k,j)#.  That is, it counts the number of paths from $#i#$ to $#j#$
(through intermediate vertices, $#k#$) whose length is exactly two.
This observation is the foundation of an algorithm that computes the
shortest paths between all pairs of vertices in $G$ using only $O(\log
#n#)$ matrix multiplications.

\section{#AdjacencyLists#: A Graph as a Collection of Lists}
\seclabel{adjacency-list}
\translatedby{Dev Kordeš}{sl}

\index{adjacency list}%
\emph{Seznam sosednosti} - ponazoritev grafov vzame pristop bolj usmerjen 
v vozlišča. Obstaja veliko možnih izvedb seznamov sosednosti. 
V tem poglavju predstavljamo preprosto izvedbo. Na koncu odseka, 
razpravljamo o različnih možnostih. V seznamu sosednosti je graf 
$G=(V,E)$ predstavljen kot polje, #adj#, seznamov.  Seznam
#adj[i]# vsebuje seznam vseh vozlišč sosednjih vozlišču #i#.
Vsebuje vsak #j# tako, da $#(i,j)#\in E$.
\codeimport{ods/AdjacencyLists.adj.n.AdjacencyLists(n0)}
(Primer je pokazan v \figref{graph-adjlist}.)  V tej specifični implementaciji,
pokažemo vsak seznam #adj# kot \javaonly{an}\cpponly{a
subclass of} #ArrayStack#, ker želimo doseči konstanten čas dostopov
do pozicij. Mogoče so tudi drugačne opcije.  Ena opcija je 
implementiranje #adj# kot #DLList#.


\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph} \\[3ex]
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}\hline
        0&1&2&3&4&5&6 &7 &8&9 &10&11 \\\hline
        1&0&1&2&0&1&5 &6 &4&8 &9 &10 \\
        4&2&3&7&5&2&2 &3 &9&5 &6 &7 \\
         &6&6& &8&6&7 &11& &10&11& \\
         &5& & & &9&10&  & &  &  & \\
         & & & & &4&  &  & &  &  & \\
    \end{tabular} 
  \end{center}
  \caption{A graph and its adjacency lists}
  \figlabel{graph-adjlist}
\end{figure}



Operacija #addEdge(i,j)# doda vrednost  #j# seznamu #adj[i]#:
\codeimport{ods/AdjacencyLists.addEdge(i,j)}
To se izvede v konstantem času.

Operacija #removeEdge(i,j)# pregleda seznam #adj[i]#
dokler ne najde #j# in ga odstrani iz seznama:
\codeimport{ods/AdjacencyLists.removeEdge(i,j)}
To se izvede v  $O(\deg(#i#))$ času, kjer $\deg(#i#)$ (\emph{stopnja}
\index{degree}%
$#i#$ -ja) prešteje število robov v $E$, ki imajo $#i#$ za njihov vir.

Operacija #hasEdge(i,j)# je podobna;  pregleda seznam
#adj[i]# dokler ne najde #j# (in vrne true), ali doseže konec
seznama (in vrne false):
\codeimport{ods/AdjacencyLists.hasEdge(i,j)}
To se izvede v $O(\deg(#i#))$ času.

Operacija #outEdges(i)# je zelo preprosta;
\javaimport{ods/AdjacencyLists.outEdges(i)}
\cppimport{ods/AdjacencyLists.outEdges(i,edges)}
\javaonly{To se očitno izvede v konstantem času.}\cpponly{To se očitno izvede v $O(\deg(#i#))$ času.}

Operacija #inEdges(i)# je veliko več dela.  Operacija pogleda vsako
vozlišče $j$ če obstaja #(i,j)# in, če tako, doda #j#
v izhodni seznam:
\javaimport{ods/AdjacencyLists.inEdges(i)}
\cppimport{ods/AdjacencyLists.inEdges(i,edges)}
Operacija je zelo počasna. Pregleda seznam sosednosti vsakega vozlišča
in se izvede v $O(#n# + #m#)$ času.

Naslednji izrek povzema delovanje zgornje podatkovne strukture:

\begin{thm}
Podatkovna struktura #AdjacencyLists# implementira vmesnik #Graph#.
#AdjacencyLists# podpira operacije
\begin{itemize}
  \item #addEdge(i,j)# v konstantem času na operacijo;
  \item #removeEdge(i,j)# in #hasEdge(i,j)# v $O(\deg(#i#))$ času
    na operacijo;
  \javaonly{\item #outEdges(i)# v konstantem časi na operacijo; in}
  \cpponly{\item #outEdges(i)# v $O(\deg(#i#))$ času na operacijo; in}
  \item #inEdges(i)# v $O(#n#+#m#)$ času na operacijo.
\end{itemize}
#AdjacencyLists# porabi  $O(#n#+#m#)$ prostora.
\end{thm}

Obstaja veliko možnosti kako lahko implementiramo graf kot seznam 
sosednosti. Ena izmed vprašanj ki se nam porajajo so:
\begin{itemize}
  \item Kakšno zbirko podatkov uporabiti za shranjevanje vsakega elementa v 
  #adj#?  Lahko bi uporabili array-based list, linked-list, ali celo
  hashtable.
  \item Lahko bi uporabili drug seznam sosednosti, #inadj#, ki hrani
  za vsak #i#, seznam vozlišč #j#, tako da $#(j,i)#\in E$
  Zo lahko močno poveča učinkovitost operacije #inEdges(i)#, 
  ampak rahlo zmanjša učinkovitost dodajanja in brisanja robov.
  \item Lahko bi vpis za rob #(i,j)# v #adj[i]# bil povezan z
  referenco na ustrezni vpis v #inadj[j]#
  \item Lahko bi robovi bili prvorazredni objekti z njihovimi asociativnimi podatki
  Tako bi #adj# vseboval seznam robov namesto seznama vozlišč (integers).
\end{itemize}
Pri večini gornjih vprašanj pride do kompromisa med kompleksnostjo (in 
prosotorom) implementacije in uspešnostjo funkcij implementacije.

\section{Graph Traversal}

In this section we present two algorithms for exploring a graph,
starting at one of its vertices, #i#, and finding all vertices that
are reachable from #i#.  Both of these algorithms are best suited to
graphs represented using an adjacency list representation.  Therefore,
when analyzing these algorithms we will assume that the underlying
representation is an #AdjacencyLists#.

\subsection{Breadth-First Search}

\index{breadth-first-search}%
The \emph{bread-first-search} algorithm starts at a vertex #i# and visits,
first the neighbours of #i#, then the neighbours of the neighbours of #i#,
then the neighbours of the neighbours of the neighbours of #i#, and so on.

This algorithm is a generalization of the breadth-first traversal
algorithm for binary trees (\secref{bintree:traversal}), and is
very similar; it uses a queue, #q#, that initially contains only #i#.
It then repeatedly extracts an element from #q# and adds its neighbours
to #q#, provided that these neighbours have never been in #q# before.
The only major difference between the breadth-first-search algorithm
for graphs and the one for trees is that the algorithm for graphs has
to ensure that it does not add the same vertex to #q# more than once.
It does this by using an auxiliary boolean array, #seen#, that tracks
which vertices have already been discovered.
\codeimport{ods/Algorithms.bfs(g,r)}
An example of running #bfs(g,0)# on the graph from \figref{graph}
is shown in \figref{graph-bfs}.  Different executions are possible,
depending on the ordering of the adjacency lists; \figref{graph-bfs}
uses the adjacency lists in \figref{graph-adjlist}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph-bfs}
  \end{center}
  \caption[Breadth-first-search]{An example of bread-first-search starting at node 0. Nodes are
  labelled with the order in which they are added to #q#.  Edges that
  result in nodes being added to #q# are drawn in black, other edges
  are drawn in grey.}
  \figlabel{graph-bfs}
\end{figure}

Analyzing the running-time of the #bfs(g,i)# routine is fairly
straightforward.  The use of the #seen# array ensures that no vertex is
added to #q# more than once.  Adding (and later removing) each vertex
from #q# takes constant time per vertex for a total of $O(#n#)$ time.
Since each vertex is processed by the inner loop at most once, each
adjacency list is processed at most once, so each edge of $G$ is processed
at most once.  This processing, which is done in the inner loop takes
constant time per iteration, for a total of $O(#m#)$ time.  Therefore,
the entire algorithm runs in $O(#n#+#m#)$ time.

The following theorem summarizes the performance of the #bfs(g,r)# algorithm.
\begin{thm}\thmlabel{bfs-graph}
  When given as input a #Graph#, #g#, that is implemented using the
  #AdjacencyLists# data structure, the #bfs(g,r)# algorithm runs in $O(#n#+#m#)$
  time.
\end{thm}

A breadth-first traversal has some very special properties.  Calling
#bfs(g,r)# will eventually enqueue (and eventually dequeue) every vertex
#j# such that there is a directed path from #r# to #j#.  Moreover,
the vertices at distance 0 from #r# (#r# itself) will enter #q# before
the vertices at distance 1, which will enter #q# before the vertices at
distance 2, and so on.  Thus, the #bfs(g,r)# method visits vertices
in increasing order of distance from #r# and vertices that cannot be
reached from #r# are never visited at all.

A particularly useful application of the breadth-first-search algorithm
is, therefore, in computing shortest paths.  To compute the shortest
path from #r# to every other vertex, we use a variant of #bfs(g,r)#
that uses an auxilliary array, #p#, of length #n#.  When a new vertex
#j# is added to #q#, we set #p[j]=i#.  In this way, #p[j]# becomes the
second last node on a shortest path from #r# to #j#.  Repeating this,
by taking #p[p[j]#, #p[p[p[j]]]#, and so on we can reconstruct the
(reversal of) a shortest path from #r# to #j#.



\subsection{Depth-First Search}

The \emph{depth-first-search}
\index{depth-first-search}%
algorithm is similar to the standard
algorithm for traversing binary trees;  it first fully explores one
subtree before returning to the current node and then exploring the
other subtree.  Another way to think of depth-first-search is by saying
that it is similar to breadth-first search except that it uses a stack
instead of a queue.

During the execution of the depth-first-search algorithm, each vertex,
#i#, is assigned a colour, #c[i]#: #white# if we have never seen
the vertex before, #grey# if we are currently visiting that vertex,
and #black# if we are done visiting that vertex.  The easiest way to
think of depth-first-search is as a recursive algorithm.  It starts by
visiting #r#.  When visiting a vertex #i#, we first mark #i# as #grey#.
Next, we scan #i#'s adjacency list and recursively visit any white vertex
we find in this list.  Finally, we are done processing #i#, so we colour
#i# black and return.
\codeimport{ods/Algorithms.dfs(g,r).dfs(g,i,c)}
An example of the execution of this algorithm is shown in \figref{graph-dfs}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/graph-dfs}
  \end{center}
  \caption[Depth-first-search]{An example of depth-first-search starting at node 0. Nodes are
  labelled with the order in which they are processed.  Edges that
  result in a recursive call are drawn in black, other edges
  are drawn in #grey#.}
  \figlabel{graph-dfs}
\end{figure}

Although depth-first-search may best be thought of as a recursive
algorithm, recursion is not the best way to implement it. Indeed, the code
given above will fail for many large graphs by causing a stack overflow.
An alternative implementation is to replace the recursion stack with an
explicit stack, #s#.  The following implementation does just that:
\codeimport{ods/Algorithms.dfs2(g,r)} 
In the preceding code, when the next vertex, #i#, is processed, #i# is coloured
#grey# and then replaced, on the stack, with its adjacent vertices.
During the next iteration, one of these vertices will be visited.

Not surprisingly, the running times of #dfs(g,r)# and #dfs2(g,r)# are the
same as that of #bfs(g,r)#:
\begin{thm}\thmlabel{dfs-graph}
  When given as input a #Graph#, #g#, that is implemented using the
  #AdjacencyLists# data structure, the #dfs(g,r)# and #dfs2(g,r)# algorithms
  each run in $O(#n#+#m#)$ time.
\end{thm}

As with the breadth-first-search algorithm, there is an underlying
tree associated with each execution of depth-first-search.  When a node
$#i#\neq #r#$ goes from #white# to #grey#, this is because #dfs(g,i,c)#
was called recursively while processing some node #i'#.  (In the case
of #dfs2(g,r)# algorithm, #i# is one of the nodes that replaced #i'#
on the stack.)  If we think of #i'# as the parent of #i#, then we obtain
a tree rooted at #r#.  In \figref{graph-dfs}, this tree is a path from
vertex 0 to vertex 11.

An important property of the depth-first-search algorithm is the
following: Suppose that when node #i# is coloured #grey#, there exists a path
from #i# to some other node #j# that uses only white vertices.  Then #j#
will be coloured first #grey# then #black# before #i# is coloured #black#.
(This can be proven by contradiction, by considering any path $P$ from #i#
to #j#.)

One application of this property is the detection of cycles.
\index{cycle detection}%
Refer
to \figref{dfs-cycle}.  Consider some cycle, $C$, that can be reached
from #r#.  Let #i# be the first node of $C$ that is coloured #grey#,
and let #j# be the node that precedes #i# on the cycle $C$.  Then,
by the above property, #j# will be coloured #grey# and the edge #(j,i)#
will be considered by the algorithm while #i# is still #grey#.  Thus,
the algorithm can conclude that there is a path, $P$, from #i# to #j#
in the depth-first-search tree and the edge #(j,i)# exists.  Therefore,
$P$ is also a cycle.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/dfs-cycle}
  \end{center}
  \caption[Cycle detection]{The depth-first-search algorithm can be used to detect cycles
  in $G$. The node #j# is coloured #grey# while #i# is still #grey#.  This
  implies that there is a path, $P$, from #i# to #j# in the depth-first-search
  tree, and the edge #(j,i)# implies that $P$ is also a cycle.}
  \figlabel{dfs-cycle}
\end{figure}

\section{Discussion and Exercises}

The running times of the depth-first-search and breadth-first-search
algorithms are somewhat overstated by the Theorems~\ref{thm:bfs-graph} and
\ref{thm:dfs-graph}.  Define $#n#_{#r#}$ as the number of vertices, #i#,
of $G$, for which there exists a path from #r# to #i#.  Define $#m#_#r#$
as the number of edges that have these vertices as their sources.
Then the following theorem is a more precise statement of the running
times of the breadth-first-search and depth-first-search algorithms.
(This more refined statement of the running time is useful in some of
the applications of these algorithms outlined in the exercises.)
\begin{thm}\thmlabel{graph-traversal}
  When given as input a #Graph#, #g#, that is implemented using the
  #AdjacencyLists# data structure, the #bfs(g,r)#, #dfs(g,r)# and #dfs2(g,r)#
  algorithms each run in $O(#n#_{#r#}+#m#_{#r#})$ time.
\end{thm}

Breadth-first search seems to have been discovered independently by
Moore \cite{m59} and Lee \cite{l61} in the contexts of maze exploration
and circuit routing, respectively.

Adjacency-list representations of graphs were presented by
Hopcroft and Tarjan \cite{ht73} as an alternative to the (then more
common) adjacency-matrix representation.  This representation, as well as
depth-first-search, played a major part in the celebrated Hopcroft-Tarjan
planarity testing algorithm 
\index{planarity testing}%
that can determine, in $O(#n#)$ time, if
a graph can be drawn, in the plane, and in such a way that no pair of
edges cross each other \cite{ht74}.

In the following exercises, an undirected graph is one in which, for
every #i# and #j#, the edge $(#i#,#j#)$ is present if and only if the
edge $(#j#,#i#)$ is present.
\index{undirected graph}%
\index{graph!undirected}%

\begin{exc}
  Draw an adjacency list representation and an adjacency matrix
  representation of the graph in \figref{graph-example2}.
\end{exc}

\begin{figure}
  \centering{\includegraphics[scale=0.90909]{figs/graph-example2}}
  \caption{An example graph.}
  \figlabel{graph-example2}
\end{figure}

\begin{exc}
  \index{incidence matrix}%
  The \emph{incidence matrix} representation of a graph,
  $G$, is an $#n#\times#m#$ matrix, $A$, where
  \[
     A_{i,j} = \begin{cases}
        -1 & \text{if vertex $i$ the source of edge $j$} \\
        +1 & \text{if vertex $i$ the target of edge $j$} \\
        0 & \text{otherwise.}
     \end{cases}
  \]
  \begin{enumerate}
    \item Draw the incident matrix representation of the graph in
      \figref{graph-example2}.
    \item Design, analyze and implement an incidence matrix representation
      of a graph.  Be sure to analyze the space, the cost of
      #addEdge(i,j)#, #removeEdge(i,j)#, #hasEdge(i,j)#, #inEdges(i)#,
      and #outEdges(i)#.
  \end{enumerate}
\end{exc}

\begin{exc}
  Illustrate an execution of the #bfs(G,0)# and #dfs(G,0)# on the graph, $#G#$,
  in \figref{graph-example2}.
\end{exc}

\begin{exc}
  \index{connected graph}%
  \index{graph!connected}%
  Let $G$ be an undirected graph.  We say $G$ is \emph{connected} if,
  for every pair of vertices #i# and #j# in $G$, there is a path from
  $#i#$ to $#j#$ (since $G$ is undirected, there is also a path from #j#
  to #i#). Show how to test if $G$ is connected in $O(#n#+#m#)$ time.
\end{exc}

\begin{exc}
  \index{connected components}%
  Let $G$ be an undirected graph.  A \emph{connected-component labelling}
  of $G$ partitions the vertices of $G$ into maximal sets, each of which
  forms a connected subgraph.  Show how to compute a connected component
  labelling of $G$ in $O(#n#+#m#)$ time.
\end{exc}

\begin{exc}
  \index{spanning forest}%
  Let $G$ be an undirected graph.  A \emph{spanning forest} of $G$ is a
  collection of trees, one per component, whose edges are edges of $G$
  and whose vertices contain all vertices of $G$.  Show how to compute
  a spanning forest of of $G$ in $O(#n#+#m#)$ time.
\end{exc}

\begin{exc}
  \index{strongly-connected graph}%
  \index{graph!strongly-connected}%
  We say that a graph $G$ is \emph{strongly-connected} if, for every
  pair of vertices #i# and #j# in $G$, there is a path from $#i#$ to
  $#j#$. Show how to test if $G$ is strongly-connected in $O(#n#+#m#)$
  time.
\end{exc}

\begin{exc}
  Given a graph $G=(V,E)$ and some special vertex $#r#\in V$, show how
  to compute the length of the shortest path from $#r#$ to #i# for every
  vertex $#i#\in V$.
\end{exc}

\begin{exc}
  Give a (simple) example where the #dfs(g,r)# code visits the nodes of a
  graph in an order that is different from that of the #dfs2(g,r)# code.
  Write a version of #dfs2(g,r)# that always visits nodes in exactly
  the same order as #dfs(g,r)#.  (Hint: Just start tracing the execution
  of each algorithm on some graph where #r# is the source of more than
  1 edge.)
\end{exc}

\begin{exc}
  \index{universal sink}%
  \index{celebrity|see{universal sink}}%
  A \emph{universal sink} in a graph $G$ is a vertex that is the target
  of $#n#-1$ edges and the source of no edges.\footnote{A universal sink,
  #v#, is also sometimes called a \emph{celebrity}: Everyone in the room
  recognizes #v#, but #v# doesn't recognize anyone else in the room.}
  Design and implement an algorithm that tests if a graph $G$, represented
  as an #AdjacencyMatrix#, has a universal sink.  Your algorithm should
  run in $O(#n#)$ time.
\end{exc}
