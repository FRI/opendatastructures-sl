\chapter{Algoritmi za urejanje}
\chaplabel{sorting}
\translatedby{Matic Teršek}{sl}
\translatedby{Nejc Thaler}{sl}
\translatedby{Aleš Turk}{sl}

V tem poglavju se bomo pogovarjali o algoritmih, ki uredijo zbirko #n# elementov. To se lahko sliši kot čudna tema v knjigi podatkovnih struktur, ampak za to obstaja nekaj dobrih razlogov. Najočitnejši je ta, da sta dva od urejevalnih algoritmov(hitro urejanje in urejanje s kopico) tesno povezana s podatkovnima strukturama, ki smo ju že obdelali(naključno binarno drevo in kopice).

V prvem delu tega poglavja bo govora o algoritmih, ki uporabljajo zgolj primerjanje in sicer tri take algoritme s časovno zahtevnostjo $O(#n#\log #n#)$.
Kot se izkaže, so vsi trije algoritmi asimptotično optimalni. Se pravi vsak algoritem, ki uporablja zgolj primerjanje izvede približno $#n#\log#n#$ primerjav v najslabšem kot tudi v povprečnem primeru.

Preden nadaljujemo velja izpostaviti, da lahko uporabimo katerikoli implementacijo urejene množice ali prioritetne vrste, ki smo jih predstavili v prejšnjih poglavjih, da dobimo urejevalni algoritem s časovno zahtevnostjo $O(#n#\log #n#)$. Naprimer, lahko uredimo #n# elemente tako, da izvedemo najprej #n# #add(x)# operacij, nato pa #n# #remove()# operacij na binarni ali zdržljivi kopici. Alternativno lahko uporabimo tudi #n# #add(x)# operacij na katerimkoli binarnim iskalnim drevesom, kjer nato izvedemo vmesno prečkanje(vaja 6.8), da dobimo elemente v urejenem vrstnem redu. Vendar si v obeh primerih naredimo veliko preglavic, da zgradimo strukturo, ki je nikoli ne uporabljamo v celoti. Urejanje je tako pomembna težava, da je vredno razviti direktne metode, ki so kot se le da hitre, preproste in prostorsko učnkovite.

Drugi del tega poglavja kaže, da ne obstaja časovnih zagotovil, če uporabimo katerekoli druge operacije razen primerjave. Je pa res, da lahko s tabelnim indeksiranjem uredimo množico #n# števil v območju $\{0,\ldots,#n#^c-1\}$ s časovno zahtevnostjo $O(c#n#)$.

\section{Comparison-Based Sorting}
\index{comparison-based sorting}%
\index{sorting algorithm!comparison-based}%
V tem delu bomo predstavili tri algoritme za urejanje: urejanje z zlivanjem, hitro urejanje in urejanje s kopico. Vsak izmed teh treh algoritmov sprejme kot prvi argument tabelo #a#, ki jo uredi v naraščujočem vrstnem redu v (pričakovanem) času $O(#n#\log #n#)$. Vsi ti algoritmi delujejo na osnovi primerjav. Njihov drugi argument #c# je #primerjalnik# ki implementira metodo #compare(a,b)#. Ti urejevalni algoritmi nimajo privzetega tipa podatkov, ker izvajajo zgolj operacijo compare(a,b). Spomnimo se poglavja 1.2.4, kjer smo se naučili, da #compare(a,b)# vrača negativno vrednost če je $#a#<#b#$, pozitivno, če je vrednost $#a#>#b#$ in nič, če je $#a#=#b#$.

\subsection{Merge-Sort}
\seclabel{merge-sort}

\index{merge-sort}%
Algoritem \emph{urejanja z zlivanjem} je klasičen primer rekurzivnega algoritma deli in vladaj.
Če je dolžina od #a# največ 1, potem je #a# že urejen in zato ne naredimo ničesar. V nasprotnem primeru
pa #a# razdelimo na dva dela, $#a0#=#a#[0],\ldots,#a#[#n#/2-1]$ in $#a1#=#a#[#n#/2],\ldots,#a#[#n#-1]$. Nato rekurzivno uredimo #a0# in #a1# ter ju nato združimo s čimer dobimo popolno urejeno tabelo #a#.

V primerjavi z urejanjem je zlivanje urejenih tabel #a0# in #a1# dokaj enostavno. Elemente dodajamo enega za drugim. Če je #a0# ali #a1# prazna, potem dodajamo naslednje elementi iz druge(ne prazne) tabele. Sicer vzamemo manjšega od nasledjih elementov iz obeh tabel in ga dodamo v #a#:

\javaimport{ods/Algorithms.merge(a0,a1,a,c)}
\cppimport{ods/Algorithms.merge(a0,a1,a)}

Opazimo, da algoritem #merge(a0,a1,a,c)# v najslabšem primeru izvede $#n#-1$ primerjav, preden izprazne #a0# ali #a1#.

Da bi lažje razumeli čas izvajanja urejanja z zlivanjem, si ga je najbolje predstavljati kot njegovo rekurzivno drevo. Zaenkrat predpostavimo, da je #n# potenca števila dve, tako da je $#n#=2^{\log #n#}$, $\log #n#$ pa je celo število.
Glej sliko \figref{mergesort-recursion}. Urejanje z zlivanjem spremeni problem urejanja #n# elementov v dva problema urejanja $#n#/2$ elementov. Ta dva podproblema potem spremeni vsakega v dva nova podproblema, torej skupno v štiri probleme velikosti $#n#/4$. Te štiri nato razdelimo v osem podproblemov velikosti $#n#/8$ in tako dalje. Na koncu tega procesa $#n#/2$ podproblemov, vsakega velikosti dve, razdelimo v #n# problemov velikosti ena. Za vsak podproblem velikosti $#n#/2^{i}$ je čas zlivanja in kopiranja podatkov razreda $O(#n#/2^i)$. Ker imamo $2^i$ podproblemov velikosti $#n#/2^i$, je skupen čas reševanja problemov velikosti $2^i$, če ne štejemo rekurzivnih klicev:
$$2^i\times O(n/2^i) = O(n) \enspace .$$

\subsection{Quicksort}

\index{quicksort}%
Hitro urejanje ali \emph{quicksort} algoritem je še en klasični "deli in vladaj" algoritem. V nasprotju z algoritmom zlivanja (mergesort), kateri združuje po rešitvi dveh podproblemov, algoritem hitrega urejanja počne vse svoje delo vnaprej.\\

Algoritem lahko preprosto opišemo tako: Izberemo naključni delilni element, ki ga imenujemo \emph{pivot}, \index{pivot element}%
#x#, ki ga dobimo iz #a#; Razdelek #a# je sestavljena iz sklopa elementov manjših od #x#, sklopa elementov enakih kot #x# in niz elementov večjih od #x#; na koncu rekurzivno razvrstimo prvi in tretji sklop števil v tem razdelku. Primer je prikazan na sliki \figref{quicksort}.
\javaimport{ods/Algorithms.quickSort(a,c).quickSort(a,i,n,c)}
\cppimport{ods/Algorithms.quickSort(a).quickSort(a,i,n)}
\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.90909]{figs/quicksort}
    \caption[Quicksort]{Primer izvajanja \javaonly{#quickSort(a,0,14,c)#} \cpponly{#quickSort(a,0,14)#}}
    \figlabel{quicksort}
  \end{center}
\end{figure}
Vse to je narejeno v enem koraku, tako da namesto ustvarjanja kopij urejenih podseznamov, #quickSort(a,i,n,c)# metoda razvršča samo podseznam $#a[i]#,\ldots,#a[i+n-1]#$. Prvotno kličemo to metodo kot\\
#quickSort(a,0,a.length,c)#. \\

V središču quicksort algoritma je algoritem delitve na mestu. Ta algoritem, brez uporabe dodatnega prostora, zamenja elemente v #a# in izračuna indekse #p# in #q# tako da:
\[
   #a[i]# \begin{cases} 
         {}< #x# & \text{če $0\le #i#\le #p#$} \\
         {}= #x# & \text{če $#p#< #i# < #q#$} \\
         {}> #x# & \text{če $#q#\le #i# \le #n#-1$}
     \end{cases}
\]

Ta delitev, ki se opravi z #while# zanko v sami kodi, deluje s ponavljajočim povečanjem #p#-ja in zmanjševanjem #q#-ja ob ohranjanju prvega in zadnjega od teh pogojev (#p# in #q#). Ob vsakem koraku element na položaju #j# premaknemo na prvo mesto, ali pa na zadnje mesto. V prvih dveh primerih, je #j# povečan, v zadnjem primeru pa ne, ker nov element na položaju #j# še ni bil obdelan.\\

Quicksort algoritem je zelo tesno povezan z naključnim binarnim iskalnim drevesom, opisanem v poglavju \secref{rbst}. Pravzaprav, če poženemo quicksort algoritem nad #n# različnimi elementi, potem je quicksort-ovo rekurzivno drevo enako naključnemu iskalnemu drevesu. Da bi to videli, se moramo spomniti, kako gradimo naključno binarna iskalna drevesa. Najprej naključno izberemo element #x# in ga postavimo za koren drevesa. Nato vsak naslednji element primerjamo z #x#-om. Manjše elemente postavljamo v levo poddrevo, večje pa v desno poddrevo.\\

S tem algoritmom izberemo nakjučni element #x# in takoj za tem primerjamo vse elemente s tem #x#-om. Najmanjše elemente postavimo na začetek polja, večje pa postavimo na konec. Quicksort algoritem nato rekurzivno uredi začetek in konec polja, medtem ko naključno iskalno drevo rekurzivno vstavi manjše elemente v levo poddrevo korena in večje elemente v desno poddrevo korena.\\

Zgornje ujemanje med naključnim binarnim iskalnim drevesom in algoritmom hitrega urejanja lahko uporabimo za lemo \lemref{rbs}

\begin{lem}\lemlabel{quicksort}
Ko kličemo algoritem quicksort za urejanje polja, ki vsebuje cela števila $0,\ldots,#n#-1$, je pričakovano število primerjav elementa s pivot-om $H_{#i#+1} + H_{#n#-#i#}$.
\end{lem}

Malo seštevanja harmoničnih števil nam da naslednji izrek o času delovanja, katerega porabi algoritem:

\begin{thm}\thmlabel{quicksort-i}
Ko quicksort algoritem uporabimo za urejanje polja z #n# različnimi elementi, pričakujemo največje število opravljenih primerjav $2#n#\ln #n# + O(#n#)$.
\end{thm}

\begin{proof}
Naj bo $T$ število primerjav opravljenih z algoritmom quicksort, ko razvršča $n$ različnih elementov. Z uporabo Leme \lemref{quicksort}, imamo:
\begin{align*}
  \E[T] &= \sum_{i=0}^{#n#-1}(H_{#i#+1}+H_{#n#-#i#}) \\ 
        &= 2\sum_{i=1}^{#n#}H_i \\ 
        &\le 2\sum_{i=1}^{#n#}H_{#n#} \\ 
        &\le 2#n#\ln#n# + 2#n# = 2#n#\ln #n# + O(#n#) \qedhere
\end{align*}
\end{proof}

Izrek \thmref{quicksort} opisuje primer, kjer so razvrščeni elementi vsi različni. Ko vhodni seznam #a#, vsebuje podvojene elemente, pričakovani čas delovanja za hitro urejanje ni nič slabši, in je lahko celo boljši. Vedno ko je podvojeni element #x# izbran kot pivot #a#, vse pojavitve #x#-a združimo in jih kasneje ne vključimo v enega od dveh podproblemov.

\begin{thm}\thmlabel{quicksort}
Časovna zahtevnost metoda #Quicksort(a, c)# je $O(#n#\log #n#)$, pričakovano število primerjav, ki jih opravi, je večinoma $2#n#\ln #n# +O(#n#)$.
\end{thm}

\subsection{Heap-sort}
\seclabel{heapsort}

\index{heap-sort}%
Algoritem \emph{Heap-sort} je še eden izmed algoritmov urejanja na mestu. Heap-sort uporablja binarno kopico, ki smo jo obravnavali v poglavju \secref{binaryheap}. Spomnimo se, da podatkovna struktura #Binarna-kopica# predstavlja kopico, ki je realizirana z enim seznamom. Heap-sort algoritem pretvori vhodni seznam #a# v kopico in nato ponavljajoče izloča minimalno vrednost.\\

Bolj natančno povedano, kopica hrani #n# elementov v seznam #a#, v lokacijah $#a[0]#,\ldots,#a[n-1]#$ z najmanjšo vrednostjo v korenu oz. #a[0]#. Po transformaciji v #Binarno kopico# heap-sort algoritem ponavljajoče izmenjuje #a[0]# in #a[n-1]#, ter kliče #trickleDown(0)#, tako da so $#a[0]#,\ldots,#a[n-2]#$ zopet veljavna predstavitev kopice. Ko se ta proces konča (ko je $#n#=0$) se elementi #a# shranijo v padajočem zaporedju, da je #a# obrnjen in dobimo končno urejevalno zaporedje.
\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/heapsort}
  \end{center}
  \caption[Heap sort]{Primer izvedbe #heapSort(a,c)#.}
  \figlabel{heapsort}
\end{figure}

\javaimport{ods/BinaryHeap.sort(a,c)}
\cppimport{ods/BinaryHeap.sort(b)}

Ključna podrutina v heap-sort je konstruktor za pretvorbo urejenega seznama #a# v kopico. To bi z lahkoto storili v času $O(#n#\log#n#)$ z ponavljajočim klicem metode #add(x)# binarne kopice, a znamo to operacijo izvesti hitreje z uporabo bottom-up algoritma.
Spomnimo se, da so v binarni kopici otroci #a[i]# shranjeni na položajih #a[2i+1]# in #a[2i+2]#. To namiguje, da elementi $#a#[\lfloor#n#/2\rfloor],\ldots,#a[n-1]#$ nimajo otrok. Z drugimi besedami je vsak element $#a#[\lfloor#n#/2\rfloor],\ldots,#a[n-1]#$
podkopica velikosti 1. Sedaj ko delamo od zadaj naprej, lahko kličemo metodo #trickleDown(i)# za vsak $#i#\in\{\lfloor #n#/2\rfloor-1,\ldots,0\}$. To deluje, ker je do trenutka ko kličemo #trickleDown(i)# vsak od otrok #a[i]# koren podkopice. 
S tem ko kličemo #trickleDown(i)#, nastavimo #a[i]# kot koren svoje podkopice.
\javaimport{ods/BinaryHeap.BinaryHeap(a,c)}
\cppimport{ods/BinaryHeap.BinaryHeap(b)}

Zanimivost te bottom-up strategije je, da je bolj učinkovita kot klicanje metode #add(x)# #n#-krat. Opazimo, da za $#n#/2$ elementov sploh ne delamo, za $#n#/4$ elementov kličemo #trickleDown(i)# nad podkupico, katere koren je $a[i]$ in je njena višina enaka 1.
Za $#n#/8$ elementov kličemo metodo #trickleDown(i)# nad podkopici katere višina je enaka 2 in tako dalje.
Ker je delo, ki ga izvaja #trickleDown(i)# sorazmerno višini podkopice #a[i]#, je celotnega dela največ
\[
    \sum_{i=1}^{\log#n#} O((i-1)#n#/2^{i})
    \le \sum_{i=1}^{\infty} O(i#n#/2^{i})
    = O(#n#)\sum_{i=1}^{\infty} i/2^{i}
    =  O(2#n#) = O(#n#) \enspace .
\]
Predzadnja enakost sledi, ker je seštevek
$\sum_{i=1}^{\infty} i/2^{i}$ po definiciji enak pričakovanemu številu glav ob metu kovanc ob uporabi lemme \lemref{coin-tosses}.

Sledeči teorem opisuje zmogljivost metode #heapSort(a,c)#.
\begin{thm}
  Metoda #heapSort(a,c)# se izvede v $O(#n#\log #n#)$ času in izvede največ $2#n#\log #n# + O(#n#)$ primerjav.
\end{thm}

\begin{proof}
Algoritem deluje v treh korakih:  (1)~Pretvorba #a# v kopico,
(2)~ponavljajoče izločanje minimalnega elementa iz #a# in (3)~obrne elemente v #a#.  
Ravno smo zatrdili da korak~1 potrebuje $O(#n#)$
časa za izvedbo in $O(#n#)$ primerjav. Korak~3  potrebuje $O(#n#)$ čaza za izvedbo in nič primerjav.  
Korak~2 izvede #n# klicev metode #trickleDown(0)#.
$i$-ti klic se izvaja na kopici velikosti $#n#-i$ in izvede največ 
$2\log(#n#-i)$ primerjav. Če seštejemo preko #i# dobimo
\[
   \sum_{i=0}^{#n#-i} 2\log(#n#-i) 
   \le \sum_{i=0}^{#n#-i} 2\log #n#
   =  2#n#\log #n#
\]
S tem ko dodamo število izvedenih primerjav v vsakem od treh korakov dokončamo dokaz.
\end{proof}

\section{Diskusija in Naloge}

Sortiranje je osnovni algoritemski problem v računalništvu in ima dolgo zgodovino.
Knuth \cite{k97v3} pripisuje alogritem sortiranja z zlivanjem
von Neumann(1945). Hitro urejanje je last Hoare \cite{h61}.
Originalno urejanje s kopico je last Williams \cite{w64}, ampak verzija, ki je tu 
predstavljena(v kateri se kopica gradi iz spodaj nazvgor v $O(#n#)$ času) je last Floyd \cite{f64}.
Spodnje meje za sortiranje s primerjavami se zdijo folklorne. Naslednja tabela
povzame izvedbo teh algoritmov za urenjanje s primerjavami:

\begin{center}
  \begin{tabular}{|l|r@{}l@{ }l|l|} \hline
    & \multicolumn{3}{c|}{primerjave} & na mestu  \\ \hline
    Urejanje z zlivanjem & $#n#\log #n#$ & &  najslabši primer & Ne  \\
    Hitrjo urejanje & $1.38#n#\log #n#$ & ${}+ O(#n#)$ & pričakovano & Da \\
    Urejanje s kopico & $2#n#\log #n#$ & ${}+ O(#n#)$ & najslabši primer & Da \\ \hline
  \end{tabular}
\end{center}

Vsi te alogiritmi urejanje s primerjanjem imajo svoje prednosti in slabosti.
Urejanje z zlivanjem naredi najmanj primerjav in se ne zanaša na naključnost.
Na žalost, uporablja pomožno tabelo med fazo zlivanja. Dodeljevanje pomnilnika 
tej tabeli je lahko drago in ima potencial, da je to usodnno za algoritem, če je
količina spomina omejena. Hitro urejanje je algoritem urejanja \emph{na mestu}
\index{in-place algorithm}%
in je blizu na drugem mestu v številu primerjav, ampak je naključno, zato čas 
izvajanja ni vedno zagotovljen. Urejanje s kopico naredi največ primerjav, ampak je 
urejanje na mestu in je deterministično.

Obstaja en primer, v katerem je urejanje s kopico očiten zmagovalec; to se zgodi pri sortiranju
povezanega seznama. V tem primeru, ne potrebujemo pomožne tabele; dva urejena povezana seznama, 
se zelo lahko zljieta v en urejen povezan seznam z uporabo manipulacije kazalcev (glej
\excref{list-merge-sort}).

Algoritma urejanja s štetjem in urejanja po delih opisana tu, je last 
Seward \cite[Section~2.4.6]{s54}. Ampak različice urejanja po delih so
v uporabi že od 20 let 20. stoletja, za urejanje luknjanih kartic
z uporabo strojev za urejanje luknjanih kartic. Te stroji lahko uredijo 
kup kartic v dva kupa, glede na obstoj(ali neobstoj) ljuknice na specifični
lokaciji na kartici. Ponovitev tega procesa, za drugo
luknjico nam da implementacijo urejanja po delih.

Na koncu, opazimo, da urejanje s štetjem in po delih lahko uporabimo, za 
urejanje drugih vrst številk razen ne negativnih celih števil. 
Enostavne spremembe urejanja s štetjem lahko sortirajo cela števila
v kateremkoli intervalu $\{a,\ldots,b\}$, v $O(#n#+b-a)$ času.  Podobno, urejanje 
po delih lahko ureja cela števila na enakem intervalu v $O(#n#(\log_{#n#}(b-a))$ času.
Na koncu, lahko oba algoritma uporabimo za urejanje števil s plavajočo vejico v 
IEEE 754 formatu plavjoče vejice. To lahko naredimo zato, ker je IEEE format narejen
tako, da dovoljuje primerjavo dveh števil s plavajočo vejico glede na njuni vrednosti, 
kot če bi bili celi števili v predznačeni dvojiški predstavitvi \cite{ieee754}.

\begin{exc}
  Ilustriraje izvedbo urejanje z zlivanjem in urejanja s kopico na vhodni tabeli,
  ki vsebuje $1,7,4,6,2,8,3,5$. Naredite vzorčno ilustracijo ene možnosti izvede
  hitrega urejanja na isti tabeli.
\end{exc}

\begin{exc}\exclabel{list-merge-sort}
  Implementirajte verzijo algoritma za urejanje z zlivanjem, ki sortirajo dvojno povezan seznam, brez uporabe
  pomožne tabele. (Glej \excref{dllist-sort}.) 
\end{exc}

\begin{exc}
  Nekatere implementacije #quickSort(a,i,n,c)# vedno uporabljajo #a[i]#
  kot pivot.  V primeru, da je vhodna tabele dolžine #n# v kateri taka implementacija izvede
  $\binom{#n#}{2}$ primerjav.
\end{exc}

\begin{exc}
  Nekatere implementacije #quickSort(a,i,n,c)# vedno uporabljajo #a[i+n/2]#
  kot pivot. V primeru, da je vhodna tabele dolžine #n# v kateri taka 
  implementacija izvede $\binom{#n#}{2}$ primerjav.
\end{exc}

\begin{exc}
  Pokažite, da za katerokoli implementacijo #quickSort(a,i,n,c)#,
  ki izbere pivot deterministično, brez da pogleda katerokoli vrednost 
  v $#a[i]#,\ldots,#a[i+n-1]#$, obstaja vhodna tabela dolžine #n#,
  katera povzroči to implementacijo, da naredi $\binom{#n#}{2}$ primerjav.
\end{exc}

\begin{exc}
  Načrtujte #Comparator#, #c#, katerega lahko podate kot argument funkciji
  #quickSort(a,i,n,c)#, kateri bi povzročil $\binom{#n#}{2}$ primerjav.  
  (Namig: Vašemu Comparator-ju ni potrebno gledati vrednosti, ki se primerjajo.)
\end{exc}

\begin{exc}
  Analizirajte pričakovano število primerjav, ki jih naredi Quicksort, malo bolj pazljivo, kot
  dokaz \thmref{quicksort}. Dokažite, da je pričakovano število primerjav $2#n#H_#n# -#n# + H_#n#$.
\end{exc}

\begin{exc}
  Opišite vhodno tabelo, ki povzroči, da urejanje s kopico, naredi največ
  $2#n#\log #n#-O(#n#)$ primerjav. Utemeljite vaš odgovor.
\end{exc}

\javaonly{
\begin{exc}
  Implementacija sortiranja s kopico, ki je opisana tukaj, uredi elemente v obratni 
  vrstni red in nato  tabelo. Ta zadnji korak, lahko izputimo, če definiramo nov #Comparator#,
  ki negira rezultat vhoda #Comparatorja# #c#. Razložite zakaj to nebi
  bila dobra optimizacija. (Namig: Pomislite koliko negacij bi bilo potrebno v razmerju s koliko časa potrebujemo, da obrnemo tabelo.)
\end{exc}
}

\begin{exc}
  Najdite nek drug par premutacij $1,2,3$ , ki nisto pravilno urejene
  z drevesom primerjav v \figref{comparison-tree-2}.
\end{exc}

\begin{exc}\exclabel{log-factorial}
  Dokažite, da $\log #n#! = #n#\log #n#-O(#n#)$.
\end{exc}

\begin{exc}
  Dokažite, da dvojiško drevo s $k$ listi ima višino najmanj $\log k$.
\end{exc}

\begin{exc}\exclabel{randomized-lower-bound}
  okažite, da če izberemo naključen list iz dvojiškega drevesa s $k$ listi,
  potem je pričakovana višina lista, najmanj $\log k$.
\end{exc}

\begin{exc}
  Implementacija #radixSort(a,k)# podana tukaj, deluje ko vhodna 
  tabela, #a# vsebuje samo \javaonly{ne negativna} cela števila.
  \javaonly{Razširite to implementacijo, tako da deluje tudi, ko #a# vsebuje negativna in ne negativna cela števila.}
  \cpponly{Napišite verzijo, ki deluje za predznačena cela števila.}
\end{exc}

