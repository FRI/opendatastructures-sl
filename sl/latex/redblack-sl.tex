\chapter{Red-Black Trees}
\chaplabel{redblack}

\index{binary search tree!red-black}%
\index{red-black tree}%
In this chapter, we present red-black trees, a version of binary search
trees with logarithmic height.  Red-black trees are one of the most
widely used data structures.  They appear as the primary search structure
in many library implementations, including the Java Collections Framework
and several implementations of the C++ Standard Template Library. They
are also used within the Linux operating system kernel.  There are
several reasons for the popularity of red-black trees:
\begin{enumerate}
\item A red-black tree storing #n# values has height at most $2\log #n#$.
\item The #add(x)# and #remove(x)# operations on a red-black tree run
   in $O(\log #n#)$ \emph{worst-case} time.
\item The amortized number of rotations performed during an #add(x)#
   or #remove(x)# operation is constant.
\end{enumerate}
The first two of these properties already put red-black trees 
ahead of skiplists, treaps, and scapegoat trees.
Skiplists and treaps rely on randomization and their $O(\log #n#)$
running times are only expected. Scapegoat trees have a guaranteed
bound on their height, but #add(x)# and #remove(x)# only run in $O(\log
#n#)$ amortized time.  The third property is just icing on the cake. It
tells us that  that the time needed to add or remove an element #x# is
dwarfed by the time it takes to find #x#.\footnote{Note that skiplists and
treaps also have this property in the expected sense. See
Exercises~\ref{exc:skiplist-changes} and \ref{exc:treap-rotates}.}

However, the nice properties of red-black trees come with a price:
implementation complexity. Maintaining a bound of $2\log #n#$ on the
height is not easy. It requires a careful analysis of a number of cases.
We must ensure that the implementation does exactly the right
thing in each case.  One misplaced rotation or change of colour produces
a bug that can be very difficult to understand and track down.

Rather than jumping directly into the implementation of red-black trees,
we will first provide some background on a related data structure:
2-4 trees.  This will give some insight into how red-black trees were
discovered and why efficiently maintaining them is even possible.

\section{2-4 Trees}
\seclabel{twofour}

A 2-4 tree is a rooted tree with the following properties:
\begin{prp}[height]
  All leaves have the same depth.
\end{prp}
\begin{prp}[degree]
  Every internal node has 2, 3, or 4 children.
\end{prp}
An example of a 2-4 tree is shown in \figref{twofour-example}.
\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/24rb-2}
  \end{center}
  \caption{A 2-4 tree of height 3.}
  \figlabel{twofour-example}
\end{figure}
The properties of 2-4 trees imply that their height is logarithmic in
the number of leaves:
\begin{lem}\lemlabel{twofour-height}
  A 2-4 tree with #n# leaves has height at most $\log #n#$.
\end{lem}

\begin{proof}
  The lower-bound of 2 on the number of children of an internal node
  implies that, if the height of a 2-4 tree is $h$, then it has at least
  $2^h$ leaves.  In other words,
  \[
     #n# \ge 2^h \enspace .
  \]
  Taking logarithms on both sides of this inequality gives $h \le \log #n#$.
\end{proof}

\subsection{Adding a Leaf}

Adding a leaf to a 2-4 tree is easy (see \figref{twofour-add}).  If we
want to add a leaf #u# as the child of some node #w# on the second-last
level, then we simply make #u# a child of #w#.  This certainly maintains
the height property, but could violate the degree property;  if #w#
had four children prior to adding #u#, then #w# now has five children.
In this case, we \emph{split}
\index{split}%
#w# into two nodes, #w# and #w#', having
two and three children, respectively.
But now #w#' has no parent,
so we recursively make #w#' a child of #w#'s parent.  Again, this may
cause #w#'s parent to have too many children in which case we split it.
This process goes on until we reach a node that has fewer than four children,
or until we split the root, #r#, into two nodes #r# and #r'#.  In the
latter case, we make a new root that has #r# and #r'# as children.
This simultaneously increases the depth of all leaves and so maintains
the height property.

\begin{figure}
  \begin{center}
   \begin{tabular}{c}
     \includegraphics[scale=0.90909]{figs/24tree-add-1} \\
     \includegraphics[scale=0.90909]{figs/24tree-add-2} \\
     \includegraphics[scale=0.90909]{figs/24tree-add-3}
   \end{tabular}
  \end{center}
  \caption[Adding a leaf to a 2-4 Tree]{Adding a leaf to a 2-4 Tree.
  This process stops after one split because #w.parent# has a degree of less
  than 4 before the addition.}
  \figlabel{twofour-add}
\end{figure}

Since the height of the 2-4 tree is never more than $\log #n#$, the
process of adding a leaf finishes after at most $\log #n#$ steps.

\subsection{Removing a Leaf}

Removing a leaf from a 2-4 tree is a little more tricky (see
\figref{twofour-remove}).  To remove a leaf #u# from its parent #w#, we
just remove it.  If #w# had only two children prior to the removal of #u#,
then #w# is left with only one child and violates the degree property.

\begin{figure}
  \begin{center}
   \begin{tabular}{c}
     \includegraphics[height=\FifthHeightScaleIfNeeded]{figs/24tree-remove-1} \\
     \includegraphics[height=\FifthHeightScaleIfNeeded]{figs/24tree-remove-2} \\
     \includegraphics[height=\FifthHeightScaleIfNeeded]{figs/24tree-remove-3} \\
     \includegraphics[height=\FifthHeightScaleIfNeeded]{figs/24tree-remove-4} \\
     \includegraphics[height=\FifthHeightScaleIfNeeded]{figs/24tree-remove-5} \\
   \end{tabular}
  \end{center}
  \caption[Removing a leaf from a 2-4 Tree]{Removing a leaf from a
    2-4 Tree.  This process goes all the way to the root because each of
    #u#'s ancestors and their siblings have only two children.}
  \figlabel{twofour-remove}
\end{figure}

To correct this, we look at #w#'s sibling, #w'#.  The node #w'# is
sure to exist since #w#'s parent had at least two children.  If #w'#
has three or four children, then we take one of these children from #w'#
and give it to #w#. Now #w# has two children and #w'# has two or three
children and we are done.

On the other hand, if #w'# has only two children, then we \emph{merge}
\index{merge}%
#w# and #w'# into a single node, #w#, that has three children.  Next we
recursively remove #w'# from the parent of #w'#.  This process ends
when we reach a node, #u#, where #u# or its sibling has more than two
children, or when we reach the root.  In the latter case, if the root
is left with only one child, then we delete the root and make its child
the new root.  Again, this simultaneously decreases the height of every
leaf and therefore maintains the height property.

Again, since the height of the tree is never more than $\log #n#$,
the process of removing a leaf finishes after at most $\log #n#$ steps.

\section{#RedBlackTree#: A Simulated 2-4 Tree}
\seclabel{redblacktree}

Rdeče črno drevo je binarno iskalno drevo, katerega vsako vozlišče, #u#,
je \emph{rdeče} ali \emph{črno}. Rdeče 
predstavlja vrednost $0$, črno pa vrednost $1$.
\index{red node}%
\index{black node}%
\javaimport{ods/RedBlackTree.red.black.Node<T>}
\cppimport{ods/RedBlackTree.RedBlackNode.red.black}

Pred in po spreminjanju rdeče-črnega drevesa, morata veljati naslednji dve
lastnosti. Each property is defined both in terms of the
colours red and black, and in terms of the numeric values 0 and 1.
\begin{prp}[višina-črnih]
  \index{black-height property}%
  Enako število črnih vozlišč v poti od korena do katerega koli lista. (Vsota
  barv na poti od korena do poljubnega lista je enaka.)
\end{prp}

\begin{prp}[no-red-edge]
  \index{no-red-edge property}%
  Dve rdeči vozlišči nista med seboj nikoli sosednji.  (Velja za vsako vozlišče #u#, razen korena,
  $#u.barva# + #u.stars.barva# \ge 1$.)
\end{prp}
Opazili smo, da lahko vedno pobarvamo koren, #r#, rdeče-črnega drevesa črno,
ne da bi kršili katero od lastnosti, zato bomo predvidevali, da je koren črne barve
in algoritmi za posodabljanje rdeče-črnih dreves bodo to upoštevali.
Druga stvar, ki poenostavlja rdeče-črna drevesa
je, da so zunanja vozlišča (predstavljena z #nil#) črna vozlišča.
Na ta način ima vsako vozlišče, #u#, rdeče-črnega drevesa natanko dva
otroka, vsak z opredeljeno barvo. Primer rdeče-črnega
drevesa je predstavljen v sliki \figref{redblack-example}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/24rb-1}
  \end{center}
  \caption[A red-black tree]{Primer rdeče-črnega drevesa, kjer je višina črnih 3. Zunanja (#nil#) vozlišča so v obliki kvadrata.} 
  \figlabel{redblack-example}
\end{figure}

\translatedby{Mitja Ahlin}{sl}
\subsection{Rdeče-Črna drevesa in 2-4 Drevesa}

Sprva se morda zdi presenetljivo, da lahko rdeče-črno drevo učinkovito
posodabljamo tako, da ohranjamo višine črnih vozlišč in ne ohranjamo lastnosti rdečih vozlišč. Zdi se tudi nenavadno, da nekateri menijo, da so to koristne lastnosti. Kakorkoli, rdeče-črna drevesa so bila zasnovana za učinkovito simulirati 2-4 drevesa kot binarna drevesa.


Nanašanje na \figref{twofour-redblack}.
Vzemimo, da ima katerokoli rdeče-črno drevo, $T$, #n# vozlišč in izvaja naslednje operacije: Zbriše vsako rdeče vozlišče #n# in poveže otroka vozlišča #u# direktno na (črnega) starša vozlišča #u#. Po teji spremembi imamo drevo $T'$ z samo črnimi vozlišči.

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909]{figs/24rb-3} \\
      \includegraphics[scale=0.90909]{figs/24rb-2}
    \end{tabular}
  \end{center}
  \caption{Vsako rdeče-črno drevo ima ustrezno 2-4 drevo.}
  \figlabel{twofour-redblack}
\end{figure}

Vsako notranje vozlišče v $T'$ ima dva, tri ali štiri otroke: Črno vozlišče, ki je imelo dva črna otroka bo še vedno imelo črna otroka po spremembi. Črno vozlišče, ki je imelo enega rdečega in enega črnega otroka bo imelo tri otroke po tej spremembi. Črno vozlišče, ki je imelo dva rdeča otroka bo imelo štiri otroke po teji spremembi. Poleg tega, lastnost črnih vozlišč nam garantira, da vsaka pot od korena do lista v $T'$ je enake dolžine. Z drugimi besedami, $T'$ je 2-4 drevo!

2-4 drevo $T'$ ima $#n#+1$ listov, ki ustrezajo $#n#+1$ zunanjim vozliščim rdeče-črnega drevesa. Torej, to drevo ima višino največ $\log (#n#+1)$. Vsaka pot od korena do lista v 2-4 drevesu ustreza poti od korena rdeče-črnega drevesa $T$ do zunanjega vozlišča.
Prvo in zadnje vozlišče v teji poti sta črna in največ eden na vsaka dva notranja vozlišča je rdeč, tako, da ima ta pot največ $\log(#n#+1)$ črnih in največ $\log(#n#+1)-1$ rdečih vozlišč. Torej, najdaljša pot od korena do kateregakoli \emph{notranjega} vozlišča v $T$ je največ
\[
   2\log(#n#+1) -2 \le 2\log #n# \enspace ,
\]
za kateregakoli $#n#\ge 1$. To dokaže najpomembnejšo lastnost rdeče-črnih dreves:
\begin{lem}
Višina rdeče-črnega drevesa z #n# vozlišči je največ $2\log #n#$.
\end{lem}

Sedaj, ko smo videli relacijo med 2-4 drevesi in rdeče-črnimi drevesi, ni tako težko za verjeti, da lahko učinkovito ohranjamo rdeče-črno drevo med dodajanjem in brisanjem elementov.

Videli smo že, da dodajanje elementa v #BinarySearchTree# izvedemo z dodajanjem novega lista. Torej, za implementacijo #add(x)# v rdeče-črno drevo moramo imeti metodo za simulacijo razdelitve vozlišča s petimi otroci v 2-4 drevesu. Vozlišče v 2-4 drevesu s petimi otroci je predstavljeno s črnim vozliščem, ki ima dva rdeča otroka, eden od teh ima tudi rdečega otroka. Lahko ``razdelimo'' to vozlišče s tem, da ga pobarvamo v rdeče in pobarvamo njegova dva otroka v črno. Primer prikazuje \figref{rb-split}.

\begin{figure}
  \begin{center}
   \begin{tabular}{c}
     \includegraphics[scale=0.90909]{figs/rb-split-1} \\
     \includegraphics[scale=0.90909]{figs/rb-split-2} \\
     \includegraphics[scale=0.90909]{figs/rb-split-3} \\
   \end{tabular}
  \end{center}
  \caption[Simulirano 2-4 drevo]{Simuliranje operacije deljenja 2-4 drevesa med dodajanjem v rdeče-črno drevo. (To simulira dodajanje v 2-4 drevo prikazano na \figref{twofour-add}.)}
  \figlabel{rb-split}
\end{figure}

Podobno, implementacija #remove(x)# zahteva metodo za združevanje dveh vozlišč in izposojo sorodnikovega otroka. Združitev dveh vozlišč je inverz deljenja vozlišč (prikazano na \figref{rb-split}) in vključuje barvanje dveh (črnih) sorodnikov v rdeče in barvanje njegovega (rdečega) starša v črno. Izposoja od sorodnika je najboj zakompliciran postopek in vključuje obe rotacije in barvanje vozlišč.

Vsekakor, med vsem tem moramo še vedno ohranjati lastnost no-red-edge in lastnost black-height. Medtem ni več presenetljivo, da je to lahko izvedljivo, veliko je število primerov, ki jih moramo upoštevati, če poikušamo narediti ditektno simulacijo 2-4 drevesa z rdeče-črnim drevesom. Na neki točki, postane lažje če neupoštevamo osnovnih 2-4 dreves in delamo neposredno k ohranjanju lastnosti rdeče-črnih dreves.

\subsection{Levo-viseca Rdece-Crna Drevesa}

\index{red-black tree}%
\index{left-leaning red-black tree}%
Ne obstaja nobena definicija rdeče-črnega drevesa. Namesto tega, je družina struktur, ki uspe ohranjati  lastnosti black-height in no-red-edge med operacijama #add(x)# in #remove(x)#. Drugačne strukture to delajo na drugačne načine. Tukaj mi implementiramo podatkovno strukturo, ki jo kličemo #RdeceCrnoDrevo#.
\index{RedBlackTree@#RedBlackTree#}%
Ta struktura implementira posebno obliko rdeče-črnega drevesa, ki zadovoljuje dodatni lastnosti.
\begin{prp}[left-leaning]\prplabel{levo-visece}\prplabel{redblack-last}
  \index{left-leaning property}%
  Na kateremkoli vozlišču #u#, če je #u.levo# črno, potem #u.desno# je črno.
\end{prp}

Opomnimo, da rdeče-črno drevo prikazano na \figref{redblack-example} ne zadošča levo-viseči lastnosti; krši jo starš rdečega vozlišča na najbolj desni poti od korena proti listu.

Razlog za ohranjanje levo-viseče lastnosti je, da zmanjšuje število primerov soočenih pri posodabljanju drevesa med operacijama #add(x)# in #remove(x)#. V smuslu 2-4 dreves, to pomeni, da vsako 2-4 drevo ima edinstveno zastopanje: Vozlišče stopnje dva postane črno vozlišče z dvemi črnimi otroci. Vozlišče stopnje tri postane črno vozlišče katerega levi otrok je rdeč in desni otrok je črn. Vozlišče stopnje štiri postane črno vozlišče z dvema rdečima otrokoma.

Preden opišemo implementacijo operacij #add(x)# in #remove(x)# v podrobnosti, prvo predstavimo nekaj osnovnih podoperacij uporabljenih v teh metodah prikazanih v \figref{redblack-flippullpush}. Prvi dve podoperaciji so za manipulacijo barv med ohranjanjem lastnosti black-height. Operacija #pushBlack(u)# metoda vzame za vhod črno vozlišče #u#, katero ima dva rdeča otroka in pobarva #u# rdeče in njegova dva otroka črno. Operacija #pullBlack(x)# obrne to opisano operacijo:
\codeimport{ods/RedBlackTree.pushBlack(u).pullBlack(u)}

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/flippullpush}
  \end{center}
  \caption{Flips, pulls and pushes}
  \figlabel{redblack-flippullpush}
\end{figure}

Metoda #flipLeft(u)# zamenja barve vozlišča #u# in #u.desno# in izvede levo rotacijo nad vozliščem #u#. Ta metoda obrne barve teh dveh vozlišč tako kot tudi relacijo njihovih staršev-otrok:
\codeimport{ods/RedBlackTree.flipLeft(u)}
Operacija #flipLeft(u)# je pposebno uporabna pri povrnitvi levo-viseče lastnosti na vozlišču #u#, katero krši to lastnost (ker je #u.left# črno in #u.right# rdeče). V tem posebnem primeru, smo lahko zagotovi, da ta operacija ohranja obe lastnosti black-height in no-red-edge. Relacija #flipRight(u)# je simetrična z #fliPLeft(u)#, ko so vloge levega in desnega obrnjene.
\codeimport{ods/RedBlackTree.flipRight(u)}

\subsection{Dodajanje}

Za implementacijo #add(x)# v #RdeceCrnoDrevo#, izvedemo standardno #BinarnoIskalnoDrevo# vstavljanje za dodajanje novega lista, #u#, z $#u.x#=#x#$ in nastavimo $#u.colour#=#red#$. Opomnimo, da to ne spremeni črne višine kateremukoli vozlišču, torej ne krši lastnosti black-height. To pa lahko krši levo-visečo lastnost (če je #u# desni otrok svojega starša), in lahko krši no-red-edge lastnost (če je #u#jev starš #rdec#). Za povrnitev teh lastnosti, moramo klicati metodo #addFixup(u)#.
\codeimport{ods/RedBlackTree.add(x)}

Ilustrirano na \figref{rb-addfix}, metoda #addFixup(u)# vzame za vhod vozlišče #u# katerega barva je rdeča in katero bi lahko kršilo lastnost no-red-edge in/ali levo-ležečo lastnost. Slednja razprava je verjetno nemogoča za sledelje brez sklicevanja na \figref{rb-addfix} ali ponovnega ustvarjanja na kosu papirja. Dejansko, bralec bi si moral preučiti to sliko preden nadaljuje.

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/rb-addfix}
  \end{center}
  \caption{Enotni postopek v procesu popravljanja Property~2 po vstavljanju.}
  \figlabel{rb-addfix}
\end{figure}

Če je #u# koren drevesa, potem lahko pobarvamo #u# v črno za pridobitev nazaj obeh lastnosti. Če je tudi #u#jev sorodnik rdeč, potem mora biti #u#jev starš črn, torej oba levo-viseča in no-red-edge lastnost že držita.
 
Če ne, najprej določimo, če je #u#jev starš, #w#, kršil levo-visečo lastnost in, če je tako, izvedemo operacijo #flipLeft(w)# in nastavimo $#u#=#w#$. To nas pusti v lepo definiranem stanju: #u# je levi otrok starša, #w#, torej #w# sedaj zadošča levi-viseči lastnosti. Vse kar nam ostane je, da zagotovimo no-red-edge lastnost na #u#. Moramo samo še skrbeti za primer v katerem je #w# rdeč, sicer v nasprotnem primeru #u# že zadošča lastnosti no-red-edge.

Glede na to, da še nismo končali, #u# je rdeč in #w# je rdeč. Lastnost no-red-edge (katero krši #u# in ne #w#) implicira, da #u#jev stari starš #g# obstaja in je črn. Če je #g#jev desni otrok rdeč, potem levo-viseča lastnost zagotavlja, da oba #g#jev otrok je rdeč in klic na #pushBlack(g)# naredi #g# rdečega in #w# črnega. To povrne no-red-edge lastnost na #u#, ampak lahko povzroči, da jo krši na #g# vozlišču, tako, da celoten proces začne z $#u#=#g#$.

Če je #g#jev otrok črn, potem klic na #flipRight(g)# nardi #w# črnega starča od #g# in naredi #w#ju dva rdeča otroka, #u# in #g#. To zagotovi, da #u# zadošča no-red-edge lastnosti in #g# zadošča levo-viseči lastnosti. V tem primeru se lahko ustavimo.
\codeimport{ods/RedBlackTree.addFixup(u)}

Metoda #insertFixup(u)# ima konstantni čas za iteracijo in vsaka iteracija ali konča ali premakne #u# bližje korenu. Zato, metoda #insertFixup(u)# konča po $O(\log #n#)$ iteracijah in po $O(\log #n#)$ času.


\subsection{Odstranitev}

#odstrani(x)# operacija v #RdeceCrnemDrevesu# je najbolj zahtevna
za implementacijo in to velja za vse različice rdeče-črnega drevesa.
Tako kot #odstrani(x)# operacija v \texttt{BinarnemIskalnemDrevesu},
išče vozlišče #w# z enim otrokom,
#u# in preplete #w# iz drevesa tako, da #w.parent# sprejme #u#.

Težava lahko nastane takrat, ko je #w# črn, saj s tem kršimo lastnost višine črnih v #w.parent#. 
Temu se lahko začasno izognemo z dodajanem #w.barva# do #u.barva#. To predstavlja
dve težavi: (1)~če se #u# in #w# obe začneta z črno, potem $#u.barva#+#w.barva#=2$ (dvojna črna), ki pa ni veljavna.
Če je bil #w# rdeč, se ga nadomesti s črnim vozliščem #u#, kateri lahko
krši levo usmerjeno lastnost pri $#u.parent#$. Obe težave 
lahko rešimo tako, da pokličemo metodo #removeFixup(u)#.

#removeFixup(u)# metoda prejme kot vhodni parameter vozlišče #u#, ki 
je črne (1) ali dvojno-črne barve (2). Če je #u# dvojno-črn, potem #removeFixup(u)#
opravi vrsto vrtenj in prebarvanj tako, da dvojno-črno vozlišče premika navzgor
po drevesu, dokler ni odpravljen.
The #removeFixup(u)# method takes as its input a node #u# whose colour is black
(1) or double-black (2).  If #u# is double-black, then #removeFixup(u)#
performs a series of rotations and recolouring operations that move the
double-black node up the tree until it can be eliminated. Skozi ta postopek
se vozlišče #u# spreminja, dokler ne pride do konca postopka, #u# pa
pripada korenu  podrevesa, ki se je spremenil. Koren tega drevesa
je lahko sedaj druge barve. Če je prešel iz rdeče na črno barvo,
 #removeFixup(u)# metoda na koncu preverja,
če #u#-jev starš krši levo usmerjeno lastnost in če jo to popravi.
\codeimport{ods/RedBlackTree.removeFixup(u)}

 #removeFixup(u)# metoda je predstavljena na figref{rb-removefix}
Naslednjemu besedilu bo težko, če ne kar nemogoče slediti
brez sklicevanja na  \figref{rb-removefix}. Vsaka ponovitev zanke
v #removeFixup(u)# postopku dvojno-črnega vozlišča #u#, temelji na
enemu od štirih primerov:

\begin{figure}
  \begin{center}
    \includegraphics[height=\HeightScaleIfNeeded]{figs/rb-removefix}
  \end{center}
  \caption{A single round in the process of eliminating a double-black node
   after a removal.}
  \figlabel{rb-removefix}
\end{figure}

\noindent
Primer 0: #u# je koren. To je najpreprostejšji primer. Prebarvali smo
#u# v črno (s tem ne kršimo nobene lastnosti rdeče-črnega drevesa).

\noindent 
Case 1: #u#'s sibling, #v#, is red.  In this case, #u#'s sibling is the
left child of its parent, #w# (by the left-leaning property).  We perform
a right-flip at #w# and then proceed to the next iteration.  Note that
this action causes #w#'s parent to violate the left-leaning property and
the depth of #u# to increase.  However, it also implies that the next
iteration will be in Case~3 with #w# coloured red.  When examining Case~3
below, we will see that the process will stop during the next iteration.
\codeimport{ods/RedBlackTree.removeFixupCase1(u)}

\noindent
Case 2: #u#'s sibling, #v#, is black, and #u# is the left child of its
parent, #w#.  In this case, we call #pullBlack(w)#, making #u# black,
#v# red, and darkening the colour of #w# to black or double-black.
At this point, #w# does not satisfy the left-leaning property, so we
call #flipLeft(w)# to fix this.

At this point, #w# is red and #v# is the root of the subtree with which
we started.  We need to check if #w# causes the no-red-edge property to
be violated.  We do this by inspecting #w#'s right child, #q#.  If #q#
is black, then #w# satisfies the no-red-edge property and we can continue
the next iteration with $#u#=#v#$.

Otherwise (#q# is red), so both the no-red-edge property and the left-leaning
properties are violated at #q# and #w#, respectively.  The left-leaning
property is restored with a call to  
#rotateLeft(w)#, but the no-red-edge
property is still violated.  At this point, #q# is the left child of
#v#, #w# is the left child of #q#, #q# and #w# are both red, and #v#
is black or double-black.  A #flipRight(v)#  makes #q# the parent of
both #v# and #w#.  Following this up by a #pushBlack(q)# makes both #v#
and #w# black and sets the colour of #q# back to the original colour of #w#.

At this point, the double-black node is has been eliminated and the
no-red-edge and black-height properties are reestablished.  Only one possible problem remains: the right child of #v# may be red, in which
case the left-leaning property would be violated.  We check this and
perform a #flipLeft(v)# to correct it if necessary.
\codeimport{ods/RedBlackTree.removeFixupCase2(u)}

\noindent
Case 3: #u#'s sibling is black and #u# is the right child of its parent,
#w#.  This case is symmetric to Case~2 and is handled mostly the same way.
The only differences come from the fact that the left-leaning property
is asymmetric, so it requires different handling.

As before, we begin with a call to #pullBlack(w)#, which makes #v# red
and #u# black.  A call to #flipRight(w)# promotes #v# to the root of
the subtree.  At this point #w# is red, and the code branches two ways
depending on the colour of #w#'s left child, #q#.

If #q# is red, then the code finishes up exactly the same way as Case~2
does, but is even simpler since there is no danger of #v# not
satisfying the left-leaning property.

The more complicated case occurs when #q# is black.  In this case,
we examine the colour of #v#'s left child.  If it is red, then #v# has
two red children and its extra black can be pushed down with a call to
#pushBlack(v)#.  At this point, #v# now has #w#'s original colour, and we
are done.

If #v#'s left child is black, then #v# violates the left-leaning property,
and we restore this with a call to #flipLeft(v)#.  We then return the
node #v# so that the next iteration of #removeFixup(u)# then continues
with $#u#=#v#$.
\codeimport{ods/RedBlackTree.removeFixupCase3(u)}.

Each iteration of #removeFixup(u)# takes constant time.  Cases~2 and 3
either finish or move #u# closer to the root of the tree.  Case~0 (where
#u# is the root) always terminates and Case~1 leads immediately to Case~3,
which also terminates.  Since the height of the tree is at most $2\log
#n#$, we conclude that there are at most $O(\log #n#)$ iterations of
#removeFixup(u)#, so #removeFixup(u)# runs in $O(\log #n#)$ time.


\section{Summary}
\seclabel{redblack-summary}

The following theorem summarizes the performance of the #RedBlackTree# data structure:

\begin{thm}
  A #RedBlackTree# implements the #SSet# interface and
  supports the operations #add(x)#, #remove(x)#, and #find(x)# in $O(\log
  #n#)$ worst-case time per operation.
\end{thm}

Not included in the above theorem is the following extra bonus:

\begin{thm}\thmlabel{redblack-amortized}
  Beginning with an empty #RedBlackTree#, any sequence of $m$
  #add(x)# and #remove(x)# operations results in a total of $O(m)$
  time spent during all calls #addFixup(u)# and #removeFixup(u)#. 
\end{thm}

We only sketch a proof of \thmref{redblack-amortized}. By comparing
#addFixup(u)# and #removeFixup(u)# with the algorithms for adding or
removing a leaf in a 2-4 tree, we can convince ourselves that this
property is inherited from a 2-4 tree.  In particular, if we can show
that the total time spent splitting, merging, and borrowing in a 2-4
tree is $O(m)$, then this implies \thmref{redblack-amortized}.

The proof of this theorem for 2-4 trees uses the potential
method
\index{potential method}%
of amortized analysis.\footnote{See the proofs of
\lemref{dualarraydeque-amortized} and \lemref{selist-amortized} for
other applications of the potential method.} Define the potential of an
internal node #u# in a 2-4 tree as
\[
  \Phi(#u#) = 
    \begin{cases} 
      1 & \text{if #u# has 2 children} \\ 
      0 & \text{if #u# has 3 children} \\ 
      3 & \text{if #u# has 4 children}  
    \end{cases}
\]
and the potential of a 2-4 tree as the sum of the potentials of its nodes.
When a split occurs, it is because a node with four children becomes
two nodes, with two and three children.  This means that the overall
potential drops by $3-1-0 = 2$. When a merge occurs, two nodes that used
to have two children are replaced by one node with three children. The
result is a drop in potential of $2-0=2$.  Therefore, for every split
or merge, the potential decreases by two.

Next notice that, if we ignore splitting and merging of nodes, there are
only a constant number of nodes whose number of children is changed by
the addition or removal of a leaf.  When adding a node, one node has
its number of children increase by one, increasing the potential by
at most three.  During the removal of a leaf, one node has its number
of children decrease by one, increasing the potential by at most one,
and two nodes may be involved in a borrowing operation, increasing their
total potential by at most one.

To summarize, each merge and split causes the potential to drop by
at least two.  Ignoring merging and splitting, each addition or removal
causes the potential to rise by at most three, and the potential is always
non-negative.  Therefore, the number of splits and merges caused by $m$
additions or removals on an initially empty tree is at most $3m/2$.
\thmref{redblack-amortized} is a consequence of this analysis and the
correspondence between 2-4 trees and red-black trees.

\section{Discussion and Exercises}

Red-black trees were first introduced by Guibas and Sedgewick \cite{gs78}.
Despite their high implementation complexity they are found in some of
the most commonly used libraries and applications.  Most algorithms and
data structures textbooks discuss some variant of red-black trees.

Andersson \cite{a93} describes a left-leaning version of balanced trees
that is similar to red-black trees but has the additional constraint
that any node has at most one red child.  This implies that these trees
simulate 2-3 trees rather than 2-4 trees.  They are significantly simpler,
though, than the #RedBlackTree# structure presented in this chapter.

Sedgewick \cite{s08} describes two versions of left-leaning red-black
trees.  These use recursion along with a simulation of top-down splitting
and merging in 2-4 trees. The combination of these two techniques makes
for particularly short and elegant code.

A related, and older, data structure is the \emph{AVL tree} \cite{avl62}.
\index{AVL tree}%
AVL trees are \emph{height-balanced}:
\index{height-balanced}%
\index{binary search tree!height balanced}%
At each node $u$, the height
of the subtree rooted at #u.left# and the subtree rooted at #u.right#
differ by at most one.  It follows immediately that, if $F(h)$ is the
minimum number of leaves in a tree of height $h$, then $F(h)$ obeys the
Fibonacci recurrence
\[
   F(h) = F(h-1) + F(h-2)
\]
with base cases $F(0)=1$ and $F(1)=1$.  This means $F(h)$ is approximately
$\varphi^h/\sqrt{5}$, where $\varphi=(1+\sqrt{5})/2\approx1.61803399$ is the
\emph{golden ratio}.  (More precisely, $|\varphi^h/\sqrt{5} - F(h)|\le 1/2$.)
Arguing as in the proof of \lemref{twofour-height}, this implies
\[
   h \le \log_\varphi #n# \approx 1.440420088\log #n# \enspace ,
\]
so AVL trees have smaller height than red-black trees.  The height
balancing can be maintained during #add(x)# and #remove(x)# operations
by walking back up the path to the root and performing a rebalancing
operation at each node #u# where the height of #u#'s left and right
subtrees differ by two.  See \figref{avl-rebalance}.

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/avl-rebalance}
  \end{center}
  \caption{Rebalancing in an AVL tree.  At most two rotations are required
  to convert a node whose subtrees have a height of $h$ and $h+2$ into a node
  whose subtrees each have a height of at most $h+1$.}
  \figlabel{avl-rebalance}
\end{figure}

Andersson's variant of red-black trees, Sedgewick's variant of red-black
trees, and AVL trees are all simpler to implement than the #RedBlackTree#
structure defined here.  Unfortunately, none of them can guarantee that
the amortized time spent rebalancing is $O(1)$ per update.  In particular,
there is no analogue of \thmref{redblack-amortized} for those structures.

\begin{figure}
  \centering{\includegraphics[scale=0.90909]{figs/redblack-example}}
  \caption{A red-black tree on which to practice.}
  \figlabel{redblack-example2}
\end{figure}

\begin{exc}
  Illustrate the 2-4 tree that corresponds to the #RedBlackTree# in
  \figref{redblack-example2}.
\end{exc}

\begin{exc}
  Illustrate the addition of 13, then 3.5, then 3.3 on the #RedBlackTree#
  in \figref{redblack-example2}.
\end{exc}

\begin{exc}
  Illustrate the removal of 11, then 9, then 5 on the #RedBlackTree# in 
  \figref{redblack-example2}.
\end{exc}

\begin{exc}
  Show that, for arbitrarily large values of #n#, there are red-black
  trees with #n# nodes that have height $2\log #n#-O(1)$.
\end{exc}

\begin{exc}
  Consider the operations #pushBlack(u)# and #pullBlack(u)#.  What do
  these operations do to the underlying 2-4 tree that is being simulated
  by the red-black tree?
\end{exc}

\begin{exc}
  Show that, for arbitrarily large values of #n#, there exist sequences
  of #add(x)# and #remove(x)# operations that lead to red-black trees
  with #n# nodes that have height $2\log #n#-O(1)$.
\end{exc}



\begin{exc}
  Why does the method #remove(x)# in the #RedBlackTree# implementation
  perform the assignment #u.parent=w.parent#?  Shouldn't this already
  be done by the call to #splice(w)#?
\end{exc}

\begin{exc}
  Suppose a 2-4 tree, $T$, has $#n#_\ell$ leaves and $#n#_i$ internal nodes.
  \begin{enumerate}
    \item What is the minimum value of $#n#_i$, as a function of $#n#_\ell$?
    \item What is the maximum value of $#n#_i$, as a function of $#n#_\ell$?
    \item If $T'$ is a red-black tree that represents $T$, then how many red
     nodes does $T'$ have?
  \end{enumerate}
\end{exc}

\begin{exc}
  Suppose you are given a binary search tree with #n# nodes and a
  height of at most $2\log #n#-2$.  Is it always possible to colour the
  nodes red and black so that the tree satisfies the black-height and
  no-red-edge properties?  If so, can it also be made to satisfy the
  left-leaning property?
\end{exc}

\begin{exc}\exclabel{redblack-merge}
  Suppose you have two red-black trees $T_1$ and $T_2$ that have the
  same black height, $h$, and such that the largest key in $T_1$ is smaller
  than the smallest key in $T_2$.  Show how to merge $T_1$ and $T_2$
  into a single red-black tree in $O(h)$ time.
\end{exc}

\begin{exc}
  Extend your solution to \excref{redblack-merge} to the case where the
  two trees $T_1$ and $T_2$ have different black heights, $h_1\neq h_2$.
  The running-time should be $O(\max\{h_1,h_2\})$.
\end{exc}



\begin{exc}
  Prove that, during an #add(x)# operation, an AVL tree must perform
  at most one rebalancing operation (that involves at most two rotations;
  see \figref{avl-rebalance}).  Give an example of an AVL tree and a
  #remove(x)# operation on that tree that requires on the order of $\log
  #n#$ rebalancing operations.
\end{exc}

\begin{exc}
  Implement an #AVLTree# class that implements AVL trees as described
  above.  Compare its performance to that of the #RedBlackTree#
  implementation.   Which implementation has a faster #find(x)# operation?
\end{exc}

\begin{exc}
  Design and implement a series of experiments that compare the relative
  performance of #find(x)#, #add(x)#, and #remove(x)# for the #SSet# implemeentations #SkiplistSSet#,
  #ScapegoatTree#, #Treap#, and #RedBlackTree#.  Be sure to include
  multiple test scenarios, including cases where the data is random,
  already sorted, is removed in random order, is removed in sorted order,
  and so on.
\end{exc}
